{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "308c9b8a",
   "metadata": {},
   "source": [
    "# \"\"\"\n",
    "    THIS SCRIPT PERFORM PHOSCPREDICTION FROM IMAGE CROPS\n",
    "    \n",
    "    1. THE IMAGE CROPS CAN BE FROM A YOLOV3 PREDICTION SCRIPT \n",
    "    2. THE IMAGE CROPS CAN BE FROM A ORIGINAL BB FROM LOCALIZATION DATA\n",
    "    3. THIS SCRIPT PROJECT BACK THE RESULT ON ORIGINAL IMAGE WHERE WE\n",
    "    CAN SEE CORRECT AND WRONG PREDICTION.\n",
    "    4. IMAGE CROPS HAS SPECIFIC NAME FORMAT\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87db51a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 18:45:17.390650: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-17 18:45:17.390667: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59e7b63",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "This is PHOSCNET model prediction script\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cea7a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoscPipeline import * # contains phosc model \n",
    "from phos_label_generator import gen_label\n",
    "from phoc_label_generator import gen_phoc_label\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31331b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 18:45:25.598902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-17 18:45:25.599192: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-17 18:45:25.599238: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-04-17 18:45:25.599275: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-04-17 18:45:25.611621: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-04-17 18:45:25.611670: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-04-17 18:45:25.611715: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-04-17 18:45:25.611723: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-04-17 18:45:25.612333: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-17 18:45:25.914455: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 176160768 exceeds 10% of free system memory.\n",
      "2022-04-17 18:45:25.946911: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 176160768 exceeds 10% of free system memory.\n",
      "2022-04-17 18:45:25.962097: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 176160768 exceeds 10% of free system memory.\n",
      "2022-04-17 18:45:26.028966: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 176160768 exceeds 10% of free system memory.\n",
      "2022-04-17 18:45:26.062047: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 176160768 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "model=build_model()\n",
    "MODEL=\"/home/aniketag/Documents/phd/PHOSC-Zero-Shot-Word-Recognition-main/new_IAM_16_\"\n",
    "model.load_weights(MODEL+\".h5\")\n",
    "#model=tf.keras.models.load_model(MODEL+\".h5\")\n",
    "#print(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736dd7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d23e2ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    returns a dictionary having word as a key and PHOSC representation as a value \n",
    "\"\"\"\n",
    "\n",
    "def get_comb_label(x):\n",
    "    \n",
    "    phos_labels=gen_label(x)\n",
    "    phoc_labels=gen_phoc_label(x)\n",
    "    test_labels=dict()\n",
    "    \n",
    "    for x in phos_labels:\n",
    "        test_labels[x]=np.concatenate((phos_labels[x],phoc_labels[x]),axis=0)\n",
    "    \n",
    "    return test_labels\n",
    "\n",
    "#train_word_label=get_comb_label(list(set(df_lex['Word'])))\n",
    "\n",
    "def similarity(x,y):\n",
    "    return 1000*np.dot(x,y)/(LA.norm(x)*LA.norm(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99859485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f85cbde2",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "    below predict word from  image crop  image  using PHOSCNET \n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "527beb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(path2Image,test_word_label):\n",
    "    \n",
    "    x=img_to_array(load_img(path2Image))\n",
    "\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    y_pred=model.predict(x)\n",
    "    y_pred=np.squeeze(np.concatenate((y_pred[0],y_pred[1]),axis=1))\n",
    "    #print(y_pred)\n",
    "    mx=0\n",
    "    \n",
    "    for k in test_word_label:\n",
    "        temp=similarity(y_pred,test_word_label[k])\n",
    "        if temp>mx:\n",
    "            mx=temp\n",
    "            op=k\n",
    "            \n",
    "    return op,mx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbcdc82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expCount: 14187\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    gather all words corresponding to specific single image\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import re,os\n",
    "\n",
    "#images=['c04-139.png', 'g06-018r.png', 'a01-072x.png', 'h01-010.png', 'c04-050.png', 'm01-032.png', 'g06-042r.png', 'g06-026i.png', 'h07-080.png', 'e04-022.png','g06-047h.png']\n",
    "\n",
    "images=[\"m01-049.png\",\"m01-084.png\",'m01-090.png', 'm01-110.png', 'm01-049.png', 'm01-060.png', 'm01-104.png', 'm01-095.png', 'm01-121.png', 'm01-115.png', 'm01-084.png', 'm01-079.png']\n",
    "\n",
    "orgImage=images[0]\n",
    "\n",
    "testCropPath=\"./data/crop2/\" #\"./data/dataset/forms//\" #\n",
    "\n",
    "#testImgPath=\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/data/IAM_Data/\"\n",
    "\n",
    "\n",
    "def getPhoscFromText(testCropPath,orgImage):\n",
    "    \n",
    "    \"\"\"\n",
    "        input:image directory and image name containing image crops,  Image crops are expected\n",
    "        to have name with specific convention\n",
    "        \n",
    "        output: dictionary having word as key and PHOSC representation as value\n",
    "        \n",
    "        working: input contains paths to dictionary containing all crops of words present in image\n",
    "        from labels of image in folder, original word labels are extracted and from it PHOSCNET representation \n",
    "        is derived\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    allWords=[]\n",
    "\n",
    "\n",
    "    for indx,imgName in enumerate(os.listdir(testCropPath+orgImage)):\n",
    "\n",
    "        word=imgName.split(\"]_\")[1]\n",
    "        word=word.split(\"_.png\")[0]\n",
    "        word= regex.sub('', word)\n",
    "        allWords.append(word)\n",
    "\n",
    "    allWords=list(set(allWords))\n",
    "    test_word_label=get_comb_label(allWords)\n",
    "    #print(len(allWords))\n",
    "    #allWords\n",
    "    return test_word_label,allWords\n",
    "    \n",
    "    \n",
    "#test_word_label,allWords=getPhoscFromText(testCropPath,orgImage)\n",
    "#len(allWords)\n",
    "\n",
    "\n",
    "def resizeAll(resizeFolder):\n",
    "    \n",
    "    expCount=0\n",
    "    \n",
    "    for orgImage in os.listdir(resizeFolder):            \n",
    "        \n",
    "        tempFolder=os.path.join(resizeFolder,orgImage)\n",
    "        \n",
    "        if not os.path.isdir(tempFolder):\n",
    "            continue\n",
    "\n",
    "        for cropName in os.listdir(tempFolder):\n",
    "            try:\n",
    "                tempImgPath=os.path.join(tempFolder,cropName)\n",
    "\n",
    "                img=cv2.imread(tempImgPath)\n",
    "                #print(img.shape)\n",
    "                img=cv2.resize(img,(250,50))\n",
    "                cv2.imwrite(tempImgPath,img)\n",
    "                \n",
    "            except Exception as e:\n",
    "                expCount+=1\n",
    "                pass\n",
    "            \n",
    "    print(\"expCount:\",expCount)    \n",
    "\n",
    "#resizeAll(testCropPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df6250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28286657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " orgImage: m01-049.png\n",
      " File found!! .//data/dataset/forms//m01-049.png\n",
      " original image name: m01-049.png  original image shape: (3542, 2479, 3)\n",
      "\n",
      "cropName: m01-049.png_108_[1639, 1817, 1812, 1912]_himself_.png\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "predict() missing 1 required positional argument: 'test_word_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7489/1089442933.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m#imgName=imgName.split(\"_\")[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mpredWord\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestCropPath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcropName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m#print(\" word:\",word,\" \",predWord,\" score:\",score,\" coordinate:\",x1,y1,x2,y2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'test_word_label'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    DONT USE!!!\n",
    "\n",
    "    below part takes input single crop folder name and image name as a input\n",
    "    and perform PHOSC prediction on it, It also plots the prediction on\n",
    "    original image\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "\n",
    "testImgPath=\".//data/dataset/forms//\" \n",
    "testCropPath=\"./data/crops//\"+orgImage+\"//\"\n",
    "savePath=\"/data//cropPHOSCVisual2//\"\n",
    "\n",
    "print(\" orgImage:\",orgImage)\n",
    "\n",
    "if not os.path.isfile(testImgPath+orgImage):\n",
    "    print(\" File not present!!!\")\n",
    "else:\n",
    "    print(\" File found!!\",testImgPath+orgImage)\n",
    "\n",
    "    image=cv2.imread(testImgPath+orgImage)\n",
    "    print(\" original image name:\",orgImage,\" original image shape:\",image.shape)\n",
    "\n",
    "matchCount=0\n",
    "missMatch=0\n",
    "\n",
    "for indx,cropName in enumerate(os.listdir(testCropPath)):\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"cropName:\",cropName)\n",
    "    word=cropName.split(\"]_\")[1]\n",
    "    word=word.split(\"_.png\")[0]\n",
    "    word= regex.sub('', word)\n",
    "    \n",
    "    if len(word)<2: # skip \n",
    "        continue\n",
    "    \n",
    "    cor=cropName.split(\"[\")[1]\n",
    "    cor=cor.split(\"]\")[0]\n",
    "    cor=\"[\"+cor+\"]\"\n",
    "    cor=eval(cor)\n",
    "    \n",
    "    x1,y1,x2,y2=int(cor[0]),int(cor[1]),int(cor[2]),int(cor[3])\n",
    "        \n",
    "    #imgName=imgName.split(\"_\")[0]\n",
    "    \n",
    "    predWord,score=predict(testCropPath+cropName)\n",
    "    \n",
    "    #print(\" word:\",word,\" \",predWord,\" score:\",score,\" coordinate:\",x1,y1,x2,y2)\n",
    "    \n",
    "    if word==predWord:\n",
    "        #cv2.putText(image,word, (x1,y1-10), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n",
    "        image = cv2.rectangle(image, (x1, y1), (x2, y2),(0,255,0), 3)\n",
    "        #cv2.putText(image,predWord, (x1,y2+50), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n",
    "        matchCount+=1\n",
    "    else:\n",
    "        \n",
    "        cv2.putText(image,word, (x1,y1-10), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n",
    "        image = cv2.rectangle(image, (x1, y1), (x2, y2),(0,0,255), 3)\n",
    "        cv2.putText(image,predWord, (x1,y2+50), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n",
    "        missMatch+=1\n",
    "    \n",
    "\n",
    "cv2.putText(image,str([matchCount,missMatch,matchCount/(matchCount+missMatch)]), (15,100), cv2.FONT_HERSHEY_SIMPLEX, 3, 255)\n",
    "cv2.imwrite(savePath+orgImage,image)\n",
    "\n",
    "print(\"match\",matchCount)\n",
    "print(\"miss match:\",missMatch)\n",
    "print(\" Accuracy:\",matchCount/(matchCount+missMatch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1769953",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "    below code predicts PHOSC and visualizes all the image present in testCrop folder \n",
    "    to add more images into it changes are required in file \n",
    "    mnist_testYolo.txt which is in yolo prediction script\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d99d93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " images: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7489/215380575.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1000*np.dot(x,y)/(LA.norm(x)*LA.norm(y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match 50\n",
      "miss match: 32\n",
      " Accuracy: 0.6097560975609756\n",
      "match 29\n",
      "miss match: 54\n",
      " Accuracy: 0.3493975903614458\n",
      "match 54\n",
      "miss match: 16\n",
      " Accuracy: 0.7714285714285715\n",
      "match 47\n",
      "miss match: 49\n",
      " Accuracy: 0.4895833333333333\n",
      "match 50\n",
      "miss match: 39\n",
      " Accuracy: 0.5617977528089888\n",
      "match 59\n",
      "miss match: 34\n",
      " Accuracy: 0.6344086021505376\n",
      "match 47\n",
      "miss match: 82\n",
      " Accuracy: 0.3643410852713178\n",
      "match 58\n",
      "miss match: 36\n",
      " Accuracy: 0.6170212765957447\n",
      "match 41\n",
      "miss match: 31\n",
      " Accuracy: 0.5694444444444444\n",
      "match 63\n",
      "miss match: 32\n",
      " Accuracy: 0.6631578947368421\n",
      "match 65\n",
      "miss match: 42\n",
      " Accuracy: 0.6074766355140186\n",
      "match 63\n",
      "miss match: 47\n",
      " Accuracy: 0.5727272727272728\n",
      "match 35\n",
      "miss match: 72\n",
      " Accuracy: 0.32710280373831774\n",
      "match 46\n",
      "miss match: 29\n",
      " Accuracy: 0.6133333333333333\n",
      "match 60\n",
      "miss match: 44\n",
      " Accuracy: 0.5769230769230769\n",
      "match 55\n",
      "miss match: 64\n",
      " Accuracy: 0.46218487394957986\n",
      "match 37\n",
      "miss match: 53\n",
      " Accuracy: 0.4111111111111111\n",
      "match 36\n",
      "miss match: 46\n",
      " Accuracy: 0.43902439024390244\n",
      "match 38\n",
      "miss match: 58\n",
      " Accuracy: 0.3958333333333333\n",
      "match 37\n",
      "miss match: 40\n",
      " Accuracy: 0.4805194805194805\n",
      "match 34\n",
      "miss match: 50\n",
      " Accuracy: 0.40476190476190477\n",
      "match 47\n",
      "miss match: 63\n",
      " Accuracy: 0.42727272727272725\n",
      "match 59\n",
      "miss match: 43\n",
      " Accuracy: 0.5784313725490197\n",
      "match 74\n",
      "miss match: 79\n",
      " Accuracy: 0.48366013071895425\n",
      "match 48\n",
      "miss match: 40\n",
      " Accuracy: 0.5454545454545454\n",
      "match 53\n",
      "miss match: 41\n",
      " Accuracy: 0.5638297872340425\n",
      "match 53\n",
      "miss match: 55\n",
      " Accuracy: 0.49074074074074076\n",
      "match 62\n",
      "miss match: 45\n",
      " Accuracy: 0.5794392523364486\n",
      "match 77\n",
      "miss match: 54\n",
      " Accuracy: 0.5877862595419847\n",
      "match 37\n",
      "miss match: 58\n",
      " Accuracy: 0.3894736842105263\n",
      "match 40\n",
      "miss match: 31\n",
      " Accuracy: 0.5633802816901409\n",
      "match 54\n",
      "miss match: 51\n",
      " Accuracy: 0.5142857142857142\n",
      "match 48\n",
      "miss match: 69\n",
      " Accuracy: 0.41025641025641024\n",
      "match 51\n",
      "miss match: 33\n",
      " Accuracy: 0.6071428571428571\n",
      "match 48\n",
      "miss match: 62\n",
      " Accuracy: 0.43636363636363634\n",
      "match 67\n",
      "miss match: 41\n",
      " Accuracy: 0.6203703703703703\n",
      "match 84\n",
      "miss match: 64\n",
      " Accuracy: 0.5675675675675675\n",
      "match 50\n",
      "miss match: 25\n",
      " Accuracy: 0.6666666666666666\n",
      "match 40\n",
      "miss match: 41\n",
      " Accuracy: 0.49382716049382713\n",
      "match 55\n",
      "miss match: 55\n",
      " Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    gather all words\n",
    "    \n",
    "\"\"\"\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import re\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "\n",
    "images=['m01-090.png', 'm01-110.png', 'm01-049.png', 'm01-060.png', 'm01-104.png', 'm01-095.png', 'm01-121.png', 'm01-115.png', 'm01-084.png', 'm01-079.png']\n",
    "#images=['m01-084.png']\n",
    "\n",
    "#orgImage=images[0]\n",
    "\n",
    "testImgPath=\".//data/dataset/forms//\" #\"/home/aniketag/Documents/phd/yolov5/data/datasets/forms/m01-084.png\"\n",
    "#testImgPath=\"/home/aniketag/Documents/phd/yolov5/data/datasets/forms//\" \n",
    "\n",
    "testCropPath=\"./data//crops//\"\n",
    "\n",
    "images=os.listdir(testCropPath)\n",
    "\n",
    "savePath=\".//data/cropPHOSCVisual//\"\n",
    "\n",
    "print(\" images:\",images[0] in os.listdir(testImgPath))\n",
    "\n",
    "    \n",
    "for orgImage in images:\n",
    "    \n",
    "    try:\n",
    "        matchCount=0\n",
    "        missMatch=0\n",
    "        testCropPath=\"./data//crops//\"\n",
    "\n",
    "        if not os.path.isdir(os.path.join(testCropPath,orgImage)):\n",
    "            continue\n",
    "\n",
    "        test_word_label,allWords=getPhoscFromText(testCropPath,orgImage)\n",
    "\n",
    "        testCropPath=testCropPath+orgImage+\"//\"\n",
    "\n",
    "        if os.path.isfile(savePath+orgImage+\"_singleDict_.png\"):\n",
    "            continue\n",
    "\n",
    "        #print(\" imageName:\",orgImage,\" No of unique words:\",len(allWords),\" is file:\",os.path.isfile(testImgPath+orgImage))\n",
    "\n",
    "        image=cv2.imread(testImgPath+orgImage)\n",
    "        #print(\" original image shape:\",image.shape)\n",
    "\n",
    "        df=pd.DataFrame(index=range(200),columns=[\"image_name\",\"crop_name\",\"original_word\",\"predicted_word\"])   \n",
    "\n",
    "\n",
    "        for indx,cropImgName in enumerate(os.listdir(testCropPath)):\n",
    "\n",
    "            #print(\" cropImgName:\",cropImgName)\n",
    "\n",
    "            #temp=pd.DataFrame(columns=[\"image_name\",\"crop_name\",\"original_word\",\"predicted_word\"]\n",
    "\n",
    "            word=cropImgName.split(\"]_\")[1]\n",
    "            word=word.split(\"_.png\")[0]\n",
    "\n",
    "            cor=cropImgName.split(\"[\")[1]\n",
    "            cor=cor.split(\"]\")[0]\n",
    "            cor=\"[\"+cor+\"]\"\n",
    "            cor=eval(cor)\n",
    "\n",
    "            x1,y1,x2,y2=int(cor[0]),int(cor[1]),int(cor[2]),int(cor[3])\n",
    "\n",
    "            #imgName=imgName.split(\"_\")[0]\n",
    "\n",
    "            predWord,score=predict(testCropPath+cropImgName,test_word_label)\n",
    "\n",
    "            #print(\" word:\",word,\" \",predWord,\" score:\",score,\" coordinate:\",x1,y1,x2,y2,)\n",
    "            #print(\"\")\n",
    "\n",
    "            df.loc[indx,\"image_name\"]=orgImage\n",
    "            df.loc[indx,\"crop_name\"]=cropImgName\n",
    "            df.loc[indx,\"original_word\"]=word\n",
    "            df.loc[indx,\"predicted_word\"]=predWord        \n",
    "\n",
    "            if word==predWord:\n",
    "                #cv2.putText(image,word, (x1,y1-10), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n",
    "                image = cv2.rectangle(image, (x1, y1), (x2, y2),(0,255,0), 3)\n",
    "                #cv2.putText(image,predWord, (x1,y2+50), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n",
    "                matchCount+=1\n",
    "            else:\n",
    "\n",
    "                cv2.putText(image,word, (x1,y1-10), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n",
    "                image = cv2.rectangle(image, (x1, y1), (x2, y2),(0,0,255), 3)\n",
    "                cv2.putText(image,predWord, (x1,y2+50), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n",
    "                missMatch+=1\n",
    "\n",
    "\n",
    "        print(\"match\",matchCount)\n",
    "        print(\"miss match:\",missMatch)\n",
    "        print(\" Accuracy:\",matchCount/(matchCount+missMatch))\n",
    "\n",
    "        cv2.putText(image,str([matchCount,missMatch,matchCount/(matchCount+missMatch)]), (15,100), cv2.FONT_HERSHEY_SIMPLEX, 3, 255)\n",
    "        cv2.imwrite(savePath+orgImage+\"_singleDictResize_.png\",image)\n",
    "        #df.to_csv(savePath+orgImage+\"_singleDict_.csv\")\n",
    "\n",
    "        #input(\"check!!!\")\n",
    "    except Exception as e:\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e80e4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa4257bd",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "                    BATCH VISUALIZATION\n",
    "\n",
    "    BELOW PART CAN BE USED TO VISUALIZE THE PERFORMANCE OF ORIGINAL CROPS,\n",
    "    REQUIRED CROPS ARE TAKEN FROM PHOSCNET TRAINING DATA.\n",
    "    THE CROP NAMES DOES NOT INCLUDE WORDS PRESENT INSIDE IT OR COORDINATE TO HANDLE IT\n",
    "    CSV data_444_april.csv IS USED WHICH HAS REQUIRED INFORMATION\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59bff8e",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "    1. Select test image_name from data_444*.csv and fetch all records related to that.\n",
    "    \n",
    "    2. From fetched records get BB and text of location IE create a new dataframe which has BB and corresponding text\n",
    "    * there is difference between image name and crop name\n",
    "    \n",
    "    3. From PHOSCNET test data separate all crops corresponding to above recods and create a separate folder for it,\n",
    "    here we have only Image name from 1,2 but not corresponding crop name so we need to derive\n",
    "    it with string matching.\n",
    "    \n",
    "    Get the PHOSC vector space for all word labels present in speecific image\n",
    "    \n",
    "    4. Pass those crop to PHOSCNET get prediction and visualize it..\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48bb7a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "\n",
    "\"\"\"\n",
    "    allPaths\n",
    "\"\"\"\n",
    "\n",
    "csvFile=\"./data/dataset/data_12_april.csv\"\n",
    "phoscTestImgPath=\"./data//phoscTest//\"\n",
    "allPhoscTestCrops=\"./data/IAM_Data/IAM_test/\"\n",
    "#PhoscOrgTestCrops=\"./crop2//\"\n",
    "PhoscOrgTestCrops=\"./cropPHOSCVisual3//\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19ab471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1,2.\n",
    "    input: image name for which BB,Text records are needed\n",
    "    output: dataframe with relevant information\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "def fetchRecord(df,imageName):\n",
    "    \n",
    "    temp=df[df[\"image_name\"]==imageName]\n",
    "    #print(\" No of records:\",temp.shape)\n",
    "    return temp\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "3.\n",
    "    crops corresponding to specific image file\n",
    "    a. get list of all crops used for PHOSCNET testing\n",
    "    b. filter crops necessary for specific image file\n",
    "    \n",
    "\"\"\"\n",
    "from shutil import copy2\n",
    "\n",
    "def filterCrop(allCropList,imageName):\n",
    "    \n",
    "    imgCropList=[]\n",
    "    \n",
    "    imageName=imageName.split(\".png\")[0]\n",
    "    \n",
    "    cropPhoscTestData=\"./data/cropPhoscTestData//\"\n",
    "    basePhoscData=\"./data//IAM_Data/IAM_test//\"\n",
    "    \n",
    "    for cropName in allCropList:\n",
    "        \n",
    "        if imageName in cropName:\n",
    "            \n",
    "            imgCropList.append(cropName)\n",
    "\n",
    "    print(\" TOTAL CROPS CORRESPONDING TO IMAGE \"+imageName+\" ARE:\",len(imgCropList))\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        os.mkdir(cropPhoscTestData+imageName)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    for filterCropName in imgCropList:\n",
    "        copy2(basePhoscData+filterCropName,cropPhoscTestData+imageName)\n",
    "        \n",
    "        \n",
    "    print(\" transferred crop:\",len(cropPhoscTestData+imageName)) \n",
    "        \n",
    "    return imgCropList\n",
    "\n",
    "#imageName=\"m01-125.png\"\n",
    "#allCropList=os.listdir(allPhoscTestCrops)\n",
    "#mgCropList=filterCrop(allCropList,imageName)\n",
    "#imgCropList\n",
    "\n",
    "def getPhoscFromDF(df):\n",
    "    \n",
    "    \"\"\"\n",
    "        input: Dataframe containing all image information like text,coordinate etc.\n",
    "        output: dictionary having word as key and PHOSC representation as value\n",
    "        \n",
    "        working: similar to getPhoscFromText()\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    allWords=[]\n",
    "\n",
    "\n",
    "    for indx,row in df.iterrows():\n",
    "\n",
    "        word=row[\"text\"]\n",
    "        word= regex.sub('', word)\n",
    "        allWords.append(word)\n",
    "\n",
    "    allWords=list(set(allWords))\n",
    "    test_word_label=get_comb_label(allWords)\n",
    "    print(len(allWords))\n",
    "    #allWords\n",
    "    return test_word_label,allWords\n",
    "\n",
    "#imageName=\"m01-084.png\"\n",
    "#temp=fetchRecord(df1,imageName)\n",
    "#temp.columns\n",
    "#test_word_label=getPhoscFromDF(temp)\n",
    "#temp.head(5)\n",
    "\n",
    "\"\"\"\n",
    "    save crops from original coordinates\n",
    "    As there is no way to map PHOSCNET test data crops to original image \n",
    "    \n",
    "    below function extracts crops from original image, \n",
    "    The crops are saved in following format ImgName.png_IndexNumber_[x1,y1, x2, y2]_textString_.png\n",
    "    \n",
    "    The crop coordinate are from original dataset It is not predicted by YOLOV3\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "def PhoscOrgCrops(df,imgName):\n",
    "    \n",
    "    image=cv2.imread(phoscTestImgPath+imgName)\n",
    "    \n",
    "    #print(image.shape)\n",
    "    \n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(PhoscOrgTestCrops+imgName)\n",
    "    \n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    for indx,row in df.iterrows():\n",
    "        #print(row)\n",
    "        word=row[\"text\"]\n",
    "        word= regex.sub('', word)\n",
    "        \n",
    "        if len(word)<2:\n",
    "            continue\n",
    "\n",
    "        x1,y1,x2,y2=row[\"org_x1\"],row[\"org_y1\"],row[\"org_x2\"],row[\"org_y2\"]\n",
    "        \n",
    "        tempName=imgName+\"_\"+str(indx)+\"_\"+str([x1,y1,x2,y2])+\"_\"+word+\".png\"\n",
    "        \n",
    "        cropImage=image[y1:y2,x1:x2]\n",
    "        #print(cropImage.shape)\n",
    "\n",
    "        cv2.imwrite(PhoscOrgTestCrops+imgName+\"//\"+tempName,cropImage)\n",
    "        \n",
    "\n",
    "\n",
    "#PhoscOrgCrops(temp,imageName)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7689089",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "    BELOW PART PROJECTS RESULTS FROM ORIGINAL CROPS..\n",
    "    \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e75289c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " images: True\n",
      "48\n",
      " imageName: m01-131.png  No of unique words: 48  # crops: 62  is file: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35523/215380575.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1000*np.dot(x,y)/(LA.norm(x)*LA.norm(y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match 32\n",
      "miss match: 30\n",
      " Accuracy: 0.5161290322580645\n",
      "45\n",
      " imageName: m02-075.png  No of unique words: 45  # crops: 58  is file: True\n",
      "match 19\n",
      "miss match: 39\n",
      " Accuracy: 0.3275862068965517\n",
      "43\n",
      " imageName: m02-112.png  No of unique words: 43  # crops: 50  is file: True\n",
      "match 36\n",
      "miss match: 14\n",
      " Accuracy: 0.72\n",
      "52\n",
      " imageName: m01-136.png  No of unique words: 52  # crops: 69  is file: True\n",
      "match 28\n",
      "miss match: 41\n",
      " Accuracy: 0.4057971014492754\n",
      "51\n",
      " imageName: m03-062.png  No of unique words: 51  # crops: 64  is file: True\n",
      "match 32\n",
      "miss match: 32\n",
      " Accuracy: 0.5\n",
      "50\n",
      " imageName: m01-060.png  No of unique words: 50  # crops: 66  is file: True\n",
      "match 39\n",
      "miss match: 27\n",
      " Accuracy: 0.5909090909090909\n",
      "73\n",
      " imageName: m02-069.png  No of unique words: 73  # crops: 94  is file: True\n",
      "match 22\n",
      "miss match: 72\n",
      " Accuracy: 0.23404255319148937\n",
      "53\n",
      " imageName: m01-115.png  No of unique words: 53  # crops: 71  is file: True\n",
      "match 44\n",
      "miss match: 27\n",
      " Accuracy: 0.6197183098591549\n",
      "42\n",
      " imageName: m01-160.png  No of unique words: 42  # crops: 49  is file: True\n",
      "match 25\n",
      "miss match: 24\n",
      " Accuracy: 0.5102040816326531\n",
      "57\n",
      " imageName: m01-125.png  No of unique words: 57  # crops: 76  is file: True\n",
      "match 47\n",
      "miss match: 29\n",
      " Accuracy: 0.618421052631579\n",
      "59\n",
      " imageName: m01-121.png  No of unique words: 59  # crops: 70  is file: True\n",
      "match 40\n",
      "miss match: 30\n",
      " Accuracy: 0.5714285714285714\n",
      "63\n",
      " imageName: m03-006.png  No of unique words: 63  # crops: 81  is file: True\n",
      "match 47\n",
      "miss match: 34\n",
      " Accuracy: 0.5802469135802469\n",
      "58\n",
      " imageName: m01-090.png  No of unique words: 58  # crops: 80  is file: True\n",
      "match 26\n",
      "miss match: 54\n",
      " Accuracy: 0.325\n",
      "47\n",
      " imageName: m03-020.png  No of unique words: 47  # crops: 63  is file: True\n",
      "match 32\n",
      "miss match: 31\n",
      " Accuracy: 0.5079365079365079\n",
      "54\n",
      " imageName: m02-102.png  No of unique words: 54  # crops: 74  is file: True\n",
      "match 45\n",
      "miss match: 29\n",
      " Accuracy: 0.6081081081081081\n",
      "62\n",
      " imageName: m02-106.png  No of unique words: 62  # crops: 88  is file: True\n",
      "match 46\n",
      "miss match: 42\n",
      " Accuracy: 0.5227272727272727\n",
      "53\n",
      " imageName: m02-059.png  No of unique words: 53  # crops: 63  is file: True\n",
      "match 28\n",
      "miss match: 35\n",
      " Accuracy: 0.4444444444444444\n",
      "50\n",
      " imageName: m02-052.png  No of unique words: 50  # crops: 60  is file: True\n",
      "match 21\n",
      "miss match: 39\n",
      " Accuracy: 0.35\n",
      "58\n",
      " imageName: m02-095.png  No of unique words: 58  # crops: 74  is file: True\n",
      "match 28\n",
      "miss match: 46\n",
      " Accuracy: 0.3783783783783784\n",
      "48\n",
      " imageName: m03-013.png  No of unique words: 48  # crops: 63  is file: True\n",
      "match 25\n",
      "miss match: 38\n",
      " Accuracy: 0.3968253968253968\n",
      "47\n",
      " imageName: m03-033.png  No of unique words: 47  # crops: 66  is file: True\n",
      "match 26\n",
      "miss match: 40\n",
      " Accuracy: 0.3939393939393939\n",
      "55\n",
      " imageName: m02-072.png  No of unique words: 55  # crops: 70  is file: True\n",
      "match 27\n",
      "miss match: 43\n",
      " Accuracy: 0.38571428571428573\n",
      "56\n",
      " imageName: m02-055.png  No of unique words: 56  # crops: 75  is file: True\n",
      "match 39\n",
      "miss match: 36\n",
      " Accuracy: 0.52\n",
      "70\n",
      " imageName: m02-048.png  No of unique words: 70  # crops: 100  is file: True\n",
      "match 41\n",
      "miss match: 59\n",
      " Accuracy: 0.41\n",
      "47\n",
      " imageName: m01-079.png  No of unique words: 47  # crops: 52  is file: True\n",
      "match 28\n",
      "miss match: 24\n",
      " Accuracy: 0.5384615384615384\n",
      "49\n",
      " imageName: m01-095.png  No of unique words: 49  # crops: 61  is file: True\n",
      "match 30\n",
      "miss match: 31\n",
      " Accuracy: 0.4918032786885246\n",
      "64\n",
      " imageName: m01-149.png  No of unique words: 64  # crops: 83  is file: True\n",
      "match 43\n",
      "miss match: 40\n",
      " Accuracy: 0.5180722891566265\n",
      "57\n",
      " imageName: m01-104.png  No of unique words: 57  # crops: 75  is file: True\n",
      "match 42\n",
      "miss match: 33\n",
      " Accuracy: 0.56\n",
      "78\n",
      " imageName: m02-083.png  No of unique words: 78  # crops: 108  is file: True\n",
      "match 57\n",
      "miss match: 51\n",
      " Accuracy: 0.5277777777777778\n",
      "61\n",
      " imageName: m02-109.png  No of unique words: 61  # crops: 69  is file: True\n",
      "match 23\n",
      "miss match: 46\n",
      " Accuracy: 0.3333333333333333\n",
      "46\n",
      " imageName: m01-084.png  No of unique words: 46  # crops: 56  is file: True\n",
      "match 26\n",
      "miss match: 30\n",
      " Accuracy: 0.4642857142857143\n",
      "63\n",
      " imageName: m03-114.png  No of unique words: 63  # crops: 77  is file: True\n",
      "match 39\n",
      "miss match: 38\n",
      " Accuracy: 0.5064935064935064\n",
      "53\n",
      " imageName: m03-110.png  No of unique words: 53  # crops: 82  is file: True\n",
      "match 35\n",
      "miss match: 47\n",
      " Accuracy: 0.4268292682926829\n",
      "49\n",
      " imageName: m02-087.png  No of unique words: 49  # crops: 67  is file: True\n",
      "match 31\n",
      "miss match: 36\n",
      " Accuracy: 0.4626865671641791\n",
      "56\n",
      " imageName: m01-049.png  No of unique words: 56  # crops: 75  is file: True\n",
      "match 33\n",
      "miss match: 42\n",
      " Accuracy: 0.44\n",
      "59\n",
      " imageName: m02-080.png  No of unique words: 59  # crops: 71  is file: True\n",
      "match 42\n",
      "miss match: 29\n",
      " Accuracy: 0.5915492957746479\n",
      "79\n",
      " imageName: m02-090.png  No of unique words: 79  # crops: 107  is file: True\n",
      "match 54\n",
      "miss match: 53\n",
      " Accuracy: 0.5046728971962616\n",
      "45\n",
      " imageName: m03-095.png  No of unique words: 45  # crops: 56  is file: True\n",
      "match 38\n",
      "miss match: 18\n",
      " Accuracy: 0.6785714285714286\n",
      "48\n",
      " imageName: m02-066.png  No of unique words: 48  # crops: 58  is file: True\n",
      "match 25\n",
      "miss match: 33\n",
      " Accuracy: 0.43103448275862066\n",
      "59\n",
      " imageName: m01-110.png  No of unique words: 59  # crops: 85  is file: True\n",
      "match 34\n",
      "miss match: 51\n",
      " Accuracy: 0.4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    here\n",
    "    gather all words\n",
    "\"\"\"\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "\n",
    "#images=['m01-090.png', 'm01-110.png', 'm01-049.png', 'm01-060.png', 'm01-104.png', 'm01-095.png', 'm01-121.png', 'm01-115.png', 'm01-084.png', 'm01-079.png']\n",
    "\n",
    "#PhoscOrgTestCrops=\"./data//cropPhoscTestData2//\"# crops_yolo3\n",
    "\n",
    "#PhoscOrgTestCrops=\"./data//crops_yolo3//\"# crops_nms\n",
    "PhoscOrgTestCrops=\"./data//crops_nms2//\"\n",
    "\n",
    "\n",
    "availableCropsImg=os.listdir(PhoscOrgTestCrops)\n",
    "\n",
    "images=os.listdir(phoscTestImgPath)\n",
    "\n",
    "savePath=\"./data//cropPHOSCVisual3//\"\n",
    "testImgPath=\".//data/dataset/forms//\" \n",
    "print(\" images:\",images[0] in os.listdir(testImgPath))\n",
    "\n",
    "allCropList=os.listdir(allPhoscTestCrops)\n",
    "\n",
    "df1=pd.read_csv(\"./data/dataset/data_14_april.csv\")\n",
    "\n",
    "\n",
    "for imgNumber,orgImage in enumerate(images):\n",
    "    \n",
    "    try:\n",
    "        #print(\"\")\n",
    "        \n",
    "        \"\"\"\n",
    "        if os.path.isfile(savePath+orgImage+\"_originalCrops_.png\"):\n",
    "            continue\n",
    "        \"\"\" \n",
    "        \"\"\"\n",
    "        if os.path.isfile(savePath+orgImage+\"_originalTest_.png\"):\n",
    "            continue\n",
    "        \"\"\"\n",
    "        if os.path.isfile(savePath+orgImage+\"_yolo3Crops_.png\"):\n",
    "            continue\n",
    "\n",
    "            \n",
    "        if not orgImage in availableCropsImg:\n",
    "            continue\n",
    "            \n",
    "        matchCount=0\n",
    "        missMatch=0\n",
    "        \n",
    "        #PhoscOrgTestCrops=\"./data//cropPhoscTestData3//\"\n",
    "        #PhoscOrgTestCrops=\"./data//crops_yolo3//\"# \n",
    "        PhoscOrgTestCrops=\"./data//crops_nms2//\"\n",
    "        #PhoscOrgTestCrops=\"./data//crop2//\"\n",
    "\n",
    "        \n",
    "        temp=fetchRecord(df1,orgImage) # get relevant records\n",
    "\n",
    "        #PhoscOrgCrops(temp,orgImage) # create crops\n",
    "        \n",
    "        if 0:\n",
    "            filterCrop(allCropList,orgImage)\n",
    "        \n",
    "        #test_word_label,allWords=getPhoscFromText(PhoscOrgTestCrops,orgImage) # get attribute space\n",
    "\n",
    "        test_word_label,allWords=getPhoscFromDF(temp)\n",
    "        \n",
    "        if os.path.isdir(PhoscOrgTestCrops+orgImage+\"//\"):\n",
    "            PhoscOrgTestCrops=PhoscOrgTestCrops+orgImage+\"//\"\n",
    "        else:\n",
    "            PhoscOrgTestCrops=PhoscOrgTestCrops+orgImage[:-4]+\"//\"            \n",
    "        \n",
    "        noTestCrops=len(os.listdir(PhoscOrgTestCrops))\n",
    "        \n",
    "        #print(\" imageName:\",orgImage,\" No of unique words:\",len(allWords),\" is file:\",os.path.isfile(testImgPath+orgImage))\n",
    "\n",
    "        print(\" imageName:\",orgImage,\" No of unique words:\",len(test_word_label.keys()),\" # crops:\",noTestCrops,\" is file:\",os.path.isfile(phoscTestImgPath+orgImage))\n",
    "\n",
    "\n",
    "        image=cv2.imread(phoscTestImgPath+orgImage)\n",
    "        #print(\" original image shape:\",image.shape)\n",
    "    \n",
    "        \n",
    "        df=pd.DataFrame(index=range(200),columns=[\"image_name\",\"crop_name\",\"original_word\",\"predicted_word\"])   \n",
    "\n",
    "        for indx,cropImgName in enumerate(os.listdir(PhoscOrgTestCrops)):\n",
    "\n",
    "            #print(\" cropImgName:\",cropImgName)\n",
    "\n",
    "            #temp=pd.DataFrame(columns=[\"image_name\",\"crop_name\",\"original_word\",\"predicted_word\"]\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                word=cropImgName.split(\"]_\")[1]\n",
    "                word=word.split(\".png\")[0]\n",
    "\n",
    "                cor=cropImgName.split(\"[\")[1]\n",
    "                cor=cor.split(\"]\")[0]\n",
    "                cor=\"[\"+cor+\"]\"\n",
    "                cor=eval(cor)\n",
    "                \n",
    "            except Exception as e:\n",
    "                tempCropName=cropImgName[:-4]\n",
    "                tempRow=df1[df1[\"cropName\"]==tempCropName]\n",
    "                #print(\"\")\n",
    "                #print(\"\\n tempRow \\n \",tempRow)\n",
    "                #print(\"\")\n",
    "\n",
    "                word=tempRow.text.values[0]\n",
    "                cor=[tempRow.org_x1.values,tempRow.org_y1.values,tempRow.org_x2.values,tempRow.org_y2.values]\n",
    "                #input(\" check row\")\n",
    "                \n",
    "                #print(\" word=\",word)\n",
    "                #print(\" cor=\",cor)\n",
    "                #print(\" cropImgName:\",cropImgName)\n",
    "                \n",
    "                \n",
    "                \n",
    "            x1,y1,x2,y2=int(cor[0]),int(cor[1]),int(cor[2]),int(cor[3])\n",
    "            \n",
    "            #imgName=imgName.split(\"_\")[0]\n",
    "            \n",
    "            try:\n",
    "                predWord,score=predict(PhoscOrgTestCrops+cropImgName,test_word_label)\n",
    "            except Exception as e:\n",
    "                \n",
    "                predWord=\"\"\n",
    "                \n",
    "            #print(\"\\n word:\",word,\"-->\",predWord,\" score:\",score,\" coordinate:\",x1,y1,x2,y2,\" \\n cropImgName:\",cropImgName)\n",
    "            #predWord=predWord[:-3]\n",
    "            \n",
    "            try:\n",
    "                df.loc[indx,\"image_name\"]=orgImage\n",
    "                df.loc[indx,\"crop_name\"]=cropImgName\n",
    "                df.loc[indx,\"original_word\"]=word\n",
    "                df.loc[indx,\"predicted_word\"]=predWord        \n",
    "            except Exception as e:\n",
    "                exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "                fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "                print(\" line number:\", exc_tb.tb_lineno, \" e:\",e)\n",
    "            \n",
    "            if word[:-1]==predWord:\n",
    "                #cv2.putText(image,word, (x1,y1-10), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n",
    "                image = cv2.rectangle(image, (x1, y1), (x2, y2),(0,255,0), 4)\n",
    "                #cv2.putText(image,predWord, (x1,y2+50), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n",
    "                matchCount+=1\n",
    "            else:\n",
    "\n",
    "                cv2.putText(image,predWord, (x1,y1-10), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n",
    "                image = cv2.rectangle(image, (x1, y1), (x2, y2),(0,0,255), 3)\n",
    "                cv2.putText(image,word, (x1,y2+50), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n",
    "                missMatch+=1\n",
    "                #cv2.imwrite(savePath+orgImage+\"_originalTest_.png\",image)\n",
    "\n",
    "                #input(\" missmatch!!!\")\n",
    "\n",
    "\n",
    "        print(\"match\",matchCount)\n",
    "        print(\"miss match:\",missMatch)\n",
    "        print(\" Accuracy:\",matchCount/(matchCount+missMatch))\n",
    "\n",
    "        cv2.putText(image,str([matchCount,missMatch,matchCount/(matchCount+missMatch)]), (15,100), cv2.FONT_HERSHEY_SIMPLEX, 3, 255)\n",
    "        #cv2.imwrite(savePath+orgImage+\"_originalTest_.png\",image)\n",
    "        #df.to_csv(savePath+orgImage+\"_originalTest_.csv\")\n",
    "        \n",
    "        cv2.imwrite(savePath+orgImage+\"_yolo33Crops_.png\",image)\n",
    "        #df.to_csv(savePath+orgImage+\"_yolo2C33333rops_.csv\")\n",
    "\n",
    "        \n",
    "            \n",
    "    except Exception as e1:\n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "        print(\" line number:\", exc_tb.tb_lineno, \" e:\",e1)\n",
    "        \n",
    "    #input(\"check!!!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec7edd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037e84b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c2e847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
