{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d9bac8",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "    \n",
    "    '{06-2022-3-2}'\n",
    "    \n",
    "    This will convert IAM data into toy training data\n",
    "    \n",
    "    \n",
    "    The requirment in experiment '{05-2022-28-1}' were changed so this is new \n",
    "    \n",
    "    experimtn continuation of it\n",
    "    \n",
    "    \n",
    "    It has following words coordinates\n",
    "    \n",
    "    \n",
    "    {'the': 0,\n",
    "     'of': 1,\n",
    "     'to': 2,\n",
    "     'and': 3,\n",
    "     'in': 4,\n",
    "     'was': 5,\n",
    "     'that': 6,\n",
    "     'is': 7,\n",
    "     'he': 8,\n",
    "     'for': 9,\n",
    "     'with': 10,\n",
    "     'his': 11,\n",
    "     'it': 12,\n",
    "     'which': 13,\n",
    "     'they': 14,\n",
    "     'from': 15,\n",
    "     'are': 16,\n",
    "     'been': 17,\n",
    "     'you': 18,\n",
    "     'this': 19}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74991e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t unique: 1539\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9975e04",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "    \n",
    "    \n",
    "    #filter out only images which are into train split of IAM handwritten.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "debee39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " total png gathered: 747  original lines: 6161 unique lines: 6161\n",
      " train len: 747\n",
      " trainLines len: 6161\n",
      " total png gathered: 232  original lines: 1861 unique lines: 1861\n",
      " total png gathered: 105  original lines: 900 unique lines: 900\n",
      " total png gathered: 115  original lines: 940 unique lines: 940\n",
      " test len: 232\n",
      " testLines len: 1861\n",
      " valid len: 220\n",
      " valLines len: 1840\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "splitFilePath=\"./data/largeWriterIndependentTextLineRecognitionTask\"\n",
    "\n",
    "#os.listdir(splitFilePath)\n",
    "\n",
    "trainFile=os.path.join(splitFilePath, 'trainset.txt')\n",
    "testFile=os.path.join(splitFilePath,'testset.txt')\n",
    "validFile1=os.path.join(splitFilePath,'validationset1.txt')\n",
    "validFile2=os.path.join(splitFilePath,'validationset2.txt')\n",
    "\n",
    "\"\"\"\n",
    "    below function takes the line number and finds to which original image it \n",
    "    belongs, this image split will help to identify yolo train,test,valid data\n",
    "    \n",
    "\"\"\"\n",
    "def gatherFormInOfficialSplitForYolo(temp):\n",
    "\n",
    "    formsPath=\"/home/aniketag/Documents/phd/yolov5/data/datasets/forms//\"\n",
    "\n",
    "    gatherList=[]\n",
    "    allLines=[]\n",
    "    \n",
    "    for indx,lineDetail in enumerate(temp):\n",
    "\n",
    "        count=0\n",
    "        imgNameIndx=0\n",
    "        lineNoIndx=0\n",
    "        #print(\" lineDetail:\",lineDetail)\n",
    "        for charIndx,ele in enumerate(lineDetail):\n",
    "\n",
    "            if ele==\"-\":\n",
    "                count+=1\n",
    "                \n",
    "            if count==2:\n",
    "                imgNameIndx=charIndx\n",
    "                break\n",
    "            if count==3:\n",
    "                lineNoIndx=charIndx\n",
    "                break\n",
    "\n",
    "        pngName=lineDetail[:imgNameIndx]+\".png\"\n",
    "        pngPath=os.path.join(formsPath,pngName)\n",
    "        \n",
    "        lineName=lineDetail#[:(imgNameIndx+2)]\n",
    "        allLines.append(lineName)\n",
    "        \n",
    "        if os.path.isfile(pngPath):\n",
    "            gatherList.append(pngName)\n",
    "\n",
    "        #print(\" check File:\",os.path.isfile(pngPath))\n",
    "    \n",
    "    gatherList=list(set(gatherList))\n",
    "    allLines=list(set(allLines))\n",
    "    print(\" total png gathered:\",len(gatherList),\" original lines:\",len(temp),\"unique lines:\",len(allLines))    \n",
    "\n",
    "    return gatherList,allLines    \n",
    "\n",
    "\n",
    "with open(trainFile) as f1:\n",
    "    trainSet=f1.readlines()\n",
    "\n",
    "trainList,trainLines=gatherFormInOfficialSplitForYolo(trainSet)\n",
    "\n",
    "print(\" train len:\",len(trainList))\n",
    "print(\" trainLines len:\",len(trainLines))\n",
    "\n",
    "\n",
    "with open(testFile) as f1:\n",
    "    testSet=f1.readlines()\n",
    "\n",
    "testList,testLines=gatherFormInOfficialSplitForYolo(testSet)\n",
    "    \n",
    "with open(validFile1) as f1:\n",
    "    validSet1=f1.readlines()\n",
    "\n",
    "validList1,valLines1=gatherFormInOfficialSplitForYolo(validSet1)\n",
    "\n",
    "with open(validFile2) as f1:\n",
    "    validSet2=f1.readlines()\n",
    "\n",
    "validList2,valLines2=gatherFormInOfficialSplitForYolo(validSet2)\n",
    "    \n",
    "validList=validList1+validList2\n",
    "valLines=valLines1+valLines2\n",
    "\n",
    "\n",
    "print(\" test len:\",len(testList))\n",
    "print(\" testLines len:\",len(testLines))\n",
    "\n",
    "print(\" valid len:\",len(validList))\n",
    "print(\" valLines len:\",len(valLines))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43dd2761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t unique: 1539\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"./data/data_14_april.csv\")\n",
    "unqImages=set(df.image_name)\n",
    "print(\"\\n\\t unique:\",len(unqImages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83079f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_name', 'class', 'width', 'height', 'org_x1', 'org_y1', 'org_x2',\n",
      "       'org_y2', 'text', 'cropName', 'x', 'y', 'w', 'h'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.columns)\n",
    "freqDist=df['text'].value_counts()\n",
    "freqDict=freqDist.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c2aa154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13550"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(freqDict.keys()))\n",
    "\n",
    "#freqDist[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6baafda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    these are the filtered words for localization\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "words=[\"the\",\"of\",\"to\",\"and\",\"in\",\"was\",\"that\",\"is\",\"he\",\"for\",\"with\",\"his\",\"it\",\"which\",\"they\",\"from\",\"are\",\"been\",\"you\",\"this\"]     \n",
    "\n",
    "classDict=dict()\n",
    "\n",
    "\n",
    "for classId,w in enumerate(words):\n",
    "\n",
    "    classDict[w]=classId\n",
    "    \n",
    "#classDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b6baefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_name', 'class', 'width', 'height', 'org_x1', 'org_y1', 'org_x2',\n",
       "       'org_y2', 'text', 'cropName', 'x', 'y', 'w', 'h'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d31cb3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " total exceptions: 0  total unique images: 747\n"
     ]
    }
   ],
   "source": [
    "#for file in ['train','test']:\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "savePath=\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/data/toyData_#06-2022-3-2#//\"\n",
    "images_path = \"./data/datasets/forms//\"\n",
    "#allImages=os.listdir(images_path)\n",
    "#images_num=len(os.listdir(images_path))\n",
    "\n",
    "#labels_txt = savePath+\"/\"+\"mnist_train1_toyData_#06-2022-3-2#.txt\"\n",
    "labels_txt2 = savePath+\"/\"+\"mnist_test1_toyData_#06-2022-3-2#.txt\"\n",
    "\n",
    "lastName=\"\"\n",
    "curLine=\"\"\n",
    "prevLine=\"\"\n",
    "unqImg=[]\n",
    "exceptionCount,skipImage=0,0\n",
    "\n",
    "for indx,info in df.iterrows():\n",
    "    \n",
    "\n",
    "    if not info['image_name'] in trainList or not info[\"text\"] in classDict:# \n",
    "        continue\n",
    "    \n",
    "    \"\"\"\n",
    "    if not info['image_name'] in testList or not info[\"text\"] in classDict:# \n",
    "        continue\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \"\"\"\n",
    "        if indx%100==0:\n",
    "            print(\"\\n\\t unq images:\",len(unqImg))\n",
    "        \"\"\"\n",
    "        if len(unqImg)<30000:\n",
    "\n",
    "            with open(labels_txt, \"a\") as wf:\n",
    "                image_path =images_path+info[\"image_name\"]\n",
    "                \"\"\"\n",
    "                if indx%100==0:\n",
    "                    print(\"\\n\\t path:\",image_path)\n",
    "                \"\"\"\n",
    "                if info[\"image_name\"]!=lastName and info[\"image_name\"] not in unqImg:\n",
    "                    curLine=image_path\n",
    "\n",
    "                    if len(prevLine):\n",
    "                        #print(\"\\n\\t prevLine:\",prevLine)\n",
    "                        #wf.write( image_path+ \"\\n\")\n",
    "                        wf.write(prevLine+\"\\n\")\n",
    "\n",
    "                else:\n",
    "                    xmin,ymin=str(int(info[\"org_x1\"])),str(int(info[\"org_y1\"]))\n",
    "                    xmax,ymax=str(int(info[\"org_x2\"])),str(int(info[\"org_y2\"]))\n",
    "                    curLine += ' ' + ','.join([xmin, ymin, xmax, ymax, str(classDict[info[\"text\"]])])\n",
    "                    prevLine=curLine\n",
    "\n",
    "                lastName=info[\"image_name\"]\n",
    "\n",
    "            \n",
    "        if info[\"image_name\"] not in unqImg:\n",
    "            unqImg.append(info[\"image_name\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        exceptionCount+=1\n",
    "        print(\"\\n\\t exception index:\",indx,\"\\t count:\",exceptionCount,\" e:\",e)\n",
    "\n",
    "print(\" total exceptions:\",exceptionCount,\" total unique images:\",len(unqImg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb23908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a28535c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0,\n",
       " 'of': 1,\n",
       " 'to': 2,\n",
       " 'and': 3,\n",
       " 'in': 4,\n",
       " 'was': 5,\n",
       " 'that': 6,\n",
       " 'is': 7,\n",
       " 'he': 8,\n",
       " 'for': 9,\n",
       " 'with': 10,\n",
       " 'his': 11,\n",
       " 'it': 12,\n",
       " 'which': 13,\n",
       " 'they': 14,\n",
       " 'from': 15,\n",
       " 'are': 16,\n",
       " 'been': 17,\n",
       " 'you': 18,\n",
       " 'this': 19}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classDict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
