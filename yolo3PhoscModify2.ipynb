{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfc9ace6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11848134235952028481\n",
      "]\n",
      "\n",
      "\t YOLO_TYPE: yolov3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#print(\"\\n\\t tf:\",tf.__version__)\n",
    "#tf.enable_eager_execution()\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "#from yolov3.dataset import Dataset\n",
    "#from yolov3.yolov4 import Create_Yolo, compute_loss,Create_YoloPhosc\n",
    "#from yolov3.utils import load_yolo_weights\n",
    "from yolov3.configs import *\n",
    "#from evaluate_mAP import get_mAP\n",
    "\n",
    "print(\"\\n\\t YOLO_TYPE:\",YOLO_TYPE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63714d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from yolov3.utils import read_class_names, image_preprocess\n",
    "from yolov3.yolov3 import bbox_iou\n",
    "from yolov3.configs import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58446045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset = Dataset('train')\n",
    "# testset = Dataset('test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb9e7cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df=pd.read_csv(\"/home/k/phd/TensorFlow-2.x-YOLOv3/data/data3_phosc.csv\")\n",
    "# print(\"\\n\\t df:\",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "784b3e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53 26 13]\n",
      "(1, 13, 13, 3, 6)\n",
      "\n",
      "\t batch_mbboxes: (1, 100, 4)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH_SIZE\n",
    "YOLO_STRIDES\n",
    "classes = read_class_names(TRAIN_CLASSES)\n",
    "#classes\n",
    "anchors = (np.array(YOLO_ANCHORS).T/np.array(YOLO_STRIDES)).T\n",
    "#np.array(YOLO_ANCHORS)\n",
    "#np.array(YOLO_STRIDES)\n",
    "#anchors\n",
    "train_output_sizes=426//np.array(YOLO_STRIDES)\n",
    "print(train_output_sizes)\n",
    "'''\n",
    "batch_label_sbbox = np.zeros((self.batch_size, self.train_output_sizes[0], self.train_output_sizes[0], self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n",
    "batch_label_mbbox = np.zeros((self.batch_size, self.train_output_sizes[1], self.train_output_sizes[1], self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n",
    "batch_label_lbbox = np.zeros((self.batch_size, self.train_output_sizes[2], self.train_output_sizes[2], self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n",
    "\n",
    "'''\n",
    "\n",
    "temp=np.zeros((1,int(train_output_sizes[2]), int(train_output_sizes[2]),3, 5 +1))\n",
    "print(temp.shape)\n",
    "\n",
    "temp[:,:,:,0,:]=-255\n",
    "temp[:,:,:,1,:]=10\n",
    "temp[:,:,:,2,:]=255\n",
    "\n",
    "#sum(temp[:,:,:,2,0])\n",
    "\n",
    "batch_mbboxes = np.zeros((1, YOLO_MAX_BBOX_PER_SCALE, 4), dtype=np.float32)\n",
    "#batch_lbboxes = np.zeros((1, YOLO_MAX_BBOX_PER_SCALE, 4), dtype=np.float32)\n",
    "print(\"\\n\\t batch_mbboxes:\",batch_mbboxes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f491ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset1(object):\n",
    "    # Dataset preprocess implementation\n",
    "    def __init__(self, dataset_type,TEST_INPUT_SIZE=TEST_INPUT_SIZE):\n",
    "        \n",
    "        f = open(\"./data/tempCord.json\") # self.tempCord1,self.tempText1\n",
    "        self.tempCord1= json.load(f)\n",
    "        \n",
    "        #print(\"\\n\\t 1.no of coordinate before:\",len(self.tempCord1))\n",
    "\n",
    "        f = open(\"./data/tempText.json\")\n",
    "        self.tempText1 = json.load(f)\n",
    "\n",
    "        \n",
    "        self.annot_path  = TRAIN_ANNOT_PATH if dataset_type == 'train' else TEST_ANNOT_PATH\n",
    "        self.input_sizes = TRAIN_INPUT_SIZE if dataset_type == 'train' else TEST_INPUT_SIZE #416\n",
    "        self.batch_size  = TRAIN_BATCH_SIZE if dataset_type == 'train' else TEST_BATCH_SIZE\n",
    "        self.data_aug    = TRAIN_DATA_AUG   if dataset_type == 'train' else TEST_DATA_AUG\n",
    "\n",
    "        self.train_yolo_tiny = TRAIN_YOLO_TINY\n",
    "        self.train_input_sizes = TRAIN_INPUT_SIZE # 416 \n",
    "        self.strides = np.array(YOLO_STRIDES) # [8,16,32]\n",
    "        self.classes = read_class_names(TRAIN_CLASSES) \n",
    "        self.num_classes = len(self.classes)\n",
    "        #print(\"\\n\\t self.num_classes=\",self.num_classes)\n",
    "        self.anchors = (np.array(YOLO_ANCHORS).T/self.strides).T\n",
    "        self.anchor_per_scale = YOLO_ANCHOR_PER_SCALE\n",
    "        self.max_bbox_per_scale = YOLO_MAX_BBOX_PER_SCALE\n",
    "\n",
    "        self.annotations = self.load_annotations(dataset_type)\n",
    "        #print(\"\\n\\t 2.no of coordinate after:\",len(self.tempCord1))\n",
    "\n",
    "        self.num_samples = len(self.annotations)\n",
    "        self.num_batchs = int(np.ceil(self.num_samples / self.batch_size))\n",
    "        #print(\"\\n\\t num_samples =\",self.num_samples)\n",
    "        #print(\"\\n\\t num_batchs =\",self.num_batchs)\n",
    "        self.batch_count = 0\n",
    "        #self.tempCord1=tempCord1\n",
    "        #self.tempCord1=tempText1\n",
    "        #input(\"press!!!\")\n",
    "        \n",
    "    def load_annotations(self, dataset_type):\n",
    "        final_annotations = []\n",
    "        with open(self.annot_path, 'r') as f:\n",
    "            txt = f.read().splitlines()\n",
    "            annotations = [line.strip() for line in txt if len(line.strip().split()[1:]) != 0]\n",
    "\n",
    "        #print(annotations)\n",
    "        #np.random.shuffle(annotations)\n",
    "\n",
    "        for annotation in annotations:\n",
    "            # fully parse annotations\n",
    "            line = annotation.split()\n",
    "            image_path, index = \"\", 1\n",
    "\n",
    "            #print(\"\\n\\t line:\",line)\n",
    "            for i, one_line in enumerate(line):\n",
    "                if not one_line.replace(\",\",\"\").isnumeric():\n",
    "                    if image_path != \"\": image_path += \" \"\n",
    "                    image_path += one_line\n",
    "                else:\n",
    "                    index = i\n",
    "                    break\n",
    "\n",
    "            image_path=line.pop(0)\n",
    "            #print(\"\\n\\t path-->\",os.path.exists(image_path))\n",
    "            #print(\"\\n\\t path:\",image_path)\n",
    "            if not os.path.exists(image_path):\n",
    "                raise KeyError(\"%s does not exist ... \" %image_path)\n",
    "            if TRAIN_LOAD_IMAGES_TO_RAM:\n",
    "                image = cv2.imread(image_path)\n",
    "            else:\n",
    "                image = ''\n",
    "            final_annotations.append([image_path, line[index:], image])\n",
    "            \n",
    "            for cord in line[index:]:\n",
    "                #'[361, 587, 480, 652]'  2.cord: ['603', '603', '689', '652']\n",
    "\n",
    "                #print(\"\\n\\t 1.cord:\",cord)\n",
    "\n",
    "                cord=cord.split(\",\")[:4]\n",
    "                #print(\"\\n\\t 2.cord:\",cord)\n",
    "                \n",
    "                cord = str([int(i) for i in cord])\n",
    "                #print(\"***>\",cord)\n",
    "                txt=self.tempCord1[cord]\n",
    "\n",
    "                #txt=self.tempCord1[str(list(cord))]\n",
    "                #print(\"\\n\\t word:\",txt)\n",
    "                vec=self.tempText1[txt]\n",
    "                #print(\"\\n\\t phoc:\",len(vec['phoc']),\"\\t phos:\",len(vec['phos']))\n",
    "                #print(\"\\n\\t phoc:\",vec['phoc'])\n",
    "                #print(\"\\n\\t phoc:\",vec['phos'])\n",
    "\n",
    "                \n",
    "            #print(\"\\n\\t record:\",image_path,\"\\t \",image.shape,\"\\t index:\",index,\"\\t le:\",len(line[index:]))\n",
    "            \n",
    "            #print(\"\\n\\t line:\",line[index:])\n",
    "            \n",
    "            #input(\"check!!!\")\n",
    "        return final_annotations\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def Delete_bad_annotation(self, bad_annotation):\n",
    "        print(f'Deleting {bad_annotation} annotation line')\n",
    "        bad_image_path = bad_annotation[0]\n",
    "        bad_image_name = bad_annotation[0].split('/')[-1] # can be used to delete bad image\n",
    "        bad_xml_path = bad_annotation[0][:-3]+'xml' # can be used to delete bad xml file\n",
    "\n",
    "        # remove bad annotation line from annotation file\n",
    "        with open(self.annot_path, \"r+\") as f:\n",
    "            d = f.readlines()\n",
    "            f.seek(0)\n",
    "            for i in d:\n",
    "                if bad_image_name not in i:\n",
    "                    f.write(i)\n",
    "            f.truncate()\n",
    "\n",
    "    def __next__(self):\n",
    "        with tf.device('/gpu:0'):\n",
    "            self.train_input_size = random.choice([self.train_input_sizes])\n",
    "            self.train_output_sizes = self.train_input_size // self.strides\n",
    "\n",
    "            batch_image = np.zeros((self.batch_size, self.train_input_size, self.train_input_size, 3), dtype=np.float32)\n",
    "\n",
    "            if self.train_yolo_tiny:\n",
    "                batch_label_mbbox = np.zeros((self.batch_size, self.train_output_sizes[0], self.train_output_sizes[0], self.anchor_per_scale, 5 + self.num_classes+769), dtype=np.float32)\n",
    "                batch_label_lbbox = np.zeros((self.batch_size, self.train_output_sizes[1], self.train_output_sizes[1], self.anchor_per_scale, 5 + self.num_classes+769), dtype=np.float32)\n",
    "            else:\n",
    "                batch_label_sbbox = np.zeros((self.batch_size, self.train_output_sizes[0], self.train_output_sizes[0], self.anchor_per_scale, 5 + self.num_classes+769), dtype=np.float32)\n",
    "                batch_label_mbbox = np.zeros((self.batch_size, self.train_output_sizes[1], self.train_output_sizes[1], self.anchor_per_scale, 5 + self.num_classes+769), dtype=np.float32)\n",
    "                batch_label_lbbox = np.zeros((self.batch_size, self.train_output_sizes[2], self.train_output_sizes[2], self.anchor_per_scale, 5 + self.num_classes+769), dtype=np.float32)\n",
    "\n",
    "                batch_sbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4+769), dtype=np.float32)\n",
    "\n",
    "            batch_mbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4+769), dtype=np.float32)\n",
    "            batch_lbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4+769), dtype=np.float32)\n",
    "\n",
    "            exceptions = False\n",
    "            num = 0\n",
    "            if self.batch_count < self.num_batchs:\n",
    "                while num < self.batch_size:\n",
    "                    index = self.batch_count * self.batch_size + num\n",
    "                    if index >= self.num_samples: index -= self.num_samples\n",
    "                    annotation = self.annotations[index]\n",
    "                    \n",
    "                    print(\"\\n\\t annotation =\",annotation[0])\n",
    "                    #print(\"\\n\\t 1.annotation =\",len(annotation[1]))\n",
    "                    #print(\"\\n\\t annotation =\",annotation[2].shape)\n",
    "\n",
    "                    image, bboxes,tempCord11 = self.parse_annotation(annotation)\n",
    "                    #print(\"\\n\\t image:\",image.shape)\n",
    "                    #print(\"\\n\\t bboxes shape =\",bboxes.shape)\n",
    "                    #print(\"\\n\\t 2.bboxes =\",bboxes)\n",
    "                    \n",
    "                    try:\n",
    "                        if self.train_yolo_tiny:\n",
    "                            label_mbbox, label_lbbox, mbboxes, lbboxes = self.preprocess_true_boxes(bboxes,tempCord11)\n",
    "                        else:\n",
    "                            label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes = self.preprocess_true_boxes(bboxes,tempCord11)\n",
    "                    except IndexError:\n",
    "                        exceptions = True\n",
    "                        self.Delete_bad_annotation(annotation)\n",
    "                        print(\"IndexError, something wrong with\", annotation[0], \"removed this line from annotation file\")\n",
    "                  \n",
    "                    #label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes\n",
    "                    '''\n",
    "                    print(\"\\n\\t label_sbbox:\",label_sbbox.shape)\n",
    "                    print(\"\\n\\t label_mbbox:\",label_mbbox.shape)\n",
    "                    print(\"\\n\\t label_lbbox:\",label_lbbox.shape)\n",
    "                    print(\"\\n\\t sbboxes:\",sbboxes.shape)\n",
    "                    print(\"\\n\\t mbboxes:\",mbboxes.shape)\n",
    "                    print(\"\\n\\t lbboxes:\", lbboxes.shape)\n",
    "                    '''\n",
    "                    batch_image[num, :, :, :] = image\n",
    "                    batch_label_mbbox[num, :, :, :, :] = label_mbbox\n",
    "                    batch_label_lbbox[num, :, :, :, :] = label_lbbox\n",
    "                    batch_mbboxes[num, :, :] = mbboxes\n",
    "                    batch_lbboxes[num, :, :] = lbboxes\n",
    "                    if not self.train_yolo_tiny:\n",
    "                        batch_label_sbbox[num, :, :, :, :] = label_sbbox\n",
    "                        batch_sbboxes[num, :, :] = sbboxes\n",
    "\n",
    "                    num += 1\n",
    "\n",
    "                if exceptions:\n",
    "                    print('\\n')\n",
    "                    raise Exception(\"There were problems with dataset, I fixed them, now restart the training process.\")\n",
    "                self.batch_count += 1\n",
    "                if not self.train_yolo_tiny:\n",
    "                    batch_smaller_target = batch_label_sbbox, batch_sbboxes\n",
    "                batch_medium_target  = batch_label_mbbox, batch_mbboxes\n",
    "                batch_larger_target  = batch_label_lbbox, batch_lbboxes\n",
    "\n",
    "                if self.train_yolo_tiny:\n",
    "                    return batch_image, (batch_medium_target, batch_larger_target)\n",
    "                return batch_image, (batch_smaller_target, batch_medium_target, batch_larger_target)\n",
    "            else:\n",
    "                self.batch_count = 0\n",
    "                np.random.shuffle(self.annotations)\n",
    "                raise StopIteration\n",
    "\n",
    "    def random_horizontal_flip(self, image, bboxes):\n",
    "        if random.random() < 0.5:\n",
    "            _, w, _ = image.shape\n",
    "            image = image[:, ::-1, :]\n",
    "            bboxes[:, [0,2]] = w - bboxes[:, [2,0]]\n",
    "\n",
    "        return image, bboxes\n",
    "\n",
    "    def random_crop(self, image, bboxes):\n",
    "        if random.random() < 0.5:\n",
    "            h, w, _ = image.shape\n",
    "            max_bbox = np.concatenate([np.min(bboxes[:, 0:2], axis=0), np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
    "\n",
    "            max_l_trans = max_bbox[0]\n",
    "            max_u_trans = max_bbox[1]\n",
    "            max_r_trans = w - max_bbox[2]\n",
    "            max_d_trans = h - max_bbox[3]\n",
    "\n",
    "            crop_xmin = max(0, int(max_bbox[0] - random.uniform(0, max_l_trans)))\n",
    "            crop_ymin = max(0, int(max_bbox[1] - random.uniform(0, max_u_trans)))\n",
    "            crop_xmax = max(w, int(max_bbox[2] + random.uniform(0, max_r_trans)))\n",
    "            crop_ymax = max(h, int(max_bbox[3] + random.uniform(0, max_d_trans)))\n",
    "\n",
    "            image = image[crop_ymin : crop_ymax, crop_xmin : crop_xmax]\n",
    "\n",
    "            bboxes[:, [0, 2]] = bboxes[:, [0, 2]] - crop_xmin\n",
    "            bboxes[:, [1, 3]] = bboxes[:, [1, 3]] - crop_ymin\n",
    "\n",
    "        return image, bboxes\n",
    "\n",
    "    def random_translate(self, image, bboxes):\n",
    "        if random.random() < 0.5:\n",
    "            h, w, _ = image.shape\n",
    "            max_bbox = np.concatenate([np.min(bboxes[:, 0:2], axis=0), np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
    "\n",
    "            max_l_trans = max_bbox[0]\n",
    "            max_u_trans = max_bbox[1]\n",
    "            max_r_trans = w - max_bbox[2]\n",
    "            max_d_trans = h - max_bbox[3]\n",
    "\n",
    "            tx = random.uniform(-(max_l_trans - 1), (max_r_trans - 1))\n",
    "            ty = random.uniform(-(max_u_trans - 1), (max_d_trans - 1))\n",
    "\n",
    "            M = np.array([[1, 0, tx], [0, 1, ty]])\n",
    "            image = cv2.warpAffine(image, M, (w, h))\n",
    "\n",
    "            bboxes[:, [0, 2]] = bboxes[:, [0, 2]] + tx\n",
    "            bboxes[:, [1, 3]] = bboxes[:, [1, 3]] + ty\n",
    "\n",
    "        return image, bboxes\n",
    "\n",
    "    def parse_annotation(self, annotation, mAP = 'False'):\n",
    "        if TRAIN_LOAD_IMAGES_TO_RAM:\n",
    "            image_path = annotation[0]\n",
    "            image = annotation[2]\n",
    "        else:\n",
    "            image_path = annotation[0]\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "        bboxes = np.array([list(map(int, box.split(','))) for box in annotation[1]])\n",
    "\n",
    "        if self.data_aug:\n",
    "            image, bboxes = self.random_horizontal_flip(np.copy(image), np.copy(bboxes))\n",
    "            image, bboxes = self.random_crop(np.copy(image), np.copy(bboxes))\n",
    "            image, bboxes = self.random_translate(np.copy(image), np.copy(bboxes))\n",
    "\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if mAP == True:\n",
    "            return image, bboxes\n",
    "\n",
    "        image, bboxes,tempCord11 = image_preprocess(np.copy(image), [self.input_sizes, self.input_sizes],self.tempCord1,self.tempText1, np.copy(bboxes))\n",
    "        return image, bboxes,tempCord11\n",
    "\n",
    "    def preprocess_true_boxes(self, bboxes,tempCord11):\n",
    "        OUTPUT_LEVELS = len(self.strides)\n",
    "\n",
    "        label = [np.zeros((self.train_output_sizes[i], self.train_output_sizes[i], self.anchor_per_scale,\n",
    "                           5 + self.num_classes+769)) for i in range(OUTPUT_LEVELS)]# change\n",
    "        bboxes_xywh = [np.zeros((self.max_bbox_per_scale, 4+769)) for _ in range(OUTPUT_LEVELS)]# change\n",
    "        bbox_count = np.zeros((OUTPUT_LEVELS,))\n",
    "\n",
    "        #print(\"\\n\\tbboxes_xywh:\",len(bboxes_xywh),\"\\t shape:\",bboxes_xywh[0].shape)\n",
    "        # (3,100,4)\n",
    "        for bbox in bboxes:\n",
    "            \n",
    "            #print(\"\\n\\t bbox=\",bbox)\n",
    "            orgBbox=bbox[:4]\n",
    "            #print(\"\\n\\t 1.orgBbox:\",orgBbox)#[80 20 83 21]-->'[80, 20, 83, 21]'\n",
    "            #orgBbox=orgBbox[0]+orgBbox[1]+orgBbox[2]+orgBbox[3]\n",
    "            key=str(\"[\")+str(bbox[0])+\", \"+str(bbox[1])+\", \"+str(bbox[2])+\", \"+str(bbox[3])+\"]\"\n",
    "            #print(\"\\n\\t key:\",key)\n",
    "            key=tempCord11[key]\n",
    "            \n",
    "            '''\n",
    "            try:\n",
    "                print(\"\\n\\t text string:\",tempCord11[key])\n",
    "            except Exception as e:\n",
    "                print(\"\\n\\t exception key:\",key)\n",
    "            '''\n",
    "                #input(\"exception!!!\")\n",
    "            #orgBbox=orgBbox.split(\" \")\n",
    "            #print(\"\\n\\t 2.orgBbox:\",orgBbox)\n",
    "            #orgBbox=orgBbox=\"\".join(\", \")\n",
    "            #print(\"\\n\\t 3.orgBbox:\",orgBbox)\n",
    "\n",
    "            bbox_coor = bbox[:4]\n",
    "            bbox_class_ind = bbox[4]\n",
    "\n",
    "            onehot = np.zeros(self.num_classes, dtype=np.float)\n",
    "            onehot[bbox_class_ind] = 1.0\n",
    "            uniform_distribution = np.full(self.num_classes, 1.0 / self.num_classes)\n",
    "            deta = 0.01\n",
    "            smooth_onehot = onehot * (1 - deta) + deta * uniform_distribution\n",
    "            \n",
    "            bbox_xywh = np.concatenate([(bbox_coor[2:4] + bbox_coor[:2]) * 0.5, bbox_coor[2:4] - bbox_coor[:2]], axis=-1) # change\n",
    "            #print(\"\\n\\t 0.bbox_xywh centre HW=\",bbox_xywh)\n",
    "            \n",
    "            \n",
    "            bbox_xywh_scaled = 1.0 * bbox_xywh[np.newaxis, :4] / self.strides[:, np.newaxis]\n",
    "            #print(\"\\n\\t 1.bbox_xywh_scaled =\",bbox_xywh_scaled)\n",
    "            \n",
    "            iou = []\n",
    "            exist_positive = False\n",
    "            for i in range(OUTPUT_LEVELS):#range(3):\n",
    "                anchors_xywh = np.zeros((self.anchor_per_scale, 4))\n",
    "                #print(\"\\n\\t anchors_xywh:\",anchors_xywh) # (3,4)\n",
    "                anchors_xywh[:, 0:2] = np.floor(bbox_xywh_scaled[i, 0:2]).astype(np.int32) + 0.5\n",
    "                anchors_xywh[:, 2:4] = self.anchors[i]\n",
    "                #print(\"\\n\\t anchors_xywh:\",anchors_xywh)\n",
    "                \n",
    "                iou_scale = bbox_iou(bbox_xywh_scaled[i][np.newaxis, :], anchors_xywh)\n",
    "                iou.append(iou_scale)\n",
    "                iou_mask = iou_scale > 0.3\n",
    "                \n",
    "                #print(\"\\n\\t iou_mask =\",len(iou_mask)\n",
    "\n",
    "                if np.any(iou_mask):\n",
    "                    xind, yind = np.floor(bbox_xywh_scaled[i, 0:2]).astype(np.int32)\n",
    "\n",
    "                    label[i][yind, xind, iou_mask, :] = 0\n",
    "                    label[i][yind, xind, iou_mask, 0:4] = bbox_xywh\n",
    "                    label[i][yind, xind, iou_mask, 4:5] = 1.0\n",
    "                    label[i][yind, xind, iou_mask, 5:6] = smooth_onehot # change\n",
    "                    \n",
    "                    #print(\"\\n\\t bbox_xywh:\",bbox_xywh.shape)\n",
    "                    #print(\"\\n\\t shape:\",label[i][yind, xind, iou_mask, 6:].shape)\n",
    "                    #self.tempText1\n",
    "                    print(\"\\n\\t key:\",key)\n",
    "                    tempVec=self.tempText1[key]\n",
    "                    print(\"\\n\\ttempVec.keys():\",tempVec.keys())\n",
    "\n",
    "                    tempPhoc=tempVec['phoc']\n",
    "                    tempPhos=tempVec['phos']\n",
    "                    print(\"\\n\\t tempPhosc=\",type(tempPhoc))\n",
    "                    print(\"\\n\\t tempPhosc=\",type(tempPhos))\n",
    "\n",
    "                    tempPhosc=tempPhoc+tempPhos\n",
    "                    print(\"\\n\\t tempPhosc=\",type(tempPhosc))\n",
    "                    label[i][yind, xind, iou_mask, 6:] = tempPhosc#np.random.randint(0,1,769) # change\n",
    "                 \n",
    "                    bbox_ind = int(bbox_count[i] % self.max_bbox_per_scale)\n",
    "                    bboxes_xywh[i][bbox_ind, :4] = bbox_xywh\n",
    "                    bbox_count[i] += 1\n",
    "\n",
    "                    exist_positive = True\n",
    "\n",
    "            if not exist_positive:\n",
    "                best_anchor_ind = np.argmax(np.array(iou).reshape(-1), axis=-1)\n",
    "                best_detect = int(best_anchor_ind / self.anchor_per_scale)\n",
    "                best_anchor = int(best_anchor_ind % self.anchor_per_scale)\n",
    "                xind, yind = np.floor(bbox_xywh_scaled[best_detect, 0:2]).astype(np.int32)\n",
    "\n",
    "                label[best_detect][yind, xind, best_anchor, :] = 0\n",
    "                label[best_detect][yind, xind, best_anchor, 0:4] = bbox_xywh\n",
    "                label[best_detect][yind, xind, best_anchor, 4:5] = 1.0\n",
    "                label[best_detect][yind, xind, best_anchor, 5:6] = smooth_onehot # change\n",
    "                label[best_detect][yind, xind, best_anchor, 6:] = np.random.randint(0,1,769) # change \n",
    "\n",
    "                bbox_ind = int(bbox_count[best_detect] % self.max_bbox_per_scale)\n",
    "                bboxes_xywh[best_detect][bbox_ind, :4] = bbox_xywh\n",
    "                bbox_count[best_detect] += 1\n",
    "\n",
    "        if self.train_yolo_tiny:\n",
    "            label_mbbox, label_lbbox = label\n",
    "            mbboxes, lbboxes = bboxes_xywh\n",
    "            return label_mbbox, label_lbbox, mbboxes, lbboxes\n",
    "\n",
    "        label_sbbox, label_mbbox, label_lbbox = label\n",
    "        sbboxes, mbboxes, lbboxes = bboxes_xywh\n",
    "        return label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batchs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0b059f",
   "metadata": {},
   "source": [
    "'''\n",
    "    search record in dataframe\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9d243e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 5, 4, 2, 4, 6, 6, 4, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(1, 7,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bf623f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t annotation = /home/k/phd/yolov5/data/datasets/forms/l04-087.png\n",
      "\n",
      "\t key: or\n",
      "\n",
      "\ttempVec.keys(): dict_keys(['phoc', 'phos'])\n",
      "\n",
      "\t tempPhosc= <class 'str'>\n",
      "\n",
      "\t tempPhosc= <class 'str'>\n",
      "\n",
      "\t tempPhosc= <class 'str'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0][0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\\n 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\\n 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d500d019c331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#testset = Dataset('test')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_no\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m#nm=str(np.random.randint(10000))+\".png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\t image_data=\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-46cc1e0643af>\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m                             \u001b[0mlabel_mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_lbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_true_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtempCord11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                             \u001b[0mlabel_sbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_lbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_true_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtempCord11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                         \u001b[0mexceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-46cc1e0643af>\u001b[0m in \u001b[0;36mpreprocess_true_boxes\u001b[0;34m(self, bboxes, tempCord11)\u001b[0m\n\u001b[1;32m    360\u001b[0m                     \u001b[0mtempPhosc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtempPhoc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtempPhos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\t tempPhosc=\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtempPhosc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m                     \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempPhosc\u001b[0m\u001b[0;31m#np.random.randint(0,1,769) # change\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                     \u001b[0mbbox_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_bbox_per_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0][0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\\n 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\\n 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.]'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "f = open(\"./data/tempCord.json\")\n",
    "tempCord1= json.load(f)\n",
    "\n",
    "f = open(\"./data/tempText.json\")\n",
    "tempText1 = json.load(f)\n",
    "'''\n",
    "import json\n",
    "trainset = Dataset1('train')\n",
    "#testset = Dataset('test')\n",
    "\n",
    "for batch_no,(image_data, target) in enumerate(trainset):\n",
    "    #nm=str(np.random.randint(10000))+\".png\"\n",
    "    print(\"\\n\\t image_data=\",image_data.shape)    \n",
    "    print(\"\\n\\t target:\",target[0][0].shape)\n",
    "    input(\"image\")\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df74ae7d",
   "metadata": {},
   "source": [
    "'''\n",
    "    dataset used here is forms data (IAM handwritten not sure) which is at times character \n",
    "    level so for this need to segment characters which forms a word\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaf85ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "'[ 608 2287  694 2336]'\n",
    "'[603, 603, 689, 652]'\n",
    "'[77, 8, 78, 8]'\n",
    "ss='[603 603 689 652]'.split(\" \")\n",
    "\", \".join(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412385c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'[1763, 2064, 1849, 2113]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838fe914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open(\"./data/tempCord.json\")\n",
    "tempCord1= json.load(f)\n",
    "o=[603, 603, 689, 652]\n",
    "\n",
    "# tempCord1['[603, 603, 689, 652]']\n",
    "# tempCord1['[77, 8, 78, 8]']\n",
    "\n",
    "\n",
    "f = open(\"./data/tempText.json\")\n",
    "tempText1 = json.load(f)\n",
    "tempText1\n",
    "#['[1763,2064,1849,2113]']\n",
    "#f = open(\"./data/tempText.json\")\n",
    "#tempText1 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b639124",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    In below for loop\n",
    "    image_data: Actual Image\n",
    "    \n",
    "    image_data: (1, 416, 416, 3):(batch_size,height,width,channels) are returned feature maps from yolo\n",
    "    target[0][0]: (1, 52, 52, 3, 6) here 3 indicates # anchors boxes\n",
    "    target[1][0]: (1, 26, 26, 3, 6) here 3 indicates # anchors boxes\n",
    "    target[2][0]: (1, 13, 13, 3, 6) here 3 indicates # anchors boxes\n",
    "    \n",
    "    where every feature map has dim 6 which is (midX,midY,height,width,objectness,classProb)\n",
    "\n",
    "    target[0][1],target[1][1],target[2][1] is of shape (1, 100, 4)\n",
    "    Where I think 100 is max object detected and 4 are midX,midY,height,width\n",
    "    \n",
    "'''\n",
    "\n",
    "def shapes(image_data,target):\n",
    "\n",
    "    print(\"\\n\\t image_data:\",image_data.shape)\n",
    "    print(\"\\n\\t target 0:\",target[0][0].shape)\n",
    "    print(\"\\n\\t target 1:\",target[1][0].shape)\n",
    "    print(\"\\n\\t target 2:\",target[2][0].shape)\n",
    "    print(\"\\n\\t target:\",target[2][1].shape)\n",
    "    print(\"\\n\\t target len:\",len(target[0][0]))\n",
    "    print(\"\\n\\t target len:\",len(target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5f589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for batch_no,(image_data, target) in enumerate(trainset):\n",
    "    if 0:\n",
    "        shapes(image_data,target)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf58c9",
   "metadata": {},
   "source": [
    "'''\n",
    "    Below part from PHOSC \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af7b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from phos_label_generator import gen_label\n",
    "from phoc_label_generator import gen_phoc_label\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import img_to_array,load_img\n",
    "import pandas as pd\n",
    "'''\n",
    "    this creates a label file\n",
    "    which contains word and its PHOSCNET representation\n",
    "'''\n",
    "from createPhoscLabels import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fdf115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"\\n\\t df_train:\",df_train.columns)\n",
    "train_sequence = DataSequence(df_train, BATCH_SIZE)\n",
    "valid_sequence = DataSequence(df_valid, BATCH_SIZE) \n",
    "df=pd.read_csv(\"./data/temp2.csv\")\n",
    "print(\"\\n\\t df:\",df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6153c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDict={}\n",
    "for images,labels in train_sequence:\n",
    "    \n",
    "    print(\"\\n\\t labels:\",labels.keys())\n",
    "\n",
    "    labelPhos=labels['phosnet']\n",
    "    labelPhoc=labels['phocnet']  \n",
    "    text=labels['text']\n",
    "    #print(\"\\n\\t text:\",text)\n",
    "    print(\"\\n\\t labelPhos=\",len(labelPhos[2]))\n",
    "    print(\"\\n\\t labelPhoc=\",len(labelPhoc))\n",
    "    \n",
    "    labelDict[\"text\"]=[labelPhoc,labelPhos]\n",
    "    \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2745ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2,3,4,5]\n",
    "\n",
    "for ele in a:\n",
    "    ele=2*ele\n",
    "\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4d0c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=str([0, 0, 0, 0, 0, 0, 0, 0])\n",
    "print(a)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_keras",
   "language": "python",
   "name": "yolo_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
