{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "This creates a data frame which contains Image path BB,PHOS,PHOC representation\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!python train.py --data coco2.yaml --cfg yolov5s.yaml --weights '' --batch-size 8 --epochs 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python detect.py --source data/datasets/coco2_test/images --weights ./runs/train/exp6/weights/best.pt --conf 0.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python detect.py --source data/images --weights ./runs/train/exp3/weights/best.pt --conf 0.25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "    BELOW PART PARSES WORD AND ITS COORDINATES\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeCoordinate(d):\n",
    "    \n",
    "    '''\n",
    "    l=d[\"cord\"]\n",
    "    \n",
    "    temp=l[0]\n",
    "    minx,y1=temp[0],temp[1] \n",
    "       \n",
    "    temp=l[-1]\n",
    "       \n",
    "    maxx,y2=temp[2],temp[3]    \n",
    "    \n",
    "    return minx,y1,maxx,y2\n",
    "    '''\n",
    "    \n",
    "    minX,minY,maxX,maxY=float('inf'),float('inf'),-float('inf'),-float('inf')  \n",
    "    \n",
    "    for indx,l in enumerate(d[\"cord\"]):\n",
    "        \n",
    "        minX,minY,maxX,maxY=min(minx,l[0]),min(minx,l[1]),max(maxY,l[2]),max(maxY,l[3])\n",
    "        \n",
    "#         if indx==0:\n",
    "#             constX=l[]\n",
    "            \n",
    "#         x,y=l[0],l[-1]\n",
    "        \n",
    "#         minx,maxY=min(minx,x),max(maxY,y)\n",
    "    \n",
    "    return minX,minY,maxX,maxY\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d={'word': 'MOVE', 'cord': [[507, 768, 570, 814], [568, 770, 624, 811], [631, 768, 669, 809], [676, 772, 707, 808], [691, 766, 720, 778]]}\n",
    "#r=mergeCoordinate(d)\n",
    "#print(\"\\n\\t r:\",r)\n",
    "\n",
    "dumpPath=\"/home/k/phd/yolov5/data/datasets/forms_1/\"\n",
    "\n",
    "def mergeCoordinate(d):\n",
    "    \n",
    "    minX,minY,maxX,maxY=float('inf'),float('inf'),-float('inf'),-float('inf')  \n",
    "    allCords=[]\n",
    "    \n",
    "    #l=d[\"cord\"]\n",
    "    #l1=l[0]\n",
    "    #l2=l[-1]\n",
    "    \n",
    "    for indx,l in enumerate(d[\"cord\"]):\n",
    "        \n",
    "        #print(\"\\n\\t l in loop:\",l)\n",
    "        minX,minY,maxX,maxY=min(minX,l[0]),min(minY,l[1]),max(maxX,l[2]),max(maxY,l[3])\n",
    "        #allCords.append([minX,minY,maxX,maxY])\n",
    "        #allCords.append(l)\n",
    "    \n",
    "    #l=[l1[0],l1[1],l2[-2],l2[-1]]\n",
    "    l=[minX,minY,maxX,maxY]\n",
    "    allCords.append(l)\n",
    "    return allCords#minX,minY,maxX,maxY\n",
    "\n",
    "def show(img,nm):\n",
    "    #img.save(\"./temp/\"+nm+\".png\")\n",
    "\n",
    "    img=img.resize((1000,800))\n",
    "    img.show()\n",
    "\n",
    "#df=[\"image_name\",\"class\",\"width\",\"height\",\"x1\",\"y1\",\"x2\",\"y2\",\"org_x1\",\"org_y1\",\"org_x2\",\"org_y2\"]\n",
    "\n",
    "def fill(indx,img,nm,fileName,df,x1,y1,x2,y2,currTextVal):\n",
    "    \n",
    "    w,h=img.size\n",
    "    df.loc[indx,\"image_name\"]=nm\n",
    "    df.loc[indx,\"class\"]=1\n",
    "    df.loc[indx,\"width\"]=w\n",
    "    df.loc[indx,\"height\"]=h\n",
    "    df.loc[indx,\"x\"]=round((x1+x2)/(2*w),2) \n",
    "    df.loc[indx,\"y\"]=round((y1+y2)/(2*h),2)\n",
    "    df.loc[indx,\"w\"]=round(abs(x2-x1)/w,2)\n",
    "    df.loc[indx,\"h\"]=round(abs(y2-y1)/h,2)\n",
    "    df.loc[indx,\"org_x1\"]=x1\n",
    "    df.loc[indx,\"org_y1\"]=y1\n",
    "    df.loc[indx,\"org_x2\"]=x2\n",
    "    df.loc[indx,\"org_y2\"]=y2\n",
    "    df.loc[indx,\"text\"]=currTextVal\n",
    "    \n",
    "    xx=str(round((x1+x2)/(2*w),2))\n",
    "    yy=str(round((y1+y2)/(2*h),2))\n",
    "    ww=str(round(abs(x2-x1)/w,2))\n",
    "    hh=str(round(abs(y2-y1)/h,2))\n",
    "    \n",
    "    text=\"0\"+\" \"+xx+\" \"+yy+\" \"+ww+\" \"+hh\n",
    "    \n",
    "    with open (dumpPath+fileName,'a') as f: \n",
    "        f.write (text+'\\n')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "    below part parse forms and records coordinate and text \n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[elem.tag for elem in root.iter()]\n",
    "from collections import defaultdict\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "d={}\n",
    "\n",
    "\n",
    "#imgPath=\"/home/k/phd/yolov5/data/datasets/formsA-D/a01-000u.png\"\n",
    "imgPath=\"/home/k/phd/yolov5/data/datasets/forms/\"\n",
    "path=\"/home/k/phd/yolov5/data/xml//\"\n",
    "#files=[\"a01-000u.xml\",\"a01-000x.xml\"]\n",
    "allImages=os.listdir(imgPath)\n",
    "files=os.listdir(path)\n",
    "df=pd.DataFrame(columns=[\"image_name\",\"class\",\"width\",\"height\",\"org_x1\",\"org_y1\",\"org_x2\",\"org_y2\",\"text\"])\n",
    "lineNo=0\n",
    "expCount=0\n",
    "for indx,nm in enumerate(files):\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    if indx not in [20,22,32,33,41,46,47,62]:\n",
    "        continue\n",
    "        \n",
    "    if indx>62:\n",
    "        break\n",
    "    ''' \n",
    "    imgName=nm.split(\".xml\")[0]+\".png\"\n",
    "    if imgName not in allImages:\n",
    "        continue\n",
    "    \n",
    "    if indx%100==0:\n",
    "        print(\"\\n\\t indx:\",indx,\"\\t total:\",len(files),\"\\t\\t nm:\",nm,\"\\t unique files:\",len(df.image_name.unique()))\n",
    "        \n",
    "#     if len(df.image_name.unique())>200:\n",
    "#         break\n",
    "\n",
    "    doc = ET.parse(path+nm)\n",
    "    root = doc.getroot()\n",
    "    fn=nm.split(\".xml\")[0]+\".txt\"\n",
    "\n",
    "    img=Image.open(imgPath+imgName)\n",
    "    #img=img.convert('RGB')\n",
    "    #print(\"\\n\\t 1.shape:\",img.size)     \n",
    "    #show(img,\"nm\")\n",
    "    #input(\"check\")\n",
    "#     continue\n",
    "    img1 = ImageDraw.Draw(img) \n",
    "\n",
    "    for node in root.iter('word'):\n",
    "        #print(\"\\n\\t attrib:\",node.attrib[\"text\"])\n",
    "        currTextVal=node.attrib[\"text\"]\n",
    "        #print(\"\\n\\t \",i)\n",
    "        prevWord=None\n",
    "        words=defaultdict(list)\n",
    "\n",
    "        for ele in node.iter():\n",
    "            #print(\"\\n\\t ele:\",ele.tag)\n",
    "            if ele.tag==\"word\":\n",
    "\n",
    "                try:\n",
    "                    if \"word\" in d.keys():\n",
    "                        prevWord=d[\"word\"]\n",
    "                        #print(\"\\n\\t prevWord=\",d[\"word\"],\"\\t word:\",ele.attrib[\"text\"])\n",
    "                        \n",
    "                        #print(\"\\n\\t d:\",d)\n",
    "                        allCords=mergeCoordinate(d)\n",
    "                        #print(\"\\n\\t allCords=\",allCords)\n",
    "                        cord=allCords[0]\n",
    "                        #for cord in allCords:\n",
    "                        #print(\"\\n\\t\\t\\t cord:\",cord)\n",
    "                        x1,y1,x2,y2=int(cord[0]),int(cord[1]),int(cord[2]),int(cord[3])\n",
    "                        #area=abs(x2-x1)*abs(y2-y1)\n",
    "                        #print(\"\\n\\t area:\",area)\n",
    "                        #if 1:#abs(x2-x1)*abs(y2-y1)<300000:\n",
    "                        #img1.line((x1,(y1+y2)/2,x2,(y1+y2)/2),fill=\"black\",width=10)\n",
    "                        \n",
    "                        df=fill(lineNo,img,imgName,fn,df,x1,y1,x2,y2,currTextVal)\n",
    "                        lineNo+=1\n",
    "                        #print(\"\\n\\t img=\",img.shape)\n",
    "                        #img1.rectangle(((x1,y1), (x2,y2)),outline = \"red\",width=10)\n",
    "                        #show(img,nm)\n",
    "                        #input(3)\n",
    "\n",
    "                except Exception as e:\n",
    "                    expCount+=1\n",
    "                    exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "                    fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "                    #print(exc_type, fname, exc_tb.tb_lineno)\n",
    "                    #print(\"\\n\\t  d exception:\",e,\"\\t line number:\",exc_tb.tb_lineno,\"\\t \",indx)\n",
    "                    #print(\"\\n\\t cord:\",cord,\"\\t exp:\",expCount,d)\n",
    "                    #input(\"check\")\n",
    "\n",
    "                d={}\n",
    "                d[\"word\"]=ele.attrib[\"text\"]\n",
    "                d[\"cord\"]=[]\n",
    "            elif ele.tag==\"cmp\":\n",
    "                #print(\"\\n\\t\\t current text:\",d[\"word\"])\n",
    "                #print(\"\\n\\t\\t current co-ordinate:\",ele.attrib)\n",
    "                #print(\"\\n\\t\\t x:\",ele.attrib['x'],\"\\t y:\",ele.attrib['y'])\n",
    "                x1,y1=int(ele.attrib['x']),int(ele.attrib['y'])\n",
    "                x2,y2=x1+int(ele.attrib['width']),y1+int(ele.attrib['height'])\n",
    "                #img1.line((x1,y1,x2,y2),fill=\"green\",width=10)                \n",
    "                #img1.rectangle(((x1,y1), (x2,y2)), fill=\"green\")\n",
    "\n",
    "                d[\"cord\"].append([x1,y1,x2,y2])\n",
    "\n",
    "                allCords=mergeCoordinate(d)\n",
    "                cord=allCords[0]\n",
    "                x1,y1,x2,y2=cord[0],cord[1],cord[2],cord[3]\n",
    "                area=abs(x2-x1)*abs(y2-y1)\n",
    "                #img1.rectangle(((x1,y1), (x2,y2)),outline = \"red\",width=3)\n",
    "                #d={}\n",
    "                \n",
    "        if indx%5==0:\n",
    "            df.to_csv(\"./data/data3.csv\",index=False)\n",
    "\n",
    "    df.to_csv(\"./data/data3.csv\",index=False)\n",
    "    #print(\"\\n\\t uunique files:\",len(df.image_name.unique()))    \n",
    "    #img.save(\"./temp/\"+nm+\".png\")\n",
    "    #img=img.resize((500,400))\n",
    "    #show(img,imgName)\n",
    "    #input(\"press\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "    now add phoc and phos label\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phos_label_generator import gen_label\n",
    "from phoc_label_generator import gen_phoc_label\n",
    "\n",
    "#generate_phoc_vector(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-389ef21895cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_word_phos_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\t len:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_word_phos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_word_phoc_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_phoc_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\t len:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_word_phoc_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/phd/TensorFlow-2.x-YOLOv3/phos_label_generator.py\u001b[0m in \u001b[0;36mgen_label\u001b[0;34m(word_list)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/phd/TensorFlow-2.x-YOLOv3/phos_label_generator.py\u001b[0m in \u001b[0;36mgenerate_label\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/phd/TensorFlow-2.x-YOLOv3/phos_label_generator.py\u001b[0m in \u001b[0;36mword_vector\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_num_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mletter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mletter_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malphabet_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mletter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mvector\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnumpy_csv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mletter_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '2'"
     ]
    }
   ],
   "source": [
    "train_word_phos_label = gen_label(list(set(df['text'])))\n",
    "print(\"\\n\\t len:\",len(train_word_phos_label))\n",
    "\n",
    "train_word_phoc_label = gen_phoc_label(list(set(df['text'])))\n",
    "print(\"\\n\\t len:\",len(train_word_phoc_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "len(list(set(df['text'])))\n",
    "word=list(set(df['text']))\n",
    "\n",
    "\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "#First parameter is the replacement, second parameter is your input string\n",
    "\n",
    "tempPhos=[0]*165\n",
    "tempPhoc=[0.0]*604\n",
    "#output['Sold Count'] = output['Sold Count'].astype(object)\n",
    "df[\"phos\"]=df[\"phos\"].astype(object)\n",
    "\n",
    "for indx,row in df.iterrows():\n",
    "    \n",
    "#     if indx>100:\n",
    "#         break\n",
    "    \n",
    "    try:\n",
    "        #print(\"\\n\\t w1:\",w)\n",
    "        w=row[\"text\"]\n",
    "        w=regex.sub('', w)\n",
    "        #print(\"\\n\\t w2:\",w)\n",
    "        if len(w):\n",
    "            phos_label = gen_label([w])\n",
    "            phoc_label = gen_phoc_label([w])\n",
    "            #print(\"\\n\\t train_word_phos_label=\",train_word_phos_label)\n",
    "            #print(\"\\n\\t keys:\",len(phos_label[w]))\n",
    "            #print(\"\\n\\t type:\",type(phos_label[w]))\n",
    "            #print(\"\\n\\t phos_label[w]=\",phos_label[w])\n",
    "            #df.loc[indx,\"phoc\"]=str(phos_label[w]) gen_phoc_label\n",
    "            \n",
    "            #print(\"\\n\\t phos_label =\",len(phos_label[w].tolist()))\n",
    "            #print(\"\\n\\t phoc_label =\",len(phoc_label[w]))\n",
    "\n",
    "            df.at[indx,\"phoc\"]=phoc_label[w]\n",
    "            df.at[indx,\"phos\"]=phos_label[w]#.tolist()\n",
    "\n",
    "        else:\n",
    "            df.at[indx,\"phoc\"]=tempPhoc\n",
    "            df.at[indx,\"phos\"]=tempPhos\n",
    "\n",
    "        #input(\"check!!\")\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"\\n\\t w:\",w,\"\\t indx:\",indx,\"\\t e:\",e)\n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "        print(\"\\n\\t line number:\", exc_tb.tb_lineno)\n",
    "        input(\"check!!!\")\n",
    "df.to_csv(\"./data/data3_phosc.csv\")\n",
    "#train_word_phos_label = gen_label(list(set(df['text'])))\n",
    "#train_word_phos_label = gen_label(word[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "#df.dtypes\n",
    "phos=df.loc[0,\"phoc\"]\n",
    "#phos\n",
    "#phos[7]\n",
    "#len(phos)\n",
    "\n",
    "#phos_label = gen_label([w])\n",
    "#type(phos_label[w].tolist())\n",
    "#type(phoc_label[w])\n",
    "#phos_label[w]#.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install Pillow --y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "path=\"/home/k/phd/yolov5/runs/detect/exp7/\"\n",
    "path1=\"/home/k/phd/yolov5/runs/detect/compress/\"\n",
    "\n",
    "imgList=os.listdir(path)\n",
    "\n",
    "for indx,nm in enumerate(imgList):\n",
    "    \n",
    "    img=Image.open(path+nm)\n",
    "    img=img.resize((500,400))\n",
    "    \n",
    "    img.save(path1+nm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    text file creation for YOLO\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to illustrate\n",
    "# Append vs write mode\n",
    "file1 = open(\"myfile.txt\", \"w\")\n",
    "L = [\"This is Delhi \\n\", \"This is Paris \\n\", \"This is London\"]\n",
    "file1.writelines(L)\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/k/phd/yolov5/data/data3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-0d3723e43b51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/k/phd/yolov5/data/data3.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yolo_keras/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yolo_keras/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yolo_keras/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yolo_keras/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yolo_keras/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1218\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yolo_keras/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    790\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/k/phd/yolov5/data/data3.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "data=pd.read_csv(\"/home/k/phd/yolov5/data/data3.csv\")\n",
    "data.shape\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for file in ['train','test']:\n",
    "import numpy as np\n",
    "import os\n",
    "'''\n",
    "allImages=os.listdir(\"/home/k/phd/yolov5/data/datasets/forms/\")\n",
    "images_num=len(os.listdir(\"/home/k/phd/yolov5/data/datasets/forms/\"))\n",
    "images_path = \"/home/k/phd/yolov5/data/datasets/forms/\"#os.getcwd()+f\"/mnist_{file}\"\n",
    "labels_txt = os.getcwd()+\"/\"+\"mnist_train.txt\"\n",
    "labels_txt2 = os.getcwd()+\"/\"+\"mnist_test.txt\"\n",
    "'''\n",
    "\n",
    "allImages=os.listdir(\"/home/k/phd/yolov5/data/datasets/forms/\")\n",
    "images_num=len(os.listdir(\"/home/k/phd/yolov5/data/datasets/forms/\"))\n",
    "images_path = \"/home/k/phd/yolov5/data/datasets/forms/\"#os.getcwd()+f\"/mnist_{file}\"\n",
    "labels_txt = os.getcwd()+\"/\"+\"mnist_train.txt\"\n",
    "labels_txt2 = os.getcwd()+\"/\"+\"mnist_test.txt\"\n",
    "\n",
    "lastName=\"\"\n",
    "curLine=\"\"\n",
    "prevLine=\"\"\n",
    "unqImg=[]\n",
    "exceptionCount=0\n",
    "\n",
    "for indx,info in df.iterrows():\n",
    "    try:\n",
    "        if indx%10==0:\n",
    "            print(\"\\n\\t unq images:\",len(unqImg))\n",
    "\n",
    "        if len(unqImg)<100:\n",
    "\n",
    "            with open(labels_txt, \"a\") as wf:\n",
    "                image_path =images_path+info[\"image_name\"]\n",
    "\n",
    "                if indx%100==0:\n",
    "                    print(\"\\n\\t path:\",image_path)\n",
    "\n",
    "                if info[\"image_name\"]!=lastName and info[\"image_name\"] not in unqImg:\n",
    "                    curLine=image_path\n",
    "\n",
    "                    if len(prevLine):\n",
    "                        #print(\"\\n\\t prevLine:\",prevLine)\n",
    "                        #wf.write( image_path+ \"\\n\")\n",
    "                        wf.write(prevLine+\"\\n\")\n",
    "\n",
    "                else:\n",
    "                    xmin,ymin=str(int(info[\"org_x1\"])),str(int(info[\"org_y1\"]))\n",
    "                    xmax,ymax=str(int(info[\"org_x2\"])),str(int(info[\"org_y2\"]))\n",
    "                    curLine += ' ' + ','.join([xmin, ymin, xmax, ymax, str(0)])\n",
    "                    prevLine=curLine\n",
    "\n",
    "                lastName=info[\"image_name\"]\n",
    "\n",
    "        elif 100<len(unqImg)<200:\n",
    "\n",
    "            with open(labels_txt2, \"a\") as wf:\n",
    "                image_path =images_path+info[\"image_name\"]\n",
    "\n",
    "                if indx%100==0:\n",
    "                    print(\"\\n\\t path:\",image_path)\n",
    "\n",
    "                if info[\"image_name\"]!=lastName:\n",
    "                    curLine=image_path\n",
    "\n",
    "                    if len(prevLine):\n",
    "                        #print(\"\\n\\t prevLine:\",prevLine)\n",
    "                        #wf.write( image_path+ \"\\n\")\n",
    "                        wf.write(prevLine+\"\\n\")\n",
    "\n",
    "                else:\n",
    "                    xmin,ymin=str(int(info[\"org_x1\"])),str(int(info[\"org_y1\"]))\n",
    "                    xmax,ymax=str(int(info[\"org_x2\"])),str(int(info[\"org_y2\"]))\n",
    "                    curLine += ' ' + ','.join([xmin, ymin, xmax, ymax, str(0)])\n",
    "                    prevLine=curLine\n",
    "\n",
    "                lastName=info[\"image_name\"]\n",
    "        elif 200<len(unqImg):\n",
    "            break\n",
    "            \n",
    "        if info[\"image_name\"] not in unqImg:\n",
    "            unqImg.append(info[\"image_name\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        exceptionCount+=1\n",
    "        print(\"\\n\\t exception index:\",indx,\"\\t count:\",exceptionCount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t df: (115187, 16)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    below part convert dataframe to json \n",
    "'''\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"/home/k/phd/TensorFlow-2.x-YOLOv3/data/data3_phosc.csv\")\n",
    "print(\"\\n\\t df:\",df.shape)\n",
    "#df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#gen_phoc_label([info['text']])[info['text']]\\n#gen_label([info['text']])[info['text']]\\n\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "d=collections.defaultdict(dict)\n",
    "tempDir={}\n",
    "tempCord={}\n",
    "tempText={}\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "\n",
    "for indx,info in df.iterrows():\n",
    "    \n",
    "    tempDir2={}\n",
    "    #print(\"\\n\\t name:\",info[\"image_name\"])\n",
    "    temp=[info['org_x1'],info['org_y1'],info['org_x2'],info['org_y2']]\n",
    "    '''\n",
    "    tempDir2[\"text\"]=info['text']\n",
    "    ''' \n",
    "    w=info['text']\n",
    "    w=regex.sub('', w)\n",
    "    #print(\"\\n\\t w2:\",w)\n",
    "    \n",
    "    if len(w):\n",
    "\n",
    "        tempDir2[\"phoc\"]=np.asarray(gen_phoc_label([w])[w]).astype(np.float32)\n",
    "        tempDir2[\"phos\"]=np.asarray(gen_label([w])[w]).astype(np.float32)\n",
    "        tempText[info['text']]=tempDir2\n",
    "    else:\n",
    "        \n",
    "        tempDir2[\"phoc\"]=np.zeros(604)\n",
    "        tempDir2[\"phos\"]=np.zeros(165)\n",
    "        tempText[info['text']]=tempDir2\n",
    "    \n",
    "    \n",
    "'''\n",
    "#gen_phoc_label([info['text']])[info['text']]\n",
    "#gen_label([info['text']])[info['text']]\n",
    "'''\n",
    "#tempText.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"1\",type(b[\\'it\\']))\\nprint(\"2\",type(tempText[\\'it\\']))\\nprint(b.keys())\\nprint(tempText.keys())\\nprint(\"1.\",b)\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for ele in info['phos']\n",
    "#vec=gen_label([\"remained\"])['remained']\n",
    "#tempDict={}\n",
    "#tempDict[\"remained\"]=vec\n",
    "#type(tempDict[\"remained\"])\n",
    "\n",
    "# with open(\"./data/delMe.json\", \"w\") as outfile:\n",
    "#     json.dump(tempDict, outfile)\n",
    "\n",
    "# f = open(\"./data/delMe.json\")\n",
    "# tempDict2= json.load(f)\n",
    "# type(tempDict2[\"remained\"])\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "with open('filename.pickle', 'wb') as handle:\n",
    "    pickle.dump(tempText, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('filename.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "\n",
    "#print (tempText == b)\n",
    "'''\n",
    "print(\"1\",type(b['it']))\n",
    "print(\"2\",type(tempText['it']))\n",
    "print(b.keys())\n",
    "print(tempText.keys())\n",
    "print(\"1.\",b)\n",
    "'''\n",
    "#print(\"2.\",tempText)\n",
    "#dict_keys(['it', 'his', 'imagination', 'or', 'was', 'the', 'panel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=list(b.keys())[0]\n",
    "len(b[t]['phos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(\"./data/dataframe.json\", \"w\") as outfile:\\n    json.dump(d, outfile)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "f = open(\"./data/tempCord.json\")\n",
    "tempCord1= json.load(f)\n",
    "\n",
    "f = open(\"./data/tempText.json\")\n",
    "tempText1 = json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "with open(\"./data/dataframe.json\", \"w\") as outfile:\n",
    "    json.dump(d, outfile)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gen_phoc_label([info['text']])[info['text']]\n",
    "#gen_label([info['text']])[info['text']]\n",
    "#tempDir2.keys()\n",
    "#tempText\n",
    "#type(b['it']['phos'])\n",
    "tempText['it']['phoc'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
