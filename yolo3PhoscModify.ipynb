{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69c2b1af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7044496786814994958\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10359979392\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12167163932474956454\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\"\n",
      "]\n",
      "\n",
      "\t YOLO_TYPE: yolov3\n",
      "--> model_data/yolov3.weights\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "from yolov3.dataset import Dataset\n",
    "from yolov3.yolov4 import Create_Yolo, compute_loss,Create_YoloPhosc\n",
    "from yolov3.utils import load_yolo_weights\n",
    "from yolov3.configs import *\n",
    "from evaluate_mAP import get_mAP\n",
    "\n",
    "print(\"\\n\\t YOLO_TYPE:\",YOLO_TYPE)\n",
    "\n",
    "if YOLO_TYPE == \"yolov3\":\n",
    "    Darknet_weights = YOLO_V3_TINY_WEIGHTS if TRAIN_YOLO_TINY else YOLO_V3_WEIGHTS\n",
    "\n",
    "    \n",
    "print(\"-->\",Darknet_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc7ccd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "\n",
      "\t inside custome yolo!!!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MyReLU' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6b67d03b6aa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#yolo = Create_Yolo(input_size=YOLO_INPUT_SIZE, training=True, CLASSES=TRAIN_CLASSES)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0myolo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCreate_YoloPhosc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mYOLO_INPUT_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLASSES\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRAIN_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTRAIN_FROM_CHECKPOINT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/phd/TensorFlow-2.x-YOLOv3/yolov3/yolov4.py\u001b[0m in \u001b[0;36mCreate_YoloPhosc\u001b[0;34m(input_size, channels, training, CLASSES)\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0mrandomTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\t s:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m     \u001b[0mYolo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mYolo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MyReLU' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\n",
    "from yolov3.yolov4 import Create_YoloPhosc\n",
    "\n",
    "global TRAIN_FROM_CHECKPOINT\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(f'GPUs {gpus}')\n",
    "if len(gpus) > 0:\n",
    "    try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError: pass\n",
    "\n",
    "if os.path.exists(TRAIN_LOGDIR): shutil.rmtree(TRAIN_LOGDIR)\n",
    "writer = tf.summary.create_file_writer(TRAIN_LOGDIR)\n",
    "\n",
    "trainset = Dataset('train')\n",
    "testset = Dataset('test')\n",
    "\n",
    "\n",
    "if len(gpus) > 0:\n",
    "    try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError: pass\n",
    "\n",
    "if os.path.exists(TRAIN_LOGDIR): shutil.rmtree(TRAIN_LOGDIR)\n",
    "writer = tf.summary.create_file_writer(TRAIN_LOGDIR)\n",
    "\n",
    "trainset = Dataset('train')\n",
    "testset = Dataset('test')\n",
    "\n",
    "steps_per_epoch = len(trainset)\n",
    "global_steps = tf.Variable(1, trainable=False, dtype=tf.int64)\n",
    "warmup_steps = TRAIN_WARMUP_EPOCHS * steps_per_epoch\n",
    "total_steps = TRAIN_EPOCHS * steps_per_epoch\n",
    "\n",
    "if TRAIN_TRANSFER:\n",
    "    #Darknet = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=YOLO_COCO_CLASSES)\n",
    "    Darknet = Create_YoloPhosc(input_size=YOLO_INPUT_SIZE, CLASSES=YOLO_COCO_CLASSES)\n",
    "\n",
    "    print(\"Darknet_weights=\",os.path.isfile(Darknet_weights))\n",
    "    load_yolo_weights(Darknet, Darknet_weights) # use darknet weights\n",
    "    \n",
    "#yolo = Create_Yolo(input_size=YOLO_INPUT_SIZE, training=True, CLASSES=TRAIN_CLASSES)\n",
    "yolo=Create_YoloPhosc(input_size=YOLO_INPUT_SIZE, training=True, CLASSES=TRAIN_CLASSES)\n",
    "\n",
    "if TRAIN_FROM_CHECKPOINT:\n",
    "    try:\n",
    "        print(\"\\n\\t load weights!!!\")\n",
    "        yolo.load_weights(f\"./checkpoints/{TRAIN_MODEL_NAME}\")\n",
    "        print(\"\\n\\t loading complete\")\n",
    "\n",
    "    except ValueError:\n",
    "        print(\"Shapes are incompatible, transfering Darknet weights\")\n",
    "        TRAIN_FROM_CHECKPOINT = False\n",
    "\n",
    "if TRAIN_TRANSFER and not TRAIN_FROM_CHECKPOINT:\n",
    "    for i, l in enumerate(Darknet.layers):\n",
    "        layer_weights = l.get_weights()\n",
    "        if layer_weights != []:\n",
    "            try:\n",
    "                yolo.layers[i].set_weights(layer_weights)\n",
    "            except:\n",
    "                print(\"skipping\", yolo.layers[i].name)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "\n",
    "\n",
    "#mAP_model = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=TRAIN_CLASSES) # create second model to measure mAP\n",
    "\n",
    "best_val_loss = 1000 # should be large at start\n",
    "\n",
    "#print(\"\\n\\t mAP_model =\",mAP_model)\n",
    "\n",
    "#print(\"\\n\\t yolo:\",yolo.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba666a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supportFunctions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e364cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_step(image_data, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = yolo(image_data, training=False)\n",
    "        pred_result =pred_result[0]\n",
    "#         if type(pred_result) is list:\n",
    "#             pred_result =pred_result[0]\n",
    "        giou_loss=conf_loss=prob_loss=0\n",
    "\n",
    "        # optimizing process\n",
    "        grid = 1 if not TRAIN_YOLO_TINY else 2\n",
    "        for i in range(grid):\n",
    "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "            loss_items = compute_loss(pred, conv, *target[i], i, CLASSES=TRAIN_CLASSES)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "\n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "\n",
    "    return giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_step(counter,image_data, target):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = yolo(image_data, training=True)\n",
    "        #print(\"\\n\\t image_data:\",image_data.shape)\n",
    "        \n",
    "        image2=tf.squeeze(image_data)\n",
    "    \n",
    "        giou_loss=conf_loss=prob_loss=0\n",
    "\n",
    "        # optimizing process\n",
    "        grid = 3 if not TRAIN_YOLO_TINY else 2\n",
    "        for i in range(grid):\n",
    "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "            loss_items = compute_loss(pred, conv, *target[i], i, CLASSES=TRAIN_CLASSES)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "\n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "\n",
    "        gradients = tape.gradient(total_loss, yolo.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, yolo.trainable_variables))\n",
    "\n",
    "        # update learning rate\n",
    "        # about warmup: https://arxiv.org/pdf/1812.01187.pdf&usg=ALkJrhglKOPDjNt6SHGbphTHyMcT0cuMJg\n",
    "        global_steps.assign_add(1)\n",
    "        if global_steps < warmup_steps:# and not TRAIN_TRANSFER:\n",
    "            lr = global_steps / warmup_steps * TRAIN_LR_INIT\n",
    "        else:\n",
    "            lr = TRAIN_LR_END + 0.5 * (TRAIN_LR_INIT - TRAIN_LR_END)*(\n",
    "                (1 + tf.cos((global_steps - warmup_steps) / (total_steps - warmup_steps) * np.pi)))\n",
    "        optimizer.lr.assign(lr.numpy())\n",
    "\n",
    "        # writing summary data\n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar(\"lr\", optimizer.lr, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/total_loss\", total_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/giou_loss\", giou_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/conf_loss\", conf_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/prob_loss\", prob_loss, step=global_steps)\n",
    "        writer.flush()\n",
    "        \n",
    "        \n",
    "    pred_result = yolo(image_data, training=False)\n",
    "    #print(\"\\n\\t image_data:\",image_data.shape)\n",
    "\n",
    "    image2=tf.squeeze(image_data)\n",
    "\n",
    "    '''\n",
    "    print(\"\\n\\t\\t 1.pred_result =\",pred_result[0].shape)\n",
    "    print(\"\\n\\t\\t 2.pred_result =\",pred_result[1].shape)\n",
    "    pri t(\"\\n\\t\\t 3.pred_result =\",pred_result[2].shape)\n",
    "    '''\n",
    "    #print(\"\\n\\t image2=\",image2.shape)\n",
    "    #pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_result]\n",
    "    #print(\"\\n\\t pred_bbox =\",pred_bbox )\n",
    "    #pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "\n",
    "\n",
    "    # optimizing process\n",
    "    grid = 3 if not TRAIN_YOLO_TINY else 2\n",
    "    for i in range(grid):\n",
    "\n",
    "        '''\n",
    "            these r 3 feature maps of size 52*52,26*26,13*13,\n",
    "        '''\n",
    "        conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "\n",
    "        '''\n",
    "        print(\"\\n\\t\\t conv:\",conv.shape)\n",
    "        print(\"\\n\\t\\t pred =\",pred.shape)\n",
    "        '''\n",
    "\n",
    "        ''' \n",
    "            (xc,yc,w,h,obj,pro) is last dimension of size 6\n",
    "\n",
    "            pred = (1, 13, 13, 3, 6) is reshaped to \n",
    "            pred_bbox = (507, 6)   169 is len of single anchor tot 3 vectors             \n",
    "\n",
    "            conv: (1, 26, 26, 18)\n",
    "            pred = (1, 26, 26, 3, 6)\n",
    "            pred_bbox = (2028, 6)  676 is lenght of single anchor tot 3 vectors\n",
    "\n",
    "            image_data= (1, 416, 416, 3)\n",
    "            pred = (1, 52, 52, 3, 6)\n",
    "            pred_bbox = (8112, 6)  2704 is len of single anchor tot 3 vectors\n",
    "\n",
    "        '''\n",
    "\n",
    "        pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred]\n",
    "        pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "\n",
    "        #print(\"\\n\\t pred_bbox =\",pred_bbox.shape)\n",
    "\n",
    "        ''' \n",
    "        this removes invalid boxes like boxes having low confidence or \n",
    "        which has size greater than image\n",
    "\n",
    "        '''\n",
    "\n",
    "        bboxes = postprocess_boxes(pred_bbox, image2.numpy(), YOLO_INPUT_SIZE,0.3)\n",
    "        #print(\"\\n\\t befor nms bboxes =\",bboxes.shape)\n",
    "\n",
    "\n",
    "        bboxes = nms(bboxes, 0.45, method='nms')\n",
    "        \n",
    "        '''\n",
    "        print(\"\\n\\t after nms 1.bboxes =\",len(bboxes))\n",
    "        print(\"\\n\\t after nms 2.bboxes =\",len(bboxes))\n",
    "        '''\n",
    "        resultImage = draw_bbox(counter,i,255*image2.numpy(), bboxes, CLASSES=YOLO_COCO_CLASSES, rectangle_colors=\"\")\n",
    "        #cv2.imwrite(f'./pred/{counter}.png',resultImage)\n",
    "        #input(\"check\")\n",
    "\n",
    "\n",
    "    return global_steps.numpy(), optimizer.lr.numpy(), giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()\n",
    "\n",
    "#mAP_model = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=TRAIN_CLASSES) # create second model to measure mAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51eb1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolov3.utils import detect_image1\n",
    "\n",
    "\n",
    "def predImg(image2):\n",
    "    \n",
    "    try:\n",
    "        detect_image1(image2,\"\", \"mnist_test.jpg\", input_size=YOLO_INPUT_SIZE, show=True, CLASSES=TRAIN_CLASSES, rectangle_colors=(0,0,255))\n",
    "    except Exception as e:\n",
    "        print(\"\\n\\t detect issue!!\")\n",
    "\n",
    "def train_step1(nm,counter,image_data, target):\n",
    "    \n",
    "    image2=tf.squeeze(image_data)\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = yolo(image_data, training=True)\n",
    "        print(\"\\n\\t pred_result =>>\",len(pred_result))\n",
    "        print(\"\\n\\t part:\",len(pred_result[1]))\n",
    "        #print(\"\\n\\t image_data:\",image_data.shape)\n",
    "        pred_result =pred_result[0]\n",
    "#         if type(pred_result) is list:\n",
    "#             pred_result =pred_result[0]\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        print(\"\\n\\t\\t 1.pred_result =\",pred_result[0].shape)\n",
    "        print(\"\\n\\t\\t 2.pred_result =\",pred_result[1].shape)\n",
    "        pri t(\"\\n\\t\\t 3.pred_result =\",pred_result[2].shape)\n",
    "        '''\n",
    "        #print(\"\\n\\t image2=\",image2.shape)\n",
    "        #pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_result]\n",
    "        #print(\"\\n\\t pred_bbox =\",pred_bbox )\n",
    "        #pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "\n",
    "  \n",
    "        giou_loss=conf_loss=prob_loss=0\n",
    "        \n",
    "        allBox=[]\n",
    "        # optimizing process\n",
    "        grid = 1 if not TRAIN_YOLO_TINY else 1\n",
    "        for i in range(grid):\n",
    "            \n",
    "            '''\n",
    "                these r 3 feature maps of size 52*52,26*26,13*13,\n",
    "            '''\n",
    "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "            #pred=pred[0]  0,1   2,3 4,5\n",
    "\n",
    "            print(\"\\n\\t\\t pred =\",len(pred))\n",
    "            print(\"\\n\\t\\t pred =\",pred[0].shape)\n",
    "            \n",
    "            try:\n",
    "                print(\"\\n\\t\\t pred =\",pred.shape)\n",
    "\n",
    "            except Exception as e:\n",
    "                    pass\n",
    "\n",
    " \n",
    "            '''\n",
    "            print(\"\\n\\t\\t conv:\",conv.shape)\n",
    "            print(\"\\n\\t\\t pred =\",pred.shape)\n",
    "            '''\n",
    "            \n",
    "            ''' \n",
    "                (xc,yc,w,h,obj,pro) is last dimension of size 6\n",
    "                \n",
    "                pred = (1, 13, 13, 3, 6) is reshaped to \n",
    "                pred_bbox = (507, 6)   169 is len of single anchor tot 3 vectors             \n",
    "\n",
    "                conv: (1, 26, 26, 18)\n",
    "                pred = (1, 26, 26, 3, 6)\n",
    "                pred_bbox = (2028, 6)  676 is lenght of single anchor tot 3 vectors\n",
    "\n",
    "                image_data= (1, 416, 416, 3)\n",
    "                pred = (1, 52, 52, 3, 6)\n",
    "                pred_bbox = (8112, 6)  2704 is len of single anchor tot 3 vectors\n",
    "\n",
    "            '''\n",
    "            pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred]\n",
    "            #print(\"\\n\\t 2.pred_bbox =\",pred_bbox.shape)\n",
    "\n",
    "            pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "\n",
    "            #print(\"\\n\\t 1.pred_bbox =\",pred_bbox.shape)\n",
    "            \n",
    "            ''' \n",
    "            this removes invalid boxes like boxes having low confidence or \n",
    "            which has size greater than image\n",
    "\n",
    "            '''\n",
    "            \n",
    "            bboxes = postprocess_boxes(pred_bbox, image2.numpy(), YOLO_INPUT_SIZE,0.3)\n",
    "            print(\"\\n\\t befor nms bboxes =\",bboxes.shape)\n",
    "            \n",
    "            \n",
    "            bboxes = nms(bboxes, 0.45, method='nms')\n",
    "\n",
    "            print(\"\\n\\t after nms 1.bboxes =\",len(bboxes))\n",
    "            print(\"\\n\\t after nms 2.bboxes =\",len(bboxes))\n",
    "            \n",
    "            \n",
    "            if len(bboxes)>20:\n",
    "                allBox.append(bboxes)\n",
    "            \n",
    "            resultImage = draw_bbox(nm,counter,i,255*image2.numpy(), bboxes, CLASSES=YOLO_COCO_CLASSES, rectangle_colors=\"\")\n",
    "            #cv2.imwrite(f'./pred/{counter}.png',resultImage)\n",
    "            #input(\"check\")\n",
    "\n",
    "            loss_items = compute_loss(pred, conv, *target[i], i, CLASSES=TRAIN_CLASSES)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "\n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "\n",
    "        gradients = tape.gradient(total_loss, yolo.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, yolo.trainable_variables))\n",
    "\n",
    "        # update learning rate\n",
    "        # about warmup: https://arxiv.org/pdf/1812.01187.pdf&usg=ALkJrhglKOPDjNt6SHGbphTHyMcT0cuMJg\n",
    "        global_steps.assign_add(1)\n",
    "        if global_steps < warmup_steps:# and not TRAIN_TRANSFER:\n",
    "            lr = global_steps / warmup_steps * TRAIN_LR_INIT\n",
    "        else:\n",
    "            lr = TRAIN_LR_END + 0.5 * (TRAIN_LR_INIT - TRAIN_LR_END)*(\n",
    "                (1 + tf.cos((global_steps - warmup_steps) / (total_steps - warmup_steps) * np.pi)))\n",
    "        optimizer.lr.assign(lr.numpy())\n",
    "\n",
    "        # writing summary data\n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar(\"lr\", optimizer.lr, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/total_loss\", total_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/giou_loss\", giou_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/conf_loss\", conf_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/prob_loss\", prob_loss, step=global_steps)\n",
    "        writer.flush()\n",
    "\n",
    "        \n",
    "    '''\n",
    "        call PHOSCNET function\n",
    "    '''\n",
    "    predImg(image2.numpy())\n",
    "\n",
    "    #return image2.numpy(),global_steps.numpy(), optimizer.lr.numpy(), giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7950d15e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validate_writer = tf.summary.create_file_writer(TRAIN_LOGDIR)\n",
    "\n",
    "yoloLoad=None\n",
    "for epoch in range(2):\n",
    "    print(\"\\n\\t epoch:\",epoch)\n",
    "    counter=0\n",
    "    for batch_no,(image_data, target) in enumerate(trainset):\n",
    "        nm=str(np.random.randint(10000))+\".png\"\n",
    "        print(\"\\n\\t image_data=\",image_data.shape)    \n",
    "        train_step1(nm,counter,image_data, target)\n",
    "        #print(\"\\n\\t loss:\",results)\n",
    "        counter+=1\n",
    "        \n",
    "        #prediction()\n",
    "        #input(\"check!!!\")\n",
    "        '''\n",
    "        pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in result]\n",
    "        pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "\n",
    "        print(\"\\n\\t pred_bbox =\",pred_bbox )\n",
    "        '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf596f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
