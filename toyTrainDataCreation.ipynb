{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2cc3c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from phos_label_generator import gen_label\n",
    "from phoc_label_generator import gen_phoc_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d342ae21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115187, 13)\n",
      " no of unique words: 13550\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>class</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>org_x1</th>\n",
       "      <th>org_y1</th>\n",
       "      <th>org_x2</th>\n",
       "      <th>org_y2</th>\n",
       "      <th>text</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g06-031n.png</td>\n",
       "      <td>1</td>\n",
       "      <td>2479</td>\n",
       "      <td>3542</td>\n",
       "      <td>435</td>\n",
       "      <td>678</td>\n",
       "      <td>450</td>\n",
       "      <td>697</td>\n",
       "      <td>'</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g06-031n.png</td>\n",
       "      <td>1</td>\n",
       "      <td>2479</td>\n",
       "      <td>3542</td>\n",
       "      <td>425</td>\n",
       "      <td>683</td>\n",
       "      <td>663</td>\n",
       "      <td>777</td>\n",
       "      <td>What</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g06-031n.png</td>\n",
       "      <td>1</td>\n",
       "      <td>2479</td>\n",
       "      <td>3542</td>\n",
       "      <td>640</td>\n",
       "      <td>726</td>\n",
       "      <td>696</td>\n",
       "      <td>779</td>\n",
       "      <td>a</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g06-031n.png</td>\n",
       "      <td>1</td>\n",
       "      <td>2479</td>\n",
       "      <td>3542</td>\n",
       "      <td>727</td>\n",
       "      <td>685</td>\n",
       "      <td>1128</td>\n",
       "      <td>820</td>\n",
       "      <td>frightful</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g06-031n.png</td>\n",
       "      <td>1</td>\n",
       "      <td>2479</td>\n",
       "      <td>3542</td>\n",
       "      <td>1129</td>\n",
       "      <td>692</td>\n",
       "      <td>1365</td>\n",
       "      <td>779</td>\n",
       "      <td>event</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  class  width  height  org_x1  org_y1  org_x2  org_y2  \\\n",
       "0  g06-031n.png      1   2479    3542     435     678     450     697   \n",
       "1  g06-031n.png      1   2479    3542     425     683     663     777   \n",
       "2  g06-031n.png      1   2479    3542     640     726     696     779   \n",
       "3  g06-031n.png      1   2479    3542     727     685    1128     820   \n",
       "4  g06-031n.png      1   2479    3542    1129     692    1365     779   \n",
       "\n",
       "        text     x     y     w     h  \n",
       "0          '  0.18  0.19  0.01  0.01  \n",
       "1       What  0.22  0.21  0.10  0.03  \n",
       "2          a  0.27  0.21  0.02  0.01  \n",
       "3  frightful  0.37  0.21  0.16  0.04  \n",
       "4      event  0.50  0.21  0.10  0.02  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPath=\"/home/aniketag/Documents/phd/yolov5/data/datasets/data_444_april.csv\"\n",
    "\n",
    "df=pd.read_csv(dataPath)\n",
    "df.reset_index(drop=True)\n",
    "\n",
    "print(df.shape)\n",
    "print(\" no of unique words:\",len(df.text.unique()))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26527918",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    get most frequent words\n",
    "\"\"\"\n",
    "\n",
    "textFreq=df.text.value_counts()\n",
    "\n",
    "\"\"\"\n",
    "    most frquent words by observation of frequency\n",
    "\"\"\"\n",
    "words=[\"the\",\"of\",\"to\",\"and\",\"was\",\"that\",\"with\",\"which\",\"have\",\"would\",\"their\",\"there\",\"about\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe17377f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the        5825\n",
       ",          5555\n",
       ".          4939\n",
       "of         3191\n",
       "to         2648\n",
       "           ... \n",
       "Hal's         1\n",
       "Stan          1\n",
       "Bombay        1\n",
       "Monty         1\n",
       "rescued       1\n",
       "Name: text, Length: 13550, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#textFreq[50:100]\n",
    "textFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c1a5281",
   "metadata": {},
   "outputs": [],
   "source": [
    "testImgPath=\"/home/aniketag/Documents/phd/yolov5/data/datasets/forms//\" \n",
    "cropSavePath=\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/data/toyData_1_#05-2022-28-1#//\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32a7bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bbd30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a682b736",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "    BELOW CROPS FOR WORDS ARE CREATED\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e532b1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " word: the  temp: (5825, 6)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m imgName,x1,y1,x2,y2,text\u001b[38;5;241m=\u001b[39mrow\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m imgName\u001b[38;5;241m!=\u001b[39mlastImageName:\n\u001b[0;32m---> 22\u001b[0m     image\u001b[38;5;241m=\u001b[39m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestImgPath\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mimgName\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m#print(\"image=\",image.shape)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "lastImageName=\"\"\n",
    "\n",
    "for word in words:\n",
    "    \n",
    "    temp=df[df[\"text\"]==word]\n",
    "    temp=temp[[\"image_name\",\"org_x1\",\"org_y1\",\"org_x2\",\"org_y2\",\"text\"]]\n",
    "    \n",
    "    print(\" word:\",word,\" temp:\",temp.shape)\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(cropSavePath+word)\n",
    "    \n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    for indx,row in temp.iterrows():\n",
    "    \n",
    "        imgName,x1,y1,x2,y2,text=row\n",
    "        \n",
    "        if imgName!=lastImageName:\n",
    "            \n",
    "            image=cv2.imread(testImgPath+imgName)\n",
    "            #print(\"image=\",image.shape)\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        \"\"\"\n",
    "            crate crops\n",
    "        \"\"\"\n",
    "            \n",
    "        cropped_image = image[y1-10:y2+20, x1-10:x2+20]\n",
    " \n",
    "        cv2.imwrite(cropSavePath+word+\"//\"+imgName+\"_\"+str([x1,y1,x2,y2])+\"_\"+text+\".png\",cropped_image)\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbc8475",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "    CREATE A PAGES FROM ABOVE CROPS\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4416b6a0",
   "metadata": {},
   "source": [
    "    \"\"\"\n",
    "    1. randoly select number of words n \n",
    "    2. select n words from set of available words\n",
    "    3.select crop randomly from available crops\n",
    "    4. paste crop in sentence randomly decide spacing\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b025f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[\"the\",\"of\",\"and\",\"that\",\"have\",\"which\",\"would\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "470a1c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint\n",
    "import os\n",
    "randint(0,len(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "078b4ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['have',\n",
       " 'which',\n",
       " 'to',\n",
       " 'was',\n",
       " 'with',\n",
       " 'mnist_test1_toy_#05-2022-28-1#.txt',\n",
       " 'of',\n",
       " 'would',\n",
       " 'the',\n",
       " 'mnist_train1.txt',\n",
       " 'and',\n",
       " 'mnist_test1.txt',\n",
       " 'mnist_train1_toy_#05-2022-28-1#.txt',\n",
       " 'that']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allPaths=\"./data/toyData_#05-2022-28-1#/\"\n",
    "words=os.listdir(allPaths)\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16fc00cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['have',\n",
    " 'which',\n",
    " 'to',\n",
    " 'was',\n",
    " 'with',\n",
    " 'of',\n",
    " 'would',\n",
    " 'the',\n",
    " 'and',\n",
    " 'that']\n",
    "cropsPaths=\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/data/toyCrops_#05-2022-28-1#//\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f96e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsPath=[]\n",
    "\n",
    "for ww in words:\n",
    "    temp=[]\n",
    "    \n",
    "    try:\n",
    "        temp=os.listdir(allPaths+ww)\n",
    "        #print(len(temp))\n",
    "        \n",
    "        #if os.path.isdir(temp):\n",
    "        wordsPath.append(temp)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd57efc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 'b05-055.png_[727, 920, 837, 971]_have.png')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordsPath),wordsPath[0][0]\n",
    "#allPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0fe15c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 93)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.concat([df1, df2], axis=1)'\n",
    "len(words),totWords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b90a40b",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "below part creates a crop of data and corresponding dataframe containing BB, text, \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45404812",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import sys \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "df1=pd.DataFrame(columns=[\"image_name\",\"class\",\"width\",\"height\",\"org_x1\",\"org_y1\",\"org_x2\",\"org_y2\",\"text\",\"x\",\"y\",\"w\",\"h\"])\n",
    "\n",
    "for indx in range(500):\n",
    "\n",
    "    totWords= randint(0,10*len(words))\n",
    "    \n",
    "    orgWidth,orgHeight=1200,200\n",
    "    blank_image = 255*np.ones((800,1200,3), np.uint8)\n",
    "    nm=str(np.random.randint(1000))\n",
    "    x1,y1=10,30\n",
    "    lineNo=0\n",
    "    randLines=np.random.randint(6)\n",
    "    dTemp={}\n",
    "    \n",
    "    for i in range(totWords):\n",
    "\n",
    "        #print(\"\")\n",
    "        wordIndx=randint(0,len(words)-1)\n",
    "        tempPaths=wordsPath[wordIndx]\n",
    "\n",
    "        randCrops=randint(0,len(tempPaths)-1)\n",
    "        randCropPath=tempPaths[randCrops]\n",
    "        #print(\" randCropPath=\",randCropPath)\n",
    "        \n",
    "        textWord=words[wordIndx]\n",
    "        img=cv2.imread(allPaths+textWord+\"//\"+randCropPath)\n",
    "        #print(\" img:\",img.shape)\n",
    "        \n",
    "        try:\n",
    "            h,w,c=img.shape\n",
    "\n",
    "            #print(\" h:\",h,\" w:\",w,\" x1:\",x1,y1,x2,y2)\n",
    "\n",
    "            blank_image[y1:y1+h,x1:x1+w] = img\n",
    "\n",
    "            #w=words[wordIndx]\n",
    "            #print(\" i:\",i,\" wordIndx:\",wordIndx,\" word:\",w,\" totWords:\",totWords)\n",
    "\n",
    "\n",
    "            if x1>1000:\n",
    "                lineNo+=1\n",
    "                x1,y1=0,y1+2*h\n",
    "\n",
    "            if lineNo==randLines:\n",
    "                break\n",
    "                \n",
    "            xYolo,yYolo=(x1+x2)/2,(y1+y2)/2\n",
    "            \n",
    "\n",
    "            dTemp=pd.DataFrame({\"image_name\":[nm+\".png\"],\"class\":[1],\n",
    "                   \"width\":[orgWidth],\"height\":[orgHeight],\"org_x1\":[x1],\"org_y1\":[y1],\"org_x2\":[x2],\"org_y2\":[y2],\n",
    "                   \"text\":[textWord],\"x\":[xYolo],\"y\":[yYolo],\"w\":[1.0*w/orgWidth],\"h\":[1.0*h/orgHeight]})\n",
    "            \n",
    "            \n",
    "            cv2.imwrite(cropsPaths+nm+\".png\",blank_image)\n",
    "\n",
    "            x1,y1=x1+w+50,y1\n",
    "\n",
    "            df1=pd.concat([df1,dTemp],ignore_index=True, axis = 0)\n",
    "        except Exception as e:\n",
    "            \n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            #print(\" line number:\", exc_tb.tb_lineno,\" e:\",e)\n",
    "            #print(\"&\")\n",
    "            pass\n",
    "\n",
    "    #time.sleep(1)\n",
    "    #input(\" check!!\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cbf6273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(405, 13)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df1.to_csv(\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/data/toyCrops.csv\")\n",
    "#os.path.isfile(\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/data/toyCrops.csv\")\n",
    "\n",
    "#df1=pd.read_csv(\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/data/toyCrops.csv\")\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0beb3fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>class</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>org_x1</th>\n",
       "      <th>org_y1</th>\n",
       "      <th>org_x2</th>\n",
       "      <th>org_y2</th>\n",
       "      <th>text</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>859</td>\n",
       "      <td>813</td>\n",
       "      <td>and</td>\n",
       "      <td>434.5</td>\n",
       "      <td>421.5</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>246.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "      <td>200</td>\n",
       "      <td>188</td>\n",
       "      <td>30</td>\n",
       "      <td>859</td>\n",
       "      <td>813</td>\n",
       "      <td>that</td>\n",
       "      <td>523.5</td>\n",
       "      <td>421.5</td>\n",
       "      <td>0.1475</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>246.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "      <td>200</td>\n",
       "      <td>415</td>\n",
       "      <td>30</td>\n",
       "      <td>859</td>\n",
       "      <td>813</td>\n",
       "      <td>was</td>\n",
       "      <td>637.0</td>\n",
       "      <td>421.5</td>\n",
       "      <td>0.101667</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>246.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "      <td>200</td>\n",
       "      <td>587</td>\n",
       "      <td>30</td>\n",
       "      <td>859</td>\n",
       "      <td>813</td>\n",
       "      <td>was</td>\n",
       "      <td>723.0</td>\n",
       "      <td>421.5</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>246.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "      <td>200</td>\n",
       "      <td>760</td>\n",
       "      <td>30</td>\n",
       "      <td>859</td>\n",
       "      <td>813</td>\n",
       "      <td>of</td>\n",
       "      <td>809.5</td>\n",
       "      <td>421.5</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name class width height org_x1 org_y1 org_x2 org_y2  text      x  \\\n",
       "0    246.png     1  1200    200     10     30    859    813   and  434.5   \n",
       "1    246.png     1  1200    200    188     30    859    813  that  523.5   \n",
       "2    246.png     1  1200    200    415     30    859    813   was  637.0   \n",
       "3    246.png     1  1200    200    587     30    859    813   was  723.0   \n",
       "4    246.png     1  1200    200    760     30    859    813    of  809.5   \n",
       "\n",
       "       y         w      h  \n",
       "0  421.5  0.106667   0.43  \n",
       "1  421.5    0.1475   0.62  \n",
       "2  421.5  0.101667   0.38  \n",
       "3  421.5    0.1025   0.33  \n",
       "4  421.5  0.083333  0.575  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cropsPaths\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ac7236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f184af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"phos\"]=0\n",
    "df1[\"phos\"]=df1[\"phos\"].astype(object)\n",
    "\n",
    "df1[\"phoc\"]=0\n",
    "df1[\"phoc\"]=df1[\"phoc\"].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b485de0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " indx: 0\n",
      " indx: 1000\n",
      " indx: 2000\n",
      " indx: 3000\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "len(list(set(df1['text'])))\n",
    "word=list(set(df1['text']))\n",
    "\n",
    "\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "#First parameter is the replacement, second parameter is your input string\n",
    "\n",
    "tempPhos=[0]*165\n",
    "tempPhoc=[0.0]*604\n",
    "#output['Sold Count'] = output['Sold Count'].astype(object)\n",
    "df1[\"phos\"]=df1[\"phos\"].astype(object)\n",
    "\n",
    "for indx,row in df1.iterrows():\n",
    "    \n",
    "    if indx%1000==0:\n",
    "        print(\" indx:\",indx)\n",
    "        df1.to_csv(\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/data/toyCropsPhosc_05-2022-28-1.csv\")    \n",
    "    try:\n",
    "        #print(\"\\n\\t w1:\",w)\n",
    "        w=row[\"text\"]\n",
    "        w=regex.sub('', w)\n",
    "        #print(\"\\n\\t w2:\",w)\n",
    "        if len(w):\n",
    "            phos_label = gen_label([w])\n",
    "            phoc_label = gen_phoc_label([w])\n",
    "\n",
    "            #print(\"\\n\\t train_word_phos_label=\",train_word_phos_label)\n",
    "            #print(\"\\n\\t keys:\",len(phos_label[w]))\n",
    "            #print(\"\\n\\t type:\",type(phos_label[w]))\n",
    "            #print(\"\\n\\t phos_label[w]=\",phos_label[w])\n",
    "            #df.loc[indx,\"phoc\"]=str(phos_label[w]) gen_phoc_label\n",
    "            \n",
    "            #print(\"\\n\\t phos_label =\",len(phos_label[w].tolist()))\n",
    "            #print(\"\\n\\t phoc_label =\",len(phoc_label[w]))\n",
    "\n",
    "            df1.at[indx,\"phoc\"]=phoc_label[w]\n",
    "            df1.at[indx,\"phos\"]=phos_label[w]#.tolist()\n",
    "\n",
    "        else:\n",
    "            df1.at[indx,\"phoc\"]=tempPhoc\n",
    "            df1.at[indx,\"phos\"]=tempPhos\n",
    "\n",
    "        #input(\"check!!\")\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"\\n\\t w:\",w,\"\\t indx:\",indx,\"\\t e:\",e)\n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "        print(\"\\n\\t line number:\", exc_tb.tb_lineno)\n",
    "        input(\"check!!!\")\n",
    "df1.to_csv(\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/data/toyCropsPhosc_05-2022-28-1.csv\")    \n",
    "\n",
    "\n",
    "#train_word_phos_label = gen_label(list(set(df['text'])))\n",
    "#train_word_phos_label = gen_label(word[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ba4343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "175ce3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/data/toyCropsPhosc_05-2022-28-1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "628a9cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_name</th>\n",
       "      <th>class</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>org_x1</th>\n",
       "      <th>org_y1</th>\n",
       "      <th>org_x2</th>\n",
       "      <th>org_y2</th>\n",
       "      <th>text</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>phos</th>\n",
       "      <th>phoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>246.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>859</td>\n",
       "      <td>813</td>\n",
       "      <td>and</td>\n",
       "      <td>434.5</td>\n",
       "      <td>421.5</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.430</td>\n",
       "      <td>[1. 0. 2. 0. 0. 0. 2. 3. 0. 0. 0. 0. 0. 1. 0. ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>246.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "      <td>200</td>\n",
       "      <td>188</td>\n",
       "      <td>30</td>\n",
       "      <td>859</td>\n",
       "      <td>813</td>\n",
       "      <td>that</td>\n",
       "      <td>523.5</td>\n",
       "      <td>421.5</td>\n",
       "      <td>0.147500</td>\n",
       "      <td>0.620</td>\n",
       "      <td>[1. 0. 1. 0. 0. 0. 1. 4. 0. 0. 2. 1. 0. 0. 0. ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>246.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "      <td>200</td>\n",
       "      <td>415</td>\n",
       "      <td>30</td>\n",
       "      <td>859</td>\n",
       "      <td>813</td>\n",
       "      <td>was</td>\n",
       "      <td>637.0</td>\n",
       "      <td>421.5</td>\n",
       "      <td>0.101667</td>\n",
       "      <td>0.380</td>\n",
       "      <td>[0. 0. 2. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>246.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "      <td>200</td>\n",
       "      <td>587</td>\n",
       "      <td>30</td>\n",
       "      <td>859</td>\n",
       "      <td>813</td>\n",
       "      <td>was</td>\n",
       "      <td>723.0</td>\n",
       "      <td>421.5</td>\n",
       "      <td>0.102500</td>\n",
       "      <td>0.330</td>\n",
       "      <td>[0. 0. 2. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>246.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "      <td>200</td>\n",
       "      <td>760</td>\n",
       "      <td>30</td>\n",
       "      <td>859</td>\n",
       "      <td>813</td>\n",
       "      <td>of</td>\n",
       "      <td>809.5</td>\n",
       "      <td>421.5</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.575</td>\n",
       "      <td>[1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 image_name  class  width  height  org_x1  org_y1  org_x2  \\\n",
       "0           0    246.png      1   1200     200      10      30     859   \n",
       "1           1    246.png      1   1200     200     188      30     859   \n",
       "2           2    246.png      1   1200     200     415      30     859   \n",
       "3           3    246.png      1   1200     200     587      30     859   \n",
       "4           4    246.png      1   1200     200     760      30     859   \n",
       "\n",
       "   org_y2  text      x      y         w      h  \\\n",
       "0     813   and  434.5  421.5  0.106667  0.430   \n",
       "1     813  that  523.5  421.5  0.147500  0.620   \n",
       "2     813   was  637.0  421.5  0.101667  0.380   \n",
       "3     813   was  723.0  421.5  0.102500  0.330   \n",
       "4     813    of  809.5  421.5  0.083333  0.575   \n",
       "\n",
       "                                                phos  \\\n",
       "0  [1. 0. 2. 0. 0. 0. 2. 3. 0. 0. 0. 0. 0. 1. 0. ...   \n",
       "1  [1. 0. 1. 0. 0. 0. 1. 4. 0. 0. 2. 1. 0. 0. 0. ...   \n",
       "2  [0. 0. 2. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. ...   \n",
       "3  [0. 0. 2. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. ...   \n",
       "4  [1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. ...   \n",
       "\n",
       "                                                phoc  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6caa4a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115187, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b60b04ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t unique: 332  df: (3345, 16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/data/toyCropsPhosc_05-2022-28-1.csv\")\n",
    "\n",
    "unqImages=set(df.image_name)\n",
    "print(\"\\n\\t unique:\",len(unqImages),\" df:\",df.shape)\n",
    "#print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25a0cec",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "    below part convert data into yolo consumable format\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e9be6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t unq images: 0\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//246.png\n",
      "\n",
      "\t unq images: 2\n",
      "\n",
      "\t unq images: 4\n",
      "\n",
      "\t unq images: 5\n",
      "\n",
      "\t unq images: 7\n",
      "\n",
      "\t unq images: 9\n",
      "\n",
      "\t unq images: 10\n",
      "\n",
      "\t unq images: 11\n",
      "\n",
      "\t unq images: 12\n",
      "\n",
      "\t unq images: 14\n",
      "\n",
      "\t unq images: 16\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//448.png\n",
      "\n",
      "\t unq images: 17\n",
      "\n",
      "\t unq images: 18\n",
      "\n",
      "\t unq images: 19\n",
      "\n",
      "\t unq images: 21\n",
      "\n",
      "\t unq images: 21\n",
      "\n",
      "\t unq images: 23\n",
      "\n",
      "\t unq images: 25\n",
      "\n",
      "\t unq images: 26\n",
      "\n",
      "\t unq images: 27\n",
      "\n",
      "\t unq images: 30\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//742.png\n",
      "\n",
      "\t unq images: 30\n",
      "\n",
      "\t unq images: 32\n",
      "\n",
      "\t unq images: 33\n",
      "\n",
      "\t unq images: 34\n",
      "\n",
      "\t unq images: 35\n",
      "\n",
      "\t unq images: 36\n",
      "\n",
      "\t unq images: 37\n",
      "\n",
      "\t unq images: 37\n",
      "\n",
      "\t unq images: 38\n",
      "\n",
      "\t unq images: 39\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//603.png\n",
      "\n",
      "\t unq images: 41\n",
      "\n",
      "\t unq images: 41\n",
      "\n",
      "\t unq images: 43\n",
      "\n",
      "\t unq images: 43\n",
      "\n",
      "\t unq images: 44\n",
      "\n",
      "\t unq images: 44\n",
      "\n",
      "\t unq images: 46\n",
      "\n",
      "\t unq images: 48\n",
      "\n",
      "\t unq images: 48\n",
      "\n",
      "\t unq images: 49\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//999.png\n",
      "\n",
      "\t unq images: 51\n",
      "\n",
      "\t unq images: 51\n",
      "\n",
      "\t unq images: 53\n",
      "\n",
      "\t unq images: 55\n",
      "\n",
      "\t unq images: 55\n",
      "\n",
      "\t unq images: 56\n",
      "\n",
      "\t unq images: 57\n",
      "\n",
      "\t unq images: 57\n",
      "\n",
      "\t unq images: 59\n",
      "\n",
      "\t unq images: 60\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//833.png\n",
      "\n",
      "\t unq images: 60\n",
      "\n",
      "\t unq images: 61\n",
      "\n",
      "\t unq images: 61\n",
      "\n",
      "\t unq images: 62\n",
      "\n",
      "\t unq images: 64\n",
      "\n",
      "\t unq images: 65\n",
      "\n",
      "\t unq images: 66\n",
      "\n",
      "\t unq images: 67\n",
      "\n",
      "\t unq images: 67\n",
      "\n",
      "\t unq images: 69\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//685.png\n",
      "\n",
      "\t unq images: 70\n",
      "\n",
      "\t unq images: 71\n",
      "\n",
      "\t unq images: 72\n",
      "\n",
      "\t unq images: 73\n",
      "\n",
      "\t unq images: 75\n",
      "\n",
      "\t unq images: 75\n",
      "\n",
      "\t unq images: 76\n",
      "\n",
      "\t unq images: 78\n",
      "\n",
      "\t unq images: 78\n",
      "\n",
      "\t unq images: 80\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//201.png\n",
      "\n",
      "\t unq images: 82\n",
      "\n",
      "\t unq images: 83\n",
      "\n",
      "\t unq images: 85\n",
      "\n",
      "\t unq images: 86\n",
      "\n",
      "\t unq images: 86\n",
      "\n",
      "\t unq images: 88\n",
      "\n",
      "\t unq images: 90\n",
      "\n",
      "\t unq images: 92\n",
      "\n",
      "\t unq images: 92\n",
      "\n",
      "\t unq images: 94\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//87.png\n",
      "\n",
      "\t unq images: 96\n",
      "\n",
      "\t unq images: 97\n",
      "\n",
      "\t unq images: 99\n",
      "\n",
      "\t unq images: 100\n",
      "\n",
      "\t unq images: 100\n",
      "\n",
      "\t unq images: 101\n",
      "\n",
      "\t unq images: 102\n",
      "\n",
      "\t unq images: 104\n",
      "\n",
      "\t unq images: 105\n",
      "\n",
      "\t unq images: 107\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//960.png\n",
      "\n",
      "\t unq images: 108\n",
      "\n",
      "\t unq images: 110\n",
      "\n",
      "\t unq images: 112\n",
      "\n",
      "\t unq images: 113\n",
      "\n",
      "\t unq images: 114\n",
      "\n",
      "\t unq images: 116\n",
      "\n",
      "\t unq images: 117\n",
      "\n",
      "\t unq images: 119\n",
      "\n",
      "\t unq images: 121\n",
      "\n",
      "\t unq images: 123\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//411.png\n",
      "\n",
      "\t unq images: 123\n",
      "\n",
      "\t unq images: 124\n",
      "\n",
      "\t unq images: 124\n",
      "\n",
      "\t unq images: 125\n",
      "\n",
      "\t unq images: 125\n",
      "\n",
      "\t unq images: 127\n",
      "\n",
      "\t unq images: 128\n",
      "\n",
      "\t unq images: 129\n",
      "\n",
      "\t unq images: 129\n",
      "\n",
      "\t unq images: 130\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//436.png\n",
      "\n",
      "\t unq images: 131\n",
      "\n",
      "\t unq images: 132\n",
      "\n",
      "\t unq images: 133\n",
      "\n",
      "\t unq images: 134\n",
      "\n",
      "\t unq images: 135\n",
      "\n",
      "\t unq images: 136\n",
      "\n",
      "\t unq images: 138\n",
      "\n",
      "\t unq images: 139\n",
      "\n",
      "\t unq images: 139\n",
      "\n",
      "\t unq images: 140\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//658.png\n",
      "\n",
      "\t unq images: 141\n",
      "\n",
      "\t unq images: 141\n",
      "\n",
      "\t unq images: 143\n",
      "\n",
      "\t unq images: 144\n",
      "\n",
      "\t unq images: 146\n",
      "\n",
      "\t unq images: 147\n",
      "\n",
      "\t unq images: 148\n",
      "\n",
      "\t unq images: 150\n",
      "\n",
      "\t unq images: 150\n",
      "\n",
      "\t unq images: 150\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//512.png\n",
      "\n",
      "\t unq images: 151\n",
      "\n",
      "\t unq images: 151\n",
      "\n",
      "\t unq images: 151\n",
      "\n",
      "\t unq images: 151\n",
      "\n",
      "\t unq images: 152\n",
      "\n",
      "\t unq images: 153\n",
      "\n",
      "\t unq images: 154\n",
      "\n",
      "\t unq images: 155\n",
      "\n",
      "\t unq images: 156\n",
      "\n",
      "\t unq images: 159\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//525.png\n",
      "\n",
      "\t unq images: 161\n",
      "\n",
      "\t unq images: 162\n",
      "\n",
      "\t unq images: 162\n",
      "\n",
      "\t unq images: 163\n",
      "\n",
      "\t unq images: 164\n",
      "\n",
      "\t unq images: 164\n",
      "\n",
      "\t unq images: 165\n",
      "\n",
      "\t unq images: 165\n",
      "\n",
      "\t unq images: 166\n",
      "\n",
      "\t unq images: 167\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//570.png\n",
      "\n",
      "\t unq images: 168\n",
      "\n",
      "\t unq images: 168\n",
      "\n",
      "\t unq images: 169\n",
      "\n",
      "\t unq images: 170\n",
      "\n",
      "\t unq images: 171\n",
      "\n",
      "\t unq images: 172\n",
      "\n",
      "\t unq images: 174\n",
      "\n",
      "\t unq images: 174\n",
      "\n",
      "\t unq images: 175\n",
      "\n",
      "\t unq images: 176\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//998.png\n",
      "\n",
      "\t unq images: 177\n",
      "\n",
      "\t unq images: 178\n",
      "\n",
      "\t unq images: 179\n",
      "\n",
      "\t unq images: 180\n",
      "\n",
      "\t unq images: 181\n",
      "\n",
      "\t unq images: 182\n",
      "\n",
      "\t unq images: 182\n",
      "\n",
      "\t unq images: 184\n",
      "\n",
      "\t unq images: 184\n",
      "\n",
      "\t unq images: 186\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//403.png\n",
      "\n",
      "\t unq images: 186\n",
      "\n",
      "\t unq images: 187\n",
      "\n",
      "\t unq images: 188\n",
      "\n",
      "\t unq images: 190\n",
      "\n",
      "\t unq images: 192\n",
      "\n",
      "\t unq images: 194\n",
      "\n",
      "\t unq images: 194\n",
      "\n",
      "\t unq images: 194\n",
      "\n",
      "\t unq images: 195\n",
      "\n",
      "\t unq images: 197\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//304.png\n",
      "\n",
      "\t unq images: 198\n",
      "\n",
      "\t unq images: 200\n",
      "\n",
      "\t unq images: 200\n",
      "\n",
      "\t unq images: 201\n",
      "\n",
      "\t unq images: 201\n",
      "\n",
      "\t unq images: 203\n",
      "\n",
      "\t unq images: 205\n",
      "\n",
      "\t unq images: 206\n",
      "\n",
      "\t unq images: 206\n",
      "\n",
      "\t unq images: 208\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//857.png\n",
      "\n",
      "\t unq images: 209\n",
      "\n",
      "\t unq images: 210\n",
      "\n",
      "\t unq images: 211\n",
      "\n",
      "\t unq images: 212\n",
      "\n",
      "\t unq images: 212\n",
      "\n",
      "\t unq images: 214\n",
      "\n",
      "\t unq images: 214\n",
      "\n",
      "\t unq images: 214\n",
      "\n",
      "\t unq images: 215\n",
      "\n",
      "\t unq images: 218\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//513.png\n",
      "\n",
      "\t unq images: 219\n",
      "\n",
      "\t unq images: 219\n",
      "\n",
      "\t unq images: 219\n",
      "\n",
      "\t unq images: 220\n",
      "\n",
      "\t unq images: 220\n",
      "\n",
      "\t unq images: 222\n",
      "\n",
      "\t unq images: 222\n",
      "\n",
      "\t unq images: 223\n",
      "\n",
      "\t unq images: 223\n",
      "\n",
      "\t unq images: 223\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//325.png\n",
      "\n",
      "\t unq images: 225\n",
      "\n",
      "\t unq images: 225\n",
      "\n",
      "\t unq images: 226\n",
      "\n",
      "\t unq images: 226\n",
      "\n",
      "\t unq images: 227\n",
      "\n",
      "\t unq images: 228\n",
      "\n",
      "\t unq images: 229\n",
      "\n",
      "\t unq images: 231\n",
      "\n",
      "\t unq images: 231\n",
      "\n",
      "\t unq images: 233\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//565.png\n",
      "\n",
      "\t unq images: 233\n",
      "\n",
      "\t unq images: 235\n",
      "\n",
      "\t unq images: 236\n",
      "\n",
      "\t unq images: 237\n",
      "\n",
      "\t unq images: 239\n",
      "\n",
      "\t unq images: 241\n",
      "\n",
      "\t unq images: 243\n",
      "\n",
      "\t unq images: 245\n",
      "\n",
      "\t unq images: 246\n",
      "\n",
      "\t unq images: 248\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//787.png\n",
      "\n",
      "\t unq images: 248\n",
      "\n",
      "\t unq images: 249\n",
      "\n",
      "\t unq images: 250\n",
      "\n",
      "\t unq images: 250\n",
      "\n",
      "\t unq images: 251\n",
      "\n",
      "\t unq images: 252\n",
      "\n",
      "\t unq images: 254\n",
      "\n",
      "\t unq images: 255\n",
      "\n",
      "\t unq images: 257\n",
      "\n",
      "\t unq images: 258\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//127.png\n",
      "\n",
      "\t unq images: 258\n",
      "\n",
      "\t unq images: 259\n",
      "\n",
      "\t unq images: 260\n",
      "\n",
      "\t unq images: 260\n",
      "\n",
      "\t unq images: 261\n",
      "\n",
      "\t unq images: 262\n",
      "\n",
      "\t unq images: 263\n",
      "\n",
      "\t unq images: 264\n",
      "\n",
      "\t unq images: 266\n",
      "\n",
      "\t unq images: 267\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//757.png\n",
      "\n",
      "\t unq images: 268\n",
      "\n",
      "\t unq images: 268\n",
      "\n",
      "\t unq images: 268\n",
      "\n",
      "\t unq images: 269\n",
      "\n",
      "\t unq images: 269\n",
      "\n",
      "\t unq images: 269\n",
      "\n",
      "\t unq images: 270\n",
      "\n",
      "\t unq images: 271\n",
      "\n",
      "\t unq images: 271\n",
      "\n",
      "\t unq images: 272\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//353.png\n",
      "\n",
      "\t unq images: 274\n",
      "\n",
      "\t unq images: 274\n",
      "\n",
      "\t unq images: 275\n",
      "\n",
      "\t unq images: 275\n",
      "\n",
      "\t unq images: 276\n",
      "\n",
      "\t unq images: 277\n",
      "\n",
      "\t unq images: 277\n",
      "\n",
      "\t unq images: 278\n",
      "\n",
      "\t unq images: 279\n",
      "\n",
      "\t unq images: 279\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//19.png\n",
      "\n",
      "\t unq images: 280\n",
      "\n",
      "\t unq images: 281\n",
      "\n",
      "\t unq images: 281\n",
      "\n",
      "\t unq images: 281\n",
      "\n",
      "\t unq images: 282\n",
      "\n",
      "\t unq images: 282\n",
      "\n",
      "\t unq images: 282\n",
      "\n",
      "\t unq images: 282\n",
      "\n",
      "\t unq images: 282\n",
      "\n",
      "\t unq images: 282\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//931.png\n",
      "\n",
      "\t unq images: 283\n",
      "\n",
      "\t unq images: 284\n",
      "\n",
      "\t unq images: 284\n",
      "\n",
      "\t unq images: 286\n",
      "\n",
      "\t unq images: 286\n",
      "\n",
      "\t unq images: 288\n",
      "\n",
      "\t unq images: 289\n",
      "\n",
      "\t unq images: 291\n",
      "\n",
      "\t unq images: 291\n",
      "\n",
      "\t unq images: 292\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//154.png\n",
      "\n",
      "\t unq images: 293\n",
      "\n",
      "\t unq images: 294\n",
      "\n",
      "\t unq images: 294\n",
      "\n",
      "\t unq images: 296\n",
      "\n",
      "\t unq images: 298\n",
      "\n",
      "\t unq images: 298\n",
      "\n",
      "\t unq images: 299\n",
      "\n",
      "\t unq images: 300\n",
      "\n",
      "\t unq images: 301\n",
      "\n",
      "\t unq images: 302\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//584.png\n",
      "\n",
      "\t unq images: 303\n",
      "\n",
      "\t unq images: 304\n",
      "\n",
      "\t unq images: 305\n",
      "\n",
      "\t unq images: 305\n",
      "\n",
      "\t unq images: 306\n",
      "\n",
      "\t unq images: 307\n",
      "\n",
      "\t unq images: 307\n",
      "\n",
      "\t unq images: 309\n",
      "\n",
      "\t unq images: 310\n",
      "\n",
      "\t unq images: 310\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//673.png\n",
      "\n",
      "\t unq images: 311\n",
      "\n",
      "\t unq images: 311\n",
      "\n",
      "\t unq images: 313\n",
      "\n",
      "\t unq images: 314\n",
      "\n",
      "\t unq images: 314\n",
      "\n",
      "\t unq images: 315\n",
      "\n",
      "\t unq images: 316\n",
      "\n",
      "\t unq images: 317\n",
      "\n",
      "\t unq images: 318\n",
      "\n",
      "\t unq images: 320\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//392.png\n",
      "\n",
      "\t unq images: 321\n",
      "\n",
      "\t unq images: 323\n",
      "\n",
      "\t unq images: 323\n",
      "\n",
      "\t unq images: 324\n",
      "\n",
      "\t unq images: 324\n",
      "\n",
      "\t unq images: 324\n",
      "\n",
      "\t unq images: 325\n",
      "\n",
      "\t unq images: 325\n",
      "\n",
      "\t unq images: 325\n",
      "\n",
      "\t unq images: 328\n",
      "\n",
      "\t path: ./data/toyCrops_#05-2022-28-1#//290.png\n",
      "\n",
      "\t unq images: 329\n",
      "\n",
      "\t unq images: 331\n",
      "\n",
      "\t unq images: 331\n",
      "\n",
      "\t unq images: 331\n",
      " total exceptions: 0\n"
     ]
    }
   ],
   "source": [
    "#for file in ['train','test']:\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "savePath=\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/data/toyData_#05-2022-28-1#//\"\n",
    "images_path = \"./data/toyCrops_#05-2022-28-1#//\"\n",
    "allImages=os.listdir(images_path)\n",
    "images_num=len(os.listdir(images_path))\n",
    "\n",
    "labels_txt = savePath+\"/\"+\"mnist_train1_toy_#05-2022-28-2#.txt\"\n",
    "labels_txt2 = savePath+\"/\"+\"mnist_test1_toy_-2022-28-2#.txt\"\n",
    "\n",
    "lastName=\"\"\n",
    "curLine=\"\"\n",
    "prevLine=\"\"\n",
    "unqImg=[]\n",
    "exceptionCount=0\n",
    "\n",
    "for indx,info in df.iterrows():\n",
    "    try:\n",
    "        if indx%10==0:\n",
    "            print(\"\\n\\t unq images:\",len(unqImg))\n",
    "\n",
    "        if len(unqImg)<300:\n",
    "\n",
    "            with open(labels_txt, \"a\") as wf:\n",
    "                image_path =images_path+info[\"image_name\"]\n",
    "\n",
    "                if indx%100==0:\n",
    "                    print(\"\\n\\t path:\",image_path)\n",
    "\n",
    "                if info[\"image_name\"]!=lastName and info[\"image_name\"] not in unqImg:\n",
    "                    curLine=image_path\n",
    "\n",
    "                    if len(prevLine):\n",
    "                        #print(\"\\n\\t prevLine:\",prevLine)\n",
    "                        #wf.write( image_path+ \"\\n\")\n",
    "                        wf.write(prevLine+\"\\n\")\n",
    "\n",
    "                else:\n",
    "                    xmin,ymin=str(int(info[\"org_x1\"])),str(int(info[\"org_y1\"]))\n",
    "                    xmax,ymax=str(int(info[\"org_x2\"])),str(int(info[\"org_y2\"]))\n",
    "                    curLine += ' ' + ','.join([xmin, ymin, xmax, ymax, str(0)])\n",
    "                    prevLine=curLine\n",
    "\n",
    "                lastName=info[\"image_name\"]\n",
    "\n",
    "        elif 300<len(unqImg)<400:\n",
    "\n",
    "            with open(labels_txt2, \"a\") as wf:\n",
    "                image_path =images_path+info[\"image_name\"]\n",
    "\n",
    "                if indx%100==0:\n",
    "                    print(\"\\n\\t path:\",image_path)\n",
    "\n",
    "                if info[\"image_name\"]!=lastName:\n",
    "                    curLine=image_path\n",
    "\n",
    "                    if len(prevLine):\n",
    "                        #print(\"\\n\\t prevLine:\",prevLine)\n",
    "                        #wf.write( image_path+ \"\\n\")\n",
    "                        wf.write(prevLine+\"\\n\")\n",
    "\n",
    "                else:\n",
    "                    xmin,ymin=str(int(info[\"org_x1\"])),str(int(info[\"org_y1\"]))\n",
    "                    xmax,ymax=str(int(info[\"org_x2\"])),str(int(info[\"org_y2\"]))\n",
    "                    curLine += ' ' + ','.join([xmin, ymin, xmax, ymax, str(0)])\n",
    "                    prevLine=curLine\n",
    "\n",
    "                lastName=info[\"image_name\"]\n",
    "        elif 600<len(unqImg):\n",
    "            break\n",
    "            \n",
    "        if info[\"image_name\"] not in unqImg:\n",
    "            unqImg.append(info[\"image_name\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        exceptionCount+=1\n",
    "        print(\"\\n\\t exception index:\",indx,\"\\t count:\",exceptionCount)\n",
    "\n",
    "print(\" total exceptions:\",exceptionCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072d5675",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "    this part maps BB coordinate to words\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c8f514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7838c9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/data/IAM_Data/IAM_test/m01-049-00-02.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9841c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c64a18cf",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "    extract image name from image crops\n",
    "    Test data used for PHOSCNET is used to get test image names,\n",
    "    Then test images of PHOSCNET is used to get prediction from yolo model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea29ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoscTestData=\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/data/IAM_Data/IAM_test//\"\n",
    "yoloTrainData=\"/home/aniketag/Documents/phd/yolov5/data/datasets/forms//\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b262ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoscTestCrops=os.listdir(phoscTestData)\n",
    "yoloTrainImages=list(set(os.listdir(yoloTrainData)))\n",
    "\n",
    "#set([len(nm) for nm in phoscTestCrops])\n",
    "\n",
    "\"\"\"\n",
    "import re\n",
    "str = \"aaaaaa|bbbbbb|ccccc|dddd\"\n",
    "indexes = [x.start() for x in re.finditer('\\|', str)]\n",
    "print(indexes) # <-- [6, 13, 19]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55ed773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "matchImages=[]\n",
    "unqImgnames=[]\n",
    "\n",
    "for indx,cropName in enumerate(phoscTestCrops):\n",
    "    \n",
    "    cropName=list(cropName)\n",
    "    cropName1=cropName[:7]\n",
    "    cropName1=\"\".join(cropName1)\n",
    "    \n",
    "    cropName1=cropName1+\".png\"\n",
    "    \n",
    "    if indx%1000==0:\n",
    "        print(\" indx:\",indx)\n",
    "    \n",
    "    if cropName1 in yoloTrainImages:\n",
    "                \n",
    "        img=cv2.imread(yoloTrainData+cropName1)\n",
    "        #print(\"cropName=\",cropName,\" \",img.shape)\n",
    "        #input(\" check!!!\")\n",
    "        \n",
    "    elif len(cropName)==18:\n",
    "        \n",
    "        cropName=list(cropName)\n",
    "        cropName1=cropName[:8]\n",
    "        cropName1=\"\".join(cropName1)\n",
    "        cropName1=cropName1+\".png\"\n",
    "        img=cv2.imread(yoloTrainData+cropName1)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print(\"cropName=\",cropName)\n",
    "        #input(\" check!!!\")\n",
    "        \n",
    "    unqImgnames.append(cropName1)\n",
    "\n",
    "cropName1=list(set(cropName1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da22d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#phoscTestData\n",
    "\n",
    "\"\"\"\n",
    "    copy PHOSC\n",
    "\"\"\"\n",
    "import shutil \n",
    "unqImgnames=list(set(unqImgnames))\n",
    "phoscTestImg=\"/home/aniketag/Documents/phd/TensorFlow-2.x-YOLOv3/phoscTest//\"\n",
    "\n",
    "print(\" length:\",len(unqImgnames))\n",
    "\n",
    "for nm in unqImgnames:\n",
    "    \n",
    "    shutil.copy2(yoloTrainData+nm,phoscTestImg)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5825325",
   "metadata": {},
   "outputs": [],
   "source": [
    "unqImgnames[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
