{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b553ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12150414845287389058\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10299730816\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 59170098176290254\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\"\n",
      "]\n",
      "\n",
      "\t YOLO_TYPE: yolov3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#print(\"\\n\\t tf:\",tf.__version__)\n",
    "#tf.enable_eager_execution()\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "#from yolov3.dataset import Dataset\n",
    "from yolov3.yolov4 import compute_loss1\n",
    "from yolov3.utils import load_yolo_weights\n",
    "from yolov3.configs import *\n",
    "from evaluate_mAP import get_mAP\n",
    "\n",
    "print(\"\\n\\t YOLO_TYPE:\",YOLO_TYPE)\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from yolov3.utils import read_class_names, image_preprocess#,draw_bbox\n",
    "from yolov3.yolov3 import bbox_iou\n",
    "from yolov3.configs import *\n",
    "from yolov3.utils import load_yolo_weights, detect_image, image_preprocess, postprocess_boxes, nms, read_class_names\n",
    "from supportFunctions import draw_bbox\n",
    "'''\n",
    "    more details regarding Dataset1 is in yolo3PhoscModify2.ipynb\n",
    "'''\n",
    "\n",
    "from yolov3.dataset import Dataset1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c81993b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "#from yolov3.yolov4 import Create_YoloPhosc\n",
    "from yolov3.yolov3 import Create_Yolov3\n",
    "global TRAIN_FROM_CHECKPOINT\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(f'GPUs {gpus}')\n",
    "if len(gpus) > 0:\n",
    "    try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError: pass\n",
    "\n",
    "if os.path.exists(TRAIN_LOGDIR): shutil.rmtree(TRAIN_LOGDIR)\n",
    "writer = tf.summary.create_file_writer(TRAIN_LOGDIR)\n",
    "\n",
    "trainset = Dataset1('train')\n",
    "testset = Dataset1('test')\n",
    "\n",
    "\n",
    "if len(gpus) > 0:\n",
    "    try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError: pass\n",
    "\n",
    "if os.path.exists(TRAIN_LOGDIR): shutil.rmtree(TRAIN_LOGDIR)\n",
    "writer = tf.summary.create_file_writer(TRAIN_LOGDIR)\n",
    "\n",
    "steps_per_epoch = len(trainset)\n",
    "global_steps = tf.Variable(1, trainable=False, dtype=tf.int64)\n",
    "warmup_steps = TRAIN_WARMUP_EPOCHS * steps_per_epoch\n",
    "total_steps = TRAIN_EPOCHS * steps_per_epoch\n",
    "\n",
    "if YOLO_TYPE == \"yolov3\":\n",
    "    Darknet_weights = YOLO_V3_TINY_WEIGHTS if TRAIN_YOLO_TINY else YOLO_V3_WEIGHTS\n",
    "\n",
    "\n",
    "if TRAIN_TRANSFER:\n",
    "    #Darknet = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=YOLO_COCO_CLASSES)\n",
    "    Darknet = Create_Yolov3(input_size=YOLO_INPUT_SIZE, CLASSES=YOLO_COCO_CLASSES)\n",
    "\n",
    "    #print(\"Darknet_weights=\",os.path.isfile(Darknet_weights))\n",
    "    load_yolo_weights(Darknet, Darknet_weights) # use darknet weights\n",
    "    \n",
    "#yolo = Create_Yolo(input_size=YOLO_INPUT_SIZE, training=True, CLASSES=TRAIN_CLASSES)\n",
    "\n",
    "yolo=Create_Yolov3(input_size=YOLO_INPUT_SIZE, training=True, CLASSES=TRAIN_CLASSES)\n",
    "\n",
    "if TRAIN_FROM_CHECKPOINT:\n",
    "    try:\n",
    "        print(\"\\n\\t load weights!!!\")\n",
    "        yolo.load_weights(f\"./checkpoints/{TRAIN_MODEL_NAME}\")\n",
    "        print(\"\\n\\t loading complete\")\n",
    "\n",
    "    except ValueError:\n",
    "        print(\"Shapes are incompatible, transfering Darknet weights\")\n",
    "        TRAIN_FROM_CHECKPOINT = False\n",
    "'''\n",
    "if TRAIN_TRANSFER and not TRAIN_FROM_CHECKPOINT:\n",
    "    for i, l in enumerate(Darknet.layers):\n",
    "        layer_weights = l.get_weights()\n",
    "        if layer_weights != []:\n",
    "            try:\n",
    "                yolo.layers[i].set_weights(layer_weights)\n",
    "            except:\n",
    "                print(\"skipping\", yolo.layers[i].name)\n",
    "'''\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "#mAP_model = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=TRAIN_CLASSES) # create second model to measure mAP\n",
    "#best_val_loss = 1000 # should be large at start\n",
    "\n",
    "#print(\"\\n\\t mAP_model =\",mAP_model)\n",
    "\n",
    "#print(\"\\n\\t yolo:\",yolo.summary())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c15b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_step(image_data, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = yolo(image_data, training=False)\n",
    "        \n",
    "        print(\"\\n\\t 1.pred_result validate:\",len(pred_result[0]))\n",
    "        pred_result =pred_result[0]\n",
    "        print(\"\\n\\t 2.pred_result validate:\",pred_result.shape)\n",
    "\n",
    "#         if type(pred_result) is list:\n",
    "#             pred_result =pred_result[0]\n",
    "        giou_loss=conf_loss=prob_loss=0\n",
    "\n",
    "        # optimizing process\n",
    "        grid = 1 if not TRAIN_YOLO_TINY else 2\n",
    "        for i in range(grid):\n",
    "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "            loss_items = compute_loss1(pred, conv, *target[i], i, CLASSES=TRAIN_CLASSES)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "\n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "\n",
    "    return giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()\n",
    "\n",
    "phoscLoss=0\n",
    "def train_step(nm,counter,image_data, target):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = yolo(image_data, training=True)\n",
    "        '''\n",
    "        print(\"\\n\\t image_data in train:\",image_data.shape)\n",
    "        print(\"\\n\\t in train pred_result len=\",len(pred_result))\n",
    "        print(\"\\n\\t in train pred_result 0=\",pred_result[0].shape)\n",
    "        print(\"\\n\\t in train pred_result 1=\",pred_result[1].shape)\n",
    "        print(\"\\n\\t in train pred_result 0=\",pred_result[2].shape)\n",
    "        print(\"\\n\\t in train pred_result 1=\",pred_result[3].shape)\n",
    "        '''\n",
    "    \n",
    "        image2=tf.squeeze(image_data)\n",
    "    \n",
    "        giou_loss=conf_loss=prob_loss=phocLoss1=phosLoss2=0\n",
    "\n",
    "        # optimizing process\n",
    "        grid = 3 if not TRAIN_YOLO_TINY else 2\n",
    "\n",
    "        for i in range(grid):\n",
    "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "            #print(\"\\n\\t conv train:\",conv.shape,\"\\t i:\",i)\n",
    "            #print(\"\\n\\t pred train:\",pred.shape,\"\\t i:\",i)\n",
    "            \n",
    "            loss_items = compute_loss1(pred, conv, *target[i], i, CLASSES=TRAIN_CLASSES)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "            phocLoss1+=loss_items[3]\n",
    "            phosLoss2+=loss_items[4]\n",
    "\n",
    "            \n",
    "        #print(\"\\n\\t phoscLoss1:\",phoscLoss1,\"\\t phoscLoss2:\",phoscLoss2)\n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "        #total_loss1=phoscLoss+giou_loss + conf_loss + prob_loss+phocLoss1+phosLoss2\n",
    "        total_loss1=0.7*phoscLoss+0.3*total_loss\n",
    "        gradients = tape.gradient(total_loss1, yolo.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, yolo.trainable_variables))\n",
    "\n",
    "        global_steps.assign_add(1)\n",
    "        if global_steps < warmup_steps:# and not TRAIN_TRANSFER:\n",
    "            lr = global_steps / warmup_steps * TRAIN_LR_INIT\n",
    "        else:\n",
    "            lr = TRAIN_LR_END + 0.5 * (TRAIN_LR_INIT - TRAIN_LR_END)*(\n",
    "                (1 + tf.cos((global_steps - warmup_steps) / (total_steps - warmup_steps) * np.pi)))\n",
    "        optimizer.lr.assign(lr.numpy())\n",
    "\n",
    "        # writing summary data\n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar(\"lr\", optimizer.lr, step=global_steps)\n",
    "            tf.summary.scalar(\"total_loss\", total_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"total_loss1\", total_loss1, step=global_steps)\n",
    "\n",
    "            tf.summary.scalar(\"giou_loss\", giou_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"conf_loss\", conf_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"prob_loss\", prob_loss, step=global_steps)\n",
    "\n",
    "            tf.summary.scalar(\"phocLoss1\", phocLoss1, step=global_steps)\n",
    "            tf.summary.scalar(\"phosLoss2\",phosLoss2, step=global_steps)\n",
    "            tf.summary.scalar(\"phocLoss1+phosLoss2\",(phocLoss1+phosLoss2), step=global_steps)\n",
    "\n",
    "        writer.flush()\n",
    "    print(\"\\n\\t total_loss =\",total_loss.numpy(),\"\\t total_loss1 =\",total_loss1.numpy())\n",
    "    print(\"\\n\\t phocLoss1=\",phocLoss1.numpy(),\"\\t phosLoss2:\",phosLoss2.numpy())\n",
    "\n",
    "        \n",
    "    pred_result = yolo(image_data, training=False)\n",
    "    #print(\"\\n\\t image_data pred:\",image_data.shape)\n",
    "    #print(\"\\n\\t len(pred_result) pred:\",len(pred_result))\n",
    "    image2=tf.squeeze(image_data)\n",
    "\n",
    "    #print(\"\\n\\t\\t 1.pred_result pred=\",pred_result[0].shape)\n",
    "    #print(\"\\n\\t\\t 2.pred_result pred=\",pred_result[1].shape)\n",
    "    #print(\"\\n\\t\\t 3.pred_result pred=\",pred_result[2].shape)\n",
    "    \n",
    "    #print(\"\\n\\t image2=\",image2.shape)\n",
    "    #pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_result]\n",
    "    #print(\"\\n\\t pred_bbox =\",pred_bbox )\n",
    "    #pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "\n",
    "\n",
    "    # optimizing process\n",
    "    grid = 3 if not TRAIN_YOLO_TINY else 2\n",
    "    for i in range(grid):\n",
    "\n",
    "        '''\n",
    "            these r 3 feature maps of size 52*52,26*26,13*13,\n",
    "                                \n",
    "        '''\n",
    "        conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "\n",
    "    \n",
    "#         print(\"\\n\\t\\t conv pred:\",conv.shape)\n",
    "#         print(\"\\n\\t\\t pred pred=\",pred.shape)\n",
    "    \n",
    "\n",
    "        ''' \n",
    "            (xc,yc,w,h,obj,pro) is last dimension of size 6\n",
    "\n",
    "            pred = (1, 13, 13, 3, 6) is reshaped to \n",
    "            pred_bbox = (507, 6)   169 is len of single anchor tot 3 vectors             \n",
    "             #2.pred_result: (1, 52, 52, 2325)\n",
    "            conv: (1, 26, 26, 18)\n",
    "            pred = (1, 26, 26, 3, 6)\n",
    "            pred_bbox = (2028, 6)  676 is lenght of single anchor tot 3 vectors\n",
    "\n",
    "            image_data= (1, 416, 416, 3)\n",
    "            pred = (1, 52, 52, 3, 6)\n",
    "            pred_bbox = (8112, 6)  2704 is len of single anchor tot 3 vectors\n",
    "\n",
    "        '''\n",
    "\n",
    "        pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred]\n",
    "        #print(\"\\n\\t 1.pred_bbox pred=\",len(pred_bbox))\n",
    "\n",
    "        pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "\n",
    "        #print(\"\\n\\t 2.pred_bbox pred=\",pred_bbox.shape)\n",
    "\n",
    "        ''' \n",
    "        this removes invalid boxes like boxes having low confidence or \n",
    "        which has size greater than image\n",
    "\n",
    "        '''\n",
    "        #print(\"\\n\\t pred_bbox=\",len(pred_bbox))\n",
    "        bboxes = postprocess_boxes(pred_bbox, image2.numpy(), YOLO_INPUT_SIZE,0.25)\n",
    "        #print(\"\\n\\t befor nms bboxes =\",bboxes.shape)\n",
    "\n",
    "\n",
    "        bboxes = nms(bboxes, 0.1, method='nms')\n",
    "        \n",
    "        \n",
    "        #print(\"\\n\\t after nms 1.bboxes =\",len(bboxes))\n",
    "        #print(\"\\n\\t after nms 2.bboxes =\",bboxes)\n",
    "    \n",
    "        #draw_bbox() missing 1 required positional argument: 'bboxes\n",
    "        '''\n",
    "             draw_bbox(nm,counter,level, image, bboxes, CLASSES=YOLO_COCO_CLASSES, show_label=True, show_confidence=True,\n",
    "              Text_colors=(255, 255, 0), rectangle_colors='', tracking=False)\n",
    "        '''\n",
    "        #print(\"\\n\\t bboxes len:\",len(bboxes))\n",
    "        resultImage = draw_bbox(nm,counter,i,255*image2.numpy(), bboxes, CLASSES=YOLO_COCO_CLASSES, rectangle_colors=\"\")\n",
    "        cv2.imwrite(f'./pred/{counter}.png',resultImage)\n",
    "        #input(\"check\")\n",
    "\n",
    "\n",
    "    return global_steps.numpy(), optimizer.lr.numpy(), giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()\n",
    "\n",
    "#mAP_model = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=TRAIN_CLASSES) # create second model to measure mAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c030fa7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d626e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t epoch: 0\n",
      "\n",
      "\t respond_bbox: (1, 52, 52, 3, 1)\n",
      "\n",
      "\t respond_bgd : (1, 52, 52, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = 1000\n",
    "for epoch in range(100):\n",
    "    print(\"\\n\\t epoch:\",epoch)\n",
    "    for counter,(image_data, target) in enumerate(trainset):\n",
    "        nm=str(np.random.randint(10000))+\".png\"\n",
    "        nm=str(counter)+\".png\"\n",
    "        #print(\"\\n\\t image_data=\",image_data.shape)    \n",
    "        #print(\"\\n\\t target:\",target[0][0].shape)\n",
    "        #print(\"\\n\\t target:\",target[1][0].shape)\n",
    "        #print(\"\\n\\t target:\",target[2][0].shape)\n",
    "\n",
    "        results = train_step(nm,counter,image_data, target)\n",
    "\n",
    "        cur_step = results[0]%steps_per_epoch\n",
    "\n",
    "        if 0:\n",
    "            print(\"configure TEST options to validate model\")\n",
    "            yolo.save_weights(os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME))\n",
    "            count, giou_val, conf_val, prob_val, total_val = 0., 0, 0, 0, 0\n",
    "            \n",
    "    print(\"epoch:{:2.0f} step:{:5.0f}/{}, lr:{:.6f}, giou_loss:{:7.2f}, conf_loss:{:7.2f}, prob_loss:{:7.2f}, total_loss:{:7.2f}\"\n",
    "          .format(epoch, cur_step, steps_per_epoch, results[1], results[2], results[3], results[4], results[5]))\n",
    "\n",
    " \n",
    "    count, giou_val, conf_val, prob_val, total_val = 0., 0, 0, 0, 0\n",
    "\n",
    "\n",
    "    try:\n",
    "        print(\"\\n\\ngiou_val_loss:{:7.2f}, conf_val_loss:{:7.2f}, prob_val_loss:{:7.2f}, total_val_loss:{:7.2f}\\n\\n\".\n",
    "          format(giou_val/count, conf_val/count, prob_val/count, total_val/count))\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    if TRAIN_SAVE_CHECKPOINT and not TRAIN_SAVE_BEST_ONLY:\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME+\"_val_loss_{:7.2f}\".format(total_val/count))\n",
    "        yolo.save_weights(save_directory)\n",
    "    if TRAIN_SAVE_BEST_ONLY and best_val_loss>total_val/(count+0.01):\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME)\n",
    "        yolo.save_weights(save_directory)\n",
    "        best_val_loss = total_val/(count+0.0001)\n",
    "    if not TRAIN_SAVE_BEST_ONLY and not TRAIN_SAVE_CHECKPOINT:\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME)\n",
    "        yolo.save_weights(save_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56e9bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa00d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57bad1e7",
   "metadata": {},
   "source": [
    "best_val_loss = 1000\n",
    "for epoch in range(100):\n",
    "    print(\"\\n\\t epoch:\",epoch)\n",
    "    for counter,(image_data, target) in enumerate(trainset):\n",
    "        nm=str(np.random.randint(10000))+\".png\"\n",
    "        nm=str(counter)+\".png\"\n",
    "        #print(\"\\n\\t image_data=\",image_data.shape)    \n",
    "        #print(\"\\n\\t target:\",target[0][0].shape)\n",
    "        #print(\"\\n\\t target:\",target[1][0].shape)\n",
    "        #print(\"\\n\\t target:\",target[2][0].shape)\n",
    "\n",
    "        results = train_step(nm,counter,image_data, target)\n",
    "\n",
    "        cur_step = results[0]%steps_per_epoch\n",
    "        print(\"epoch:{:2.0f} step:{:5.0f}/{}, lr:{:.6f}, giou_loss:{:7.2f}, conf_loss:{:7.2f}, prob_loss:{:7.2f}, total_loss:{:7.2f}\"\n",
    "              .format(epoch, cur_step, steps_per_epoch, results[1], results[2], results[3], results[4], results[5]))\n",
    "\n",
    "        if 0:\n",
    "            print(\"configure TEST options to validate model\")\n",
    "            yolo.save_weights(os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME))\n",
    "            count, giou_val, conf_val, prob_val, total_val = 0., 0, 0, 0, 0\n",
    "            \n",
    "            '''\n",
    "            for image_data, target in testset:\n",
    "                results = validate_step(image_data, target)\n",
    "                count += 1\n",
    "                giou_val += results[0]\n",
    "                conf_val += results[1]\n",
    "                prob_val += results[2]\n",
    "                total_val += results[3]\n",
    "            # writing validate summary data\n",
    "            with validate_writer.as_default():\n",
    "                tf.summary.scalar(\"validate_loss/total_val\", total_val/count, step=epoch)\n",
    "                tf.summary.scalar(\"validate_loss/giou_val\", giou_val/count, step=epoch)\n",
    "                tf.summary.scalar(\"validate_loss/conf_val\", conf_val/count, step=epoch)\n",
    "                tf.summary.scalar(\"validate_loss/prob_val\", prob_val/count, step=epoch)\n",
    "            validate_writer.flush()\n",
    "\n",
    "            print(\"\\n\\ngiou_val_loss:{:7.2f}, conf_val_loss:{:7.2f}, prob_val_loss:{:7.2f}, total_val_loss:{:7.2f}\\n\\n\".\n",
    "                  format(giou_val/count, conf_val/count, prob_val/count, total_val/count))\n",
    "\n",
    "            '''\n",
    "\n",
    "    count, giou_val, conf_val, prob_val, total_val = 0., 0, 0, 0, 0\n",
    "\n",
    "    '''\n",
    "    for image_data, target in testset:\n",
    "        results = validate_step(image_data, target)\n",
    "        count += 1\n",
    "        giou_val += results[0]\n",
    "        conf_val += results[1]\n",
    "        prob_val += results[2]\n",
    "        total_val += results[3]\n",
    "    # writing validate summary data\n",
    "    with validate_writer.as_default():\n",
    "        tf.summary.scalar(\"validate_loss/total_val\", total_val/count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/giou_val\", giou_val/count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/conf_val\", conf_val/count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/prob_val\", prob_val/count, step=epoch)\n",
    "    validate_writer.flush()\n",
    "    '''\n",
    "    try:\n",
    "        print(\"\\n\\ngiou_val_loss:{:7.2f}, conf_val_loss:{:7.2f}, prob_val_loss:{:7.2f}, total_val_loss:{:7.2f}\\n\\n\".\n",
    "          format(giou_val/count, conf_val/count, prob_val/count, total_val/count))\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    if TRAIN_SAVE_CHECKPOINT and not TRAIN_SAVE_BEST_ONLY:\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME+\"_val_loss_{:7.2f}\".format(total_val/count))\n",
    "        yolo.save_weights(save_directory)\n",
    "    if TRAIN_SAVE_BEST_ONLY and best_val_loss>total_val/(count+0.01):\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME)\n",
    "        yolo.save_weights(save_directory)\n",
    "        best_val_loss = total_val/(count+0.0001)\n",
    "    if not TRAIN_SAVE_BEST_ONLY and not TRAIN_SAVE_CHECKPOINT:\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME)\n",
    "        yolo.save_weights(save_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44cda0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python train.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_keras",
   "language": "python",
   "name": "yolo_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
