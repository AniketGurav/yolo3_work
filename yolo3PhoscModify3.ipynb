{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    this script traines yolov3 with PHOSCNET results ar not good.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    this script traines yolov3 with PHOSCNET results ar not good.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_val_loss = 1000\n",
    "for epoch in range(100):\n",
    "    print(\"\\n\\t epoch:\",epoch)\n",
    "    for counter,(image_data, target) in enumerate(trainset):\n",
    "        nm=str(np.random.randint(10000))+\".png\"\n",
    "        nm=str(counter)+\".png\"\n",
    "        #print(\"\\n\\t image_data=\",image_data.shape)    \n",
    "        #print(\"\\n\\t target:\",target[0][0].shape)\n",
    "        #print(\"\\n\\t target:\",target[1][0].shape)\n",
    "        #print(\"\\n\\t target:\",target[2][0].shape)\n",
    "\n",
    "        results = train_step(nm,counter,image_data, target)\n",
    "\n",
    "        cur_step = results[0]%steps_per_epoch\n",
    "        print(\"epoch:{:2.0f} step:{:5.0f}/{}, lr:{:.6f}, giou_loss:{:7.2f}, conf_loss:{:7.2f}, prob_loss:{:7.2f}, total_loss:{:7.2f}\"\n",
    "              .format(epoch, cur_step, steps_per_epoch, results[1], results[2], results[3], results[4], results[5]))\n",
    "\n",
    "        if 0:\n",
    "            print(\"configure TEST options to validate model\")\n",
    "            yolo.save_weights(os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME))\n",
    "            count, giou_val, conf_val, prob_val, total_val = 0., 0, 0, 0, 0\n",
    "            \n",
    "            '''\n",
    "            for image_data, target in testset:\n",
    "                results = validate_step(image_data, target)\n",
    "                count += 1\n",
    "                giou_val += results[0]\n",
    "                conf_val += results[1]\n",
    "                prob_val += results[2]\n",
    "                total_val += results[3]\n",
    "            # writing validate summary data\n",
    "            with validate_writer.as_default():\n",
    "                tf.summary.scalar(\"validate_loss/total_val\", total_val/count, step=epoch)\n",
    "                tf.summary.scalar(\"validate_loss/giou_val\", giou_val/count, step=epoch)\n",
    "                tf.summary.scalar(\"validate_loss/conf_val\", conf_val/count, step=epoch)\n",
    "                tf.summary.scalar(\"validate_loss/prob_val\", prob_val/count, step=epoch)\n",
    "            validate_writer.flush()\n",
    "\n",
    "            print(\"\\n\\ngiou_val_loss:{:7.2f}, conf_val_loss:{:7.2f}, prob_val_loss:{:7.2f}, total_val_loss:{:7.2f}\\n\\n\".\n",
    "                  format(giou_val/count, conf_val/count, prob_val/count, total_val/count))\n",
    "\n",
    "            '''\n",
    "\n",
    "    count, giou_val, conf_val, prob_val, total_val = 0., 0, 0, 0, 0\n",
    "\n",
    "    '''\n",
    "    for image_data, target in testset:\n",
    "        results = validate_step(image_data, target)\n",
    "        count += 1\n",
    "        giou_val += results[0]\n",
    "        conf_val += results[1]\n",
    "        prob_val += results[2]\n",
    "        total_val += results[3]\n",
    "    # writing validate summary data\n",
    "    with validate_writer.as_default():\n",
    "        tf.summary.scalar(\"validate_loss/total_val\", total_val/count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/giou_val\", giou_val/count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/conf_val\", conf_val/count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/prob_val\", prob_val/count, step=epoch)\n",
    "    validate_writer.flush()\n",
    "    '''\n",
    "    try:\n",
    "        print(\"\\n\\ngiou_val_loss:{:7.2f}, conf_val_loss:{:7.2f}, prob_val_loss:{:7.2f}, total_val_loss:{:7.2f}\\n\\n\".\n",
    "          format(giou_val/count, conf_val/count, prob_val/count, total_val/count))\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    if TRAIN_SAVE_CHECKPOINT and not TRAIN_SAVE_BEST_ONLY:\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME+\"_val_loss_{:7.2f}\".format(total_val/count))\n",
    "        yolo.save_weights(save_directory)\n",
    "    if TRAIN_SAVE_BEST_ONLY and best_val_loss>total_val/(count+0.01):\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME)\n",
    "        yolo.save_weights(save_directory)\n",
    "        best_val_loss = total_val/(count+0.0001)\n",
    "    if not TRAIN_SAVE_BEST_ONLY and not TRAIN_SAVE_CHECKPOINT:\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME)\n",
    "        yolo.save_weights(save_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10009143104675749147\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6868458560\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 883777982896672568\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\"\n",
      "]\n",
      "\n",
      "\t YOLO_TYPE: yolov3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#print(\"\\n\\t tf:\",tf.__version__)\n",
    "#tf.enable_eager_execution()\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "#from yolov3.dataset import Dataset\n",
    "from yolov3.yolov4 import compute_loss1\n",
    "from yolov3.utils import load_yolo_weights\n",
    "from yolov3.configs import *\n",
    "from evaluate_mAP import get_mAP\n",
    "\n",
    "print(\"\\n\\t YOLO_TYPE:\",YOLO_TYPE)\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from yolov3.utils import read_class_names, image_preprocess#,draw_bbox\n",
    "from yolov3.yolov3 import bbox_iou\n",
    "from yolov3.configs import *\n",
    "from yolov3.utils import load_yolo_weights, detect_image, image_preprocess, postprocess_boxes, nms, read_class_names\n",
    "from supportFunctions import draw_bbox\n",
    "'''\n",
    "    more details regarding Dataset1 is in yolo3PhoscModify2.ipynb\n",
    "'''\n",
    "from yolov3.dataset import Dataset2\n",
    "\n",
    "trainset = Dataset2('train')\n",
    "testset = Dataset2('test')\n",
    "\n",
    "\n",
    "TRAIN_PHOSC,TRAIN_PHOC,TRAIN_PHOS\n",
    "from yoloModify import yolo33\n",
    "yoloNew=yolo33(input_size=416, channels=3, training=True, CLASSES=YOLO_COCO_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN_MODEL_NAME=\"yolov3_custom_total_loss2_  46.21\"\n",
    "#TRAIN_MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "\n",
      "\t load checkpoint!!!\n",
      "\n",
      "\t loading complete\n"
     ]
    }
   ],
   "source": [
    "#from yolov3.yolov4 import Create_YoloPhosc\n",
    "#from yolov3.yolov3 import Create_Yolov3\n",
    "global TRAIN_FROM_CHECKPOINT\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(f'GPUs {gpus}')\n",
    "if len(gpus) > 0:\n",
    "    try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError: pass\n",
    "\n",
    "if os.path.exists(TRAIN_LOGDIR): shutil.rmtree(TRAIN_LOGDIR)\n",
    "writer = tf.summary.create_file_writer(TRAIN_LOGDIR)\n",
    "\n",
    "if len(gpus) > 0:\n",
    "    try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError: pass\n",
    "\n",
    "if os.path.exists(TRAIN_LOGDIR): shutil.rmtree(TRAIN_LOGDIR)\n",
    "writer = tf.summary.create_file_writer(TRAIN_LOGDIR)\n",
    "\n",
    "steps_per_epoch = len(trainset)\n",
    "global_steps = tf.Variable(1, trainable=False, dtype=tf.int64)\n",
    "warmup_steps = TRAIN_WARMUP_EPOCHS * steps_per_epoch\n",
    "total_steps = TRAIN_EPOCHS * steps_per_epoch\n",
    "\n",
    "if YOLO_TYPE == \"yolov3\":\n",
    "    Darknet_weights = YOLO_V3_TINY_WEIGHTS if TRAIN_YOLO_TINY else YOLO_V3_WEIGHTS\n",
    "\n",
    "\n",
    "if TRAIN_TRANSFER:\n",
    "    #Darknet = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=YOLO_COCO_CLASSES)\n",
    "    Darknet = yoloNew(input_size=YOLO_INPUT_SIZE, CLASSES=YOLO_COCO_CLASSES)\n",
    "\n",
    "    #print(\"Darknet_weights=\",os.path.isfile(Darknet_weights))\n",
    "    load_yolo_weights(Darknet, Darknet_weights) # use darknet weights\n",
    "    \n",
    "#yolo = Create_Yolo(input_size=YOLO_INPUT_SIZE, training=True, CLASSES=TRAIN_CLASSES)\n",
    "\n",
    "#yolo=Create_Yolov3(input_size=YOLO_INPUT_SIZE, training=True, CLASSES=TRAIN_CLASSES)\n",
    "\n",
    "#TRAIN_MODEL_NAME=\n",
    "if TRAIN_FROM_CHECKPOINT:\n",
    "    try:\n",
    "        print(\"\\n\\t load checkpoint!!!\")\n",
    "        yoloNew.load_weights(f\"./checkpoints/{TRAIN_MODEL_NAME}\")\n",
    "        print(\"\\n\\t loading complete\")\n",
    "\n",
    "    except ValueError:\n",
    "        print(\"Shapes are incompatible, transfering Darknet weights\")\n",
    "        TRAIN_FROM_CHECKPOINT = False\n",
    "'''\n",
    "if TRAIN_TRANSFER and not TRAIN_FROM_CHECKPOINT:\n",
    "    for i, l in enumerate(Darknet.layers):\n",
    "        layer_weights = l.get_weights()\n",
    "        if layer_weights != []:\n",
    "            try:\n",
    "                yolo.layers[i].set_weights(layer_weights)\n",
    "            except:\n",
    "                print(\"skipping\", yolo.layers[i].name)\n",
    "'''\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "#mAP_model = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=TRAIN_CLASSES) # create second model to measure mAP\n",
    "#best_val_loss = 1000 # should be large at start\n",
    "\n",
    "#print(\"\\n\\t mAP_model =\",mAP_model)\n",
    "\n",
    "#print(\"\\n\\t yolo:\",yolo.summary())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yolov3_custom'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_step(image_data, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = yolo(image_data, training=False)\n",
    "        \n",
    "        print(\"\\n\\t 1.pred_result validate:\",len(pred_result[0]))\n",
    "        pred_result =pred_result[0]\n",
    "        print(\"\\n\\t 2.pred_result validate:\",pred_result.shape)\n",
    "\n",
    "#         if type(pred_result) is list:\n",
    "#             pred_result =pred_result[0]\n",
    "        giou_loss=conf_loss=prob_loss=0\n",
    "\n",
    "        # optimizing process\n",
    "        grid = 1 if not TRAIN_YOLO_TINY else 2\n",
    "        for i in range(grid):\n",
    "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "            loss_items = compute_loss1(pred, conv, *target[i], i, CLASSES=TRAIN_CLASSES)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "\n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "\n",
    "    return giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()\n",
    "\n",
    "phoscLoss=0\n",
    "\n",
    "\n",
    "def train_step(nm,counter,image_data, target):\n",
    "    #print(\"\\n\\t inside train\")\n",
    "    with tf.GradientTape() as tape:\n",
    "        #pred_result = yolo(image_data, training=True)\n",
    "        pred_result = yoloNew(image_data, training=True)\n",
    "\n",
    "        \n",
    "        '''\n",
    "        print(\"\\n\\t image_data in train:\",image_data.shape)\n",
    "        print(\"\\n\\t in train pred_result len=\",len(pred_result))\n",
    "        print(\"\\n\\t in train pred_result 0=\",pred_result[0].shape)\n",
    "        print(\"\\n\\t in train pred_result 1=\",pred_result[1].shape)\n",
    "        print(\"\\n\\t in train pred_result 0=\",pred_result[2].shape)\n",
    "        #print(\"\\n\\t in train pred_result 1=\",pred_result[3].shape)\n",
    "        '''\n",
    "    \n",
    "        image2=tf.squeeze(image_data)\n",
    "    \n",
    "        giou_loss=conf_loss=prob_loss=phocLoss1=phosLoss2=0\n",
    "\n",
    "        # optimizing process\n",
    "        grid = 3 if not TRAIN_YOLO_TINY else 2\n",
    "\n",
    "        for i in range(grid):\n",
    "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "            #print(\"\\n\\t conv train:\",conv.shape,\"\\t i:\",i)\n",
    "            #print(\"\\n\\t pred train:\",pred.shape,\"\\t i:\",i)\n",
    "            \n",
    "            loss_items = compute_loss1(pred, conv, *target[i], i, CLASSES=TRAIN_CLASSES)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "            phocLoss1+=loss_items[3]\n",
    "            phosLoss2+=loss_items[4]\n",
    "\n",
    "            \n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "        total_loss1=phoscLoss+giou_loss + conf_loss + prob_loss+phocLoss1+phosLoss2\n",
    "        #total_loss1=phoscLoss+total_loss\n",
    "        #print(\"\\n\\t phoscLoss1:\",phoscLoss1,\"\\t phoscLoss2:\",phoscLoss2)\n",
    "\n",
    "        #print(\"\\n\\t total_loss =\",total_loss,\"\\ttotal_loss =\",total_loss1)\n",
    "        \n",
    "        if total_loss<40: \n",
    "            #print(\"\\n\\t localization+PHOS loss considered \")\n",
    "            \n",
    "            total_loss1=0.2*(giou_loss + conf_loss + prob_loss)+(phocLoss1+phosLoss2+phoscLoss)\n",
    "            gradients = tape.gradient(total_loss1, yoloNew.trainable_variables)\n",
    "        else:\n",
    "            #print(\"\\n\\t only PHOS loss considered\")\n",
    "\n",
    "            gradients = tape.gradient(total_loss, yoloNew.trainable_variables)\n",
    "            \n",
    "        optimizer.apply_gradients(zip(gradients, yoloNew.trainable_variables))\n",
    "\n",
    "        global_steps.assign_add(1)\n",
    "        if global_steps < warmup_steps:# and not TRAIN_TRANSFER:\n",
    "            lr = global_steps / warmup_steps * TRAIN_LR_INIT\n",
    "        else:\n",
    "            lr = TRAIN_LR_END + 0.5 * (TRAIN_LR_INIT - TRAIN_LR_END)*(\n",
    "                (1 + tf.cos((global_steps - warmup_steps) / (total_steps - warmup_steps) * np.pi)))\n",
    "        optimizer.lr.assign(lr.numpy())\n",
    "\n",
    "        # writing summary data\n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar(\"lr\", optimizer.lr, step=global_steps)\n",
    "            tf.summary.scalar(\"total_loss\", total_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"total_loss1\", total_loss1, step=global_steps)\n",
    "\n",
    "            tf.summary.scalar(\"giou_loss\", giou_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"conf_loss\", conf_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"prob_loss\", prob_loss, step=global_steps)\n",
    "\n",
    "            tf.summary.scalar(\"phocLoss1\", phocLoss1, step=global_steps)\n",
    "            tf.summary.scalar(\"phosLoss2\",phosLoss2, step=global_steps)\n",
    "            tf.summary.scalar(\"phocLoss1+phosLoss2\",(phocLoss1+phosLoss2), step=global_steps)\n",
    "\n",
    "        writer.flush()\n",
    "    #print(\"\\n\\t total_loss =\",total_loss.numpy(),\"\\t total_loss1 =\",total_loss1.numpy())\n",
    "    #print(\"\\n\\t phocLoss1=\",phocLoss1.numpy(),\"\\t phosLoss2:\",phosLoss2.numpy())\n",
    "\n",
    "        \n",
    "    pred_result = yoloNew(image_data, training=False)\n",
    "    #print(\"\\n\\t image_data pred:\",image_data.shape)\n",
    "    #print(\"\\n\\t len(pred_result) pred:\",len(pred_result))\n",
    "    image2=tf.squeeze(image_data)\n",
    "\n",
    "    #print(\"\\n\\t\\t 1.pred_result pred=\",pred_result[0].shape)\n",
    "    #print(\"\\n\\t\\t 2.pred_result pred=\",pred_result[1].shape)\n",
    "    #print(\"\\n\\t\\t 3.pred_result pred=\",pred_result[2].shape)\n",
    "    \n",
    "    #print(\"\\n\\t image2=\",image2.shape)\n",
    "    #pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_result]\n",
    "    #print(\"\\n\\t pred_bbox =\",pred_bbox )\n",
    "    #pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "\n",
    "\n",
    "    # optimizing process\n",
    "    grid = 3 if not TRAIN_YOLO_TINY else 2\n",
    "    for i in range(grid):\n",
    "        \n",
    "        if i>0:\n",
    "            continue\n",
    "\n",
    "        '''\n",
    "            these r 3 feature maps of size 52*52,26*26,13*13,\n",
    "                                \n",
    "        '''\n",
    "        conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "        #print(\"\\n\\t\\t conv pred:\",conv.shape)\n",
    "        #print(\"\\n\\t\\t pred pred=\",pred.shape)\n",
    "    \n",
    "\n",
    "        ''' \n",
    "            (xc,yc,w,h,obj,pro) is last dimension of size 6\n",
    "\n",
    "            pred = (1, 13, 13, 3, 6) is reshaped to \n",
    "            pred_bbox = (507, 6)   169 is len of single anchor tot 3 vectors             \n",
    "             #2.pred_result: (1, 52, 52, 2325)\n",
    "            conv: (1, 26, 26, 18)\n",
    "            pred = (1, 26, 26, 3, 6)\n",
    "            pred_bbox = (2028, 6)  676 is lenght of single anchor tot 3 vectors\n",
    "\n",
    "            image_data= (1, 416, 416, 3)\n",
    "            pred = (1, 52, 52, 3, 6)\n",
    "            pred_bbox = (8112, 6)  2704 is len of single anchor tot 3 vectors\n",
    "\n",
    "        '''\n",
    "\n",
    "        pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred]\n",
    "        #print(\"\\n\\t 1.pred_bbox pred=\",len(pred_bbox))\n",
    "\n",
    "        pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "\n",
    "        #print(\"\\n\\t 2.pred_bbox pred=\",pred_bbox.shape)\n",
    "\n",
    "        ''' \n",
    "        this removes invalid boxes like boxes having low confidence or \n",
    "        which has size greater than image\n",
    "\n",
    "        '''\n",
    "        #print(\"\\n\\t pred_bbox=\",len(pred_bbox))\n",
    "        bboxes = postprocess_boxes(pred_bbox, image2.numpy(), YOLO_INPUT_SIZE,0.25)\n",
    "        #print(\"\\n\\t befor nms bboxes =\",bboxes.shape)\n",
    "\n",
    "\n",
    "        bboxes = nms(bboxes, 0.1, method='nms')\n",
    "        \n",
    "        \n",
    "        #print(\"\\n\\t after nms 1.bboxes =\",len(bboxes))\n",
    "        #print(\"\\n\\t after nms 2.bboxes =\",bboxes)\n",
    "    \n",
    "        #draw_bbox() missing 1 required positional argument: 'bboxes\n",
    "        '''\n",
    "             draw_bbox(nm,counter,level, image, bboxes, CLASSES=YOLO_COCO_CLASSES, show_label=True, show_confidence=True,\n",
    "              Text_colors=(255, 255, 0), rectangle_colors='', tracking=False)\n",
    "        '''\n",
    "        #print(\"\\n\\t bboxes len:\",len(bboxes))\n",
    "        resultImage = draw_bbox(nm,counter,i,255*image2.numpy(), bboxes, CLASSES=YOLO_COCO_CLASSES, rectangle_colors=\"\")\n",
    "        #cv2.imwrite(f'./pred/{counter}.png',resultImage)\n",
    "        #input(\"check\")\n",
    "\n",
    "\n",
    "    return global_steps.numpy(), optimizer.lr.numpy(), giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy(),total_loss1.numpy()\n",
    "\n",
    "#mAP_model = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=TRAIN_CLASSES) # create second model to measure mAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t epoch: 0 \tminLoss: 100000.0\n",
      "epoch: 0 step:    1/598, lr:0.000050, giou_loss:  24.58, conf_loss:   0.07, prob_loss:   0.00, total_loss:  24.65,total_loss1:  10.89\n",
      "\n",
      "\t model saved!!!\n",
      "\n",
      "\t epoch: 1 \tminLoss: 10.893782615661621\n",
      "epoch: 1 step:    1/598, lr:0.000100, giou_loss:   6.65, conf_loss:   0.00, prob_loss:   0.00, total_loss:   6.65,total_loss1:   7.33\n",
      "\n",
      "\t model saved!!!\n",
      "\n",
      "\t epoch: 2 \tminLoss: 7.332568645477295\n",
      "epoch: 2 step:    1/598, lr:0.000100, giou_loss:  13.87, conf_loss:   0.03, prob_loss:   0.00, total_loss:  13.90,total_loss1:  12.21\n",
      "\n",
      "\t epoch: 3 \tminLoss: 7.332568645477295\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-effeeb3c32a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#print(\"\\n\\t target:\",target[2][0].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#pred_result = yolo(image_data, training=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-379f3cefa5ae>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(nm, counter, image_data, target)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m#pred_result = yolo(image_data, training=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mpred_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myoloNew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yolo_keras/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yolo_keras/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[0;32m--> 424\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    425\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yolo_keras/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yolo_keras/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    977\u001b[0m     \u001b[0;31m#  signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[0;31m# (5) False (treating the layer as if it's in inference)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m     args, kwargs, training_mode = self._set_training_mode(\n\u001b[0m\u001b[1;32m    980\u001b[0m         args, kwargs, call_context)\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yolo_keras/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_set_training_mode\u001b[0;34m(self, args, kwargs, call_context)\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0;31m# For case (2), (3), (4) `training` arg is passed by framework.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m         args, kwargs = self._set_call_arg_value('training', training_mode, args,\n\u001b[0m\u001b[1;32m   1217\u001b[0m                                                 kwargs)\n\u001b[1;32m   1218\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yolo_keras/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_set_call_arg_value\u001b[0;34m(self, arg_name, new_value, args, kwargs, inputs_in_args, pop_kwarg_if_none)\u001b[0m\n\u001b[1;32m   2606\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2607\u001b[0m       kwargs, inputs_in_args=False, pop_kwarg_if_none=False):\n\u001b[0;32m-> 2608\u001b[0;31m     \u001b[0marg_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fn_arg_positions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2609\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marg_pos\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2610\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minputs_in_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yolo_keras/lib/python3.8/site-packages/tensorflow/python/keras/utils/layer_utils.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(item)\u001b[0m\n\u001b[1;32m    461\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m       \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yolo_keras/lib/python3.8/weakref.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_loss = 1000\n",
    "\n",
    "minLoss=100000.0\n",
    "for epoch in range(500):\n",
    "    print(\"\\n\\t epoch:\",epoch,\"\\tminLoss:\",minLoss)\n",
    "    #counter,(image_data, target,allImagesName)\n",
    "    for counter,(image_data, target,allImagesName) in enumerate(trainset):\n",
    "        nm=str(np.random.randint(10000))+\".png\"\n",
    "        nm=str(counter)+\".png\"\n",
    "        #print(\"\\n\\t image_data=\",image_data.shape,\"\\t counter:\",counter,\"\\t nm:\",nm)    \n",
    "        #print(\"\\n\\t target:\",target[0][0].shape)\n",
    "        #print(\"\\n\\t target:\",target[1][0].shape)\n",
    "        #print(\"\\n\\t target:\",target[2][0].shape)\n",
    "\n",
    "        results = train_step(nm,counter,image_data, target)\n",
    "\n",
    "        #pred_result = yolo(image_data, training=True)\n",
    "        \n",
    "        cur_step = results[0]%steps_per_epoch\n",
    "        totLoss=results[-2]\n",
    "            \n",
    "    print(\"epoch:{:2.0f} step:{:5.0f}/{}, lr:{:.6f}, giou_loss:{:7.2f}, conf_loss:{:7.2f}, prob_loss:{:7.2f}, total_loss:{:7.2f},total_loss1:{:7.2f}\"\n",
    "          .format(epoch, cur_step, steps_per_epoch, results[1], results[2], results[3], results[4], results[5],results[6]))\n",
    "\n",
    " \n",
    "    count, giou_val, conf_val, prob_val, total_val = 0., 0, 0, 0, 0\n",
    "    #minLoss=min(minLoss,max(float(results[-2]),float(results[-1])))\n",
    "\n",
    "    try:\n",
    "        print(\"\\n\\ngiou_val_loss:{:7.2f}, conf_val_loss:{:7.2f}, prob_val_loss:{:7.2f}, total_val_loss:{:7.2f}\\n\\n\".\n",
    "          format(giou_val/count, conf_val/count, prob_val/count, total_val/count))\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    if float(results[-1])<minLoss:#TRAIN_SAVE_CHECKPOINT and TRAIN_SAVE_BEST_ONLY:\n",
    "        #save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME+\"_total_loss2_{:7.2f}\".format(results[-1]))\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME)\n",
    "\n",
    "        yoloNew.save_weights(save_directory)\n",
    "        print(\"\\n\\t model saved!!!\")\n",
    "        minLoss=float(results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME,minLoss,results[-1],float(results[-1])<minLoss)\n",
    "\n",
    "if 1:#float(results[-1])<minLoss:#TRAIN_SAVE_CHECKPOINT and TRAIN_SAVE_BEST_ONLY:\n",
    "    save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME+\"_total_loss2_{:7.2f}\".format(results[-1]))\n",
    "    #save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME)\n",
    "\n",
    "    yoloNew.save_weights(save_directory)\n",
    "\n",
    "    print(\"**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SAVE_CHECKPOINT,TRAIN_SAVE_BEST_ONLY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "    below part is to regenerate error\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supportFunctions import draw_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = 1000\n",
    "NUM_CLASS=1\n",
    "for epoch in range(500):\n",
    "    print(\"\\n\\t epoch:\",epoch)\n",
    "    #counter,(image_data, target,allImagesName)\n",
    "    for counter,(image_data, target,allImagesName) in enumerate(trainset):\n",
    "        nm=str(np.random.randint(10000))+\".png\"\n",
    "        nm=str(counter)+\".png\"\n",
    "        print(\"\\n\\t image_data=\",image_data.shape,\"\\t counter:\",counter,\"\\t nm:\",nm)    \n",
    "        #print(\"\\n\\t target:\",target[0][0].shape)\n",
    "        #print(\"\\n\\t target:\",target[1][0].shape)\n",
    "        #print(\"\\n\\t target:\",target[2][0].shape)\n",
    "\n",
    "        #results = train_step(nm,counter,image_data, target)\n",
    "\n",
    "        #pred_result = yolo(image_data, training=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for counter,(image_data, target,allImagesName) in enumerate(trainset):\n",
    "    #nm=str(np.random.randint(10000))+\".png\"\n",
    "    nm=str(counter)+\".png\"\n",
    "    print(\"\\n\\t image_data=\",image_data.shape,\"\\t counter:\",counter,\"\\t nm:\",nm)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python train.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
